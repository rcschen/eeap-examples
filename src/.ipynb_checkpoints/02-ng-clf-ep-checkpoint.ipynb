{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed and Predict (BoW)\n",
    "\n",
    "We treat each document as a Bag of Words (BoW), and just average the GloVe word embeddings to create document vectors, and run them through a 2 layer classifier network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "%matplotlib inline\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "\n",
    "VOCAB_FILE = os.path.join(DATA_DIR, \"ng-vocab.tsv\")\n",
    "MIN_OCCURS = 5\n",
    "\n",
    "GLOVE_FILE = os.path.join(DATA_DIR, \"glove.840B.300d.txt\")\n",
    "WORD_EMBED_SIZE = 300\n",
    "\n",
    "NUM_CLASSES = 20\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "logging.basicConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'charities': 1005, 'isn': 3912, 'cf947': 3681, '261': 3804, 'un': 5618, 'phenomenon': 1043, 'egyptian': 2254, 'limits': 1214, 'rasterized': 72, 'ss8v': 1653, 'franklig': 4922, 'qz': 5042, 'celebrations': 3825, 'ahmed': 91, 'feminism': 2216, 'darse': 1725, 'surfing': 209, 'q0': 5021, '1142': 6479, 'privilege': 5238, '7kn': 1030, 'csci': 4430, 'bugged': 1994, 'fwd': 1626, 'unequal': 2975, 'toynbee': 5630, 'swan': 1277, 'minerals': 484, 'epsilon': 2154, 'clint': 2932, 'quantify': 6457, 'parasites': 75, 'hardest': 5995, 'labview': 6063, 'antidiscrimination': 3629, 'males': 4769, 'ik': 3977, 'meteorologist': 46, 'gammons': 4329, 'washington': 6393, 'arabian': 3751, 'stillness': 131, 'artillery': 2574, 'disciples': 2906, 'kick': 3800, 'swinging': 6374, 'sunsite': 1449, 'evolution': 3757, 'icol': 2160, 'darned': 2020, 'alias': 2360, 'hallam': 1036, 'pretense': 990, 'cambell': 1914, 'mliggett': 5156, 'bucks': 6375, 'gmuvax': 4218, 'still': 859, 'poe': 2841, 'msnyder': 2577, 't3': 3959, '665': 1116, 'loser': 5096, 'forging': 817, 'lanport': 1957, 'smalltalk': 5399, 'vaccines': 256, 'finance': 4066, 'somwhere': 1055, 'kirby': 2218, 'jha': 4029, 'rz350': 1515, 'rug': 3664, 'isu': 3907, 'anecdotal': 6083, 'blackout': 3539, 'sacco': 1737, 'mmilitzo': 102, 'backed': 1673, 'suspicions': 2064, 'teaches': 822, 'unacceptable': 2760, 'evident': 622, 'u_': 5598, 'kari': 3592, 'footnotes': 2449, '1618': 4601, 'ie': 3985, 'wit': 6299, 'gadget': 385, 'comprising': 572, 'm7ey': 467, '632': 4750, 'rfelix': 858, '19930419': 3602, 'tms390': 1008, 'politician': 1719, 'airliners': 6281, 'aligned': 6439, 'dml': 3836, 'zappala': 236, '204843': 2118, 'augmented': 4494, '592': 489, 'jpegs': 6363, 'trojan': 8, 'suprise': 4230, 'sciences': 2152, 'uc': 5627, 'enables': 6471, 'fixing': 5632, 'koreans': 1842, 'dna': 43, 'yktnews': 3881, 'groupe': 4690, 'y6': 6157, 'gator': 1286, 'exposes': 925, 'gsxr': 4826, 'casualty': 1600, 'shoddy': 4292, 'analysed': 5106, 'automated': 2542, 'equilibrium': 4413, 'flock': 3255, 'cargo': 5971, 'acupuncturist': 1190, 'c5y4t7': 1406, 'uudecoded': 225, 'fiy': 62, 'eno': 4556, 'kierkegaard': 645, 'rime': 2005, 'naomi': 412, 'skanska': 6318, 'iff': 6182, 'connecting': 180, 'microelectronics': 1265, 'caf': 6002, 'realizing': 1387, 'st1rp': 4762, '180mb': 4204, 'hurh': 2572, 'brentb': 3228, 'deskjets': 2668, 'havoc': 5974, '12ms': 4255, 'chuckling': 4669, 'jumpers': 2680, 'sparcs': 1488, 'afp': 4368, 'placement': 557, 'maintains': 1676, 'consolidated': 3214, 'xpr': 2378, 'propensity': 5084, 'parameter': 2754, 'max_program_size2': 5083, 'speaker': 1234, 'positively': 90, 'birds': 3402, 'twsu': 5910, 'glove': 4307, 'upfront': 1363, 'roaming': 4165, 'rthomson': 2669, 'faire': 1016, 'turbine': 6272, 'landlords': 1285, 'populations': 45, 'uw': 5611, 'codes': 3054, 'devellano': 31, '593': 488, 'stanton': 4496, 'ncsu': 4294, 'patently': 969, 'iek': 2317, 'exagerate': 5287, 'uh': 5620, '6695': 2186, 'nitrous': 1196, 't47': 542, 'informs': 2122, 'leaders': 4500, 'spinrite': 5702, 'yt': 6178, 'real': 3492, 'statue': 2209, 'rescind': 4712, 'gunduz': 4089, 'box': 1457, 'inconsistency': 3928, 'regime': 2065, 'mayor': 3248, 'kekule': 877, '1430': 1798, 'assimilated': 53, 'pumps': 2551, 'cary': 6025, 'swat': 1279, 'walkup': 3745, 'woofers': 2791, 'mystified': 2040, 'speedisk': 1593, 'x11': 1496, 'icom': 2159, 'quantized': 4853, 'insured': 1883, 'seventy': 6437, 'meta': 5695, 'indonesian': 450, 'ihr': 3111, 'padres': 3172, 'hep': 5429, 'loses': 5097, 'gurion': 485, 'martyrs': 3498, 'prepaid': 2719, 'collided': 261, 'stop': 3942, 'garrotte': 99, 'nordique': 104, 'whales': 2230, 'lj1': 4929, 'ecac': 162, 'tripe': 303, 'lori': 5155, 'tut': 4111, 'mrchz': 1583, 'email': 3154, 'cabell': 2737, 'whalers': 1096, 'sigurdsson': 5656, 'brunswick': 988, 'woody': 3, 'olympus': 183, '346': 1906, 'lithium': 5924, 'sarid': 298, 'inner': 3830, 'breeding': 5113, 'manifestation': 6335, 'suggests': 2414, 'falsified': 1559, 'thatcher': 6129, 'postgraduate': 5007, 'navigate': 5891, 'organisations': 405, 'criminal': 5759, 'brotherhood': 312, 'leary': 368, 'bulgarian': 4206, 'nmp': 3507, 'servants': 1141, 'norton': 3118, 'raiding': 1134, '35894': 5081, 'mk': 4540, 'wedged': 3635, 'bagpiper': 908, 'gleason': 2156, 'jrm': 985, 'umslip': 1251, 'algo_count': 2562, 'slipper': 2959, 'j4r': 5734, 'cae': 6003, 'nonprofit': 5164, 'stockman': 4824, 'cdroms': 5837, 'atrophy': 609, 'adams': 1574, 'eith': 6084, 'vendetta': 1380, 'innovative': 684, 'velarde': 4609, 'surfaces': 2179, 'er': 3433, 'kurdish': 4151, '100ns': 4888, 'raya': 4052, 'hatreds': 3126, 'trajectory': 3158, 'tastes': 2785, 'bn1': 5260, 'mbs3': 5532, 'ramble': 1898, 'geoffrey': 437, 'haldre': 2283, 'princes': 4487, 'phenomena': 6387, 'cyanide': 5508, 'entails': 6132, 'traditionally': 1977, 'uncompressed': 3089, 'marginally': 3384, 'officers': 6207, 'orlk': 6005, 'percieved': 2400, 'petch': 3709, 'mets': 5693, 'vouchers': 71, 'reiterate': 2001, '345': 1905, 'lange': 5302, 'yd': 6170, '1185': 1885, 'pnakada': 5812, 'gail': 1257, 'herring': 2266, 'dunn': 3566, 'brl': 654, 'unsubscribe': 5711, 'uicvm': 1472, 'pcmcia': 3247, 'referencing': 1151, 'granato': 1182, 'beranek': 4150, 'races': 5544, 'maths': 3573, 'propelled': 1242, 'middle': 4137, 'mindset': 4351, 'subclass': 5265, 'garner': 4799, 'liefting': 4569, 'buys': 4768, 'p24t': 6385, 'steelers': 6225, 'jerk': 182, 'brutality': 2030, 'mud': 1997, 'unify': 4289, 'irisa': 5814, 'klesko': 1659, 'resisting': 3938, 'blames': 3304, 'marksmanship': 4527, 'apostle': 1710, 'eeeep': 4633, 'magneto': 4575, 'intelsat': 1059, 'beans': 4323, 'wray': 5273, 'developing': 321, 'expeditions': 3926, 'uhcc': 5527, 'tin': 448, 'phonetic': 1793, 'fade': 4568, 'vhf': 1596, 'cathy': 982, '4368': 2238, 'plurality': 3919, 'endpoints': 756, 'web': 3078, 'induce': 4827, 'stupendous': 2677, 'ganglion': 1065, 'life': 2663, 'nieporent': 5251, 'status': 2207, 'se1': 3009, 'makedepend': 3326, 'rac2': 5641, 'recreating': 3099, 'shrinking': 935, 'hair': 1866, 'cleansed': 6101, 'weights': 4949, 'bruhns': 3070, 'cured': 4395, 'pinghua': 4236, 'hogwash': 4937, 'paranormal': 1217, 'uncwil': 5581, 'indigo': 5930, 'crows': 145, 'rasterizer': 74, '1993apr03': 4627, 'popular': 1039, '14711': 5848, 'redistribution': 5566, 'jre': 984, 'funniest': 1953, 'councils': 3253, 'smoothly': 2525, 'rears': 5208, 'flygare': 5114, 'sheol': 1127, '591': 486, 'idea': 4233, 'unsophisticated': 3272, 'mandock': 6488, 'evasion': 6206, 'fl': 875, 'chester': 429, 'shatila': 2466, 'ax2': 2787, 'uwovax': 2907, 'bulb': 964, 'br_': 657, 'keown': 1720, 'disinfectant': 3514, 'disoriented': 1853, 'stared': 4509, 'cube': 2482, 'shifts': 4767, 'sorta': 3134, 'aide': 1327, 'spokesman': 1287, 'maurice': 3609, 'tune': 5883, 'jewishness': 2573, 'divorced': 4030, 'gmeds': 3488, 'moepi': 251, 'restored': 1443, 'passing': 4429, '23426': 4405, 'reformers': 4565, 'pex': 4311, 'berne': 3458, 'memetic': 3783, 'manufacture': 6265, 'alsys': 854, 'inclusive': 3348, 'manipulator': 5636, 'm7ex': 2803, 'nutshell': 5367, 'aiyar': 5520, 'aaron_bratcher': 3882, 'dagestan': 3921, 'transceiver': 5408, 'gs135': 1475, 'spying': 4979, 'excursion': 4854, 'arise': 4858, 'dictator': 900, 'flooded': 1241, 'ascribe': 661, 'channels': 5186, 'q24e': 313, 'seanmac': 2372, 'ryde': 2271, 'annexation': 4267, 'minivan': 4375, 'gather': 2143, 'arromdians': 5871, '436': 827, 'lgo': 5756, 'dungeons': 1506, 'autoimmune': 2236, 'gentiles': 2565, 'abused': 301, 'ecl': 3727, 'bug': 4485, 'irreversible': 3520, 'records': 2767, 'groves': 3238, 'gunned': 2027, 'eerik': 2066, '60s': 5791, 'layouts': 5517, 'bus': 4479, 'mcnamara': 138, 'mulroney': 1623, 'disqualified': 6011, 'firm': 2931, 'polished': 2537, 'rayssd': 2023, 'bhm116e': 5437, 'squirted': 1616, 'stampfli': 536, 'setver': 5652, 'alcoholic': 6080, 'optarg': 1849, 'sdcc13': 4045, 'mathcad': 2223, 'swedes': 1803, 'w27': 2578, 'galen': 847, 'happily': 5886, 'squad': 1512, 'davar': 2712, 'imitation': 4857, 'figure': 2117, 'scharfy': 1253, 'ses': 2992, 'fifteen': 504, 'koblas': 2626, 'plots': 6258, 'college': 2781, 'long': 2377, '1983': 4473, 'creationist': 3150, 'ostensibly': 5376, 'actix': 5366, 'lily': 5720, 'devising': 5424, 'pb170': 885, 'knx': 445, 'continuum': 3714, 'run': 3660, 'm_sells': 5166, 'probe': 1350, 'mead': 6454, 'belt': 436, 'supermac': 2147, 'packing': 1769, 'compact': 1114, 'ceases': 962, 'purity': 3391, '195452': 5465, '8959': 6310, 'exothermic': 1269, 'suffering': 5572, 'dclunie': 2664, 'gnb': 752, 'carl': 6029, 'borrowed': 1988, 'soldering': 164, '483': 1608, 'fender': 2205, 'membrane': 581, 'minorities': 1058, 'milliseconds': 6305, 'obselete': 1248, 'granberry': 5180, 'nplease': 3688, 'goer': 2103, 'ut': 5610, 'thundering': 710, 'bigdesk': 2612, 'differed': 1009, 'es': 3432, 'parser': 5629, 'funeral': 6224, 'conductive': 111, 'abreviations': 4097, 'see': 2999, 'allegations': 2166, 'oliveira': 1808, 'cheong': 535, '1607': 769, 'vietnam': 2074, 'wetteland': 1381, 'belgeleri': 3829, 'amenable': 1148, 'x10': 1495, 'costing': 4897, 'sentient': 5467, 'ish': 3910, 'minivas': 4373, 'initiates': 366, '1mb': 3481, 'negotiation': 3286, 'sanctifying': 6368, 'rus': 3666, 'sudbury': 471, 'assertion': 6216, 'aston': 1320, 'hp4': 3213, 'alessandro': 579, 'micro': 1666, 'c5sk1d': 5943, 'current': 2728, 'individual': 4270, 'markov': 1284, 'direction': 2192, 'mq6': 2958, 'venari': 4005, 'turklere': 592, 'estrogen': 6271, 'prove': 5983, 'legendary': 5688, 'maker': 509, 'axe': 2795, 'mailorder': 3340, 'visits': 3680, 'piped': 421, 'mystics': 6448, 'messier': 246, 'glucoma': 5817, 'profound': 4998, 'se5': 3008, 'crucial': 6458, 'hadley': 4981, 'vlbus': 1374, 'pleasing': 1760, 'rebuilt': 3479, 'bud': 4486, 'nonsense': 6260, 'lowered': 5808, 'themself': 2262, 'gratitude': 746, 'chaps': 5477, 'benson': 196, '_nei': 2292, 'resource': 5373, 'usui': 4369, 'sensory': 2600, 'synchronized': 1644, 'northampton': 1484, 'having': 5638, 'decade': 5724, 'farmer': 2129, 'newton': 774, 'jackets': 1297, 'io20456': 2531, 'm0q': 3717, 'avetis': 1702, 'unidentified': 4693, 'conclusion': 2550, 'removing': 6110, 'kelly': 5565, 'tmp': 4458, 'bernstein': 5528, 'analogous': 1446, 'creations': 2764, 'contentions': 4510, 'ecr': 3732, 'vlbi': 3438, 'sacrum': 5505, 'medium': 4662, 'pocklington': 3187, 'interfaced': 4279, 'halil': 1578, 'speaks': 4706, 'w32': 6403, 'mcontent': 129, 'poisonous': 2911, 'uq': 5612, 'cassettes': 3039, 'arlow': 2169, 'debugger': 4199, 'incompetent': 2662, 'strategies': 4692, 'minimise': 2234, 'obey': 5105, 'paints': 3512, 'wiliki': 393, 'sacrificed': 3606, 'colombo': 3464, 'sooooo': 1378, 'romano': 1503, 'awakened': 4135, 'starcat': 3656, 'nei4': 987, 'loyalty': 1313, 'celibate': 2459, 'nick': 2386, '191': 333, 'codified': 1415, 'mature': 3050, 'problem': 625, 'wvnet': 3345, 'systematic': 5545, 'exuptr': 3076, 'denver': 3250, 'leans': 4916, 'veterans': 2718, 'taillights': 1091, 'busch': 1731, 'dwovax': 3337, 'geology': 3219, '083': 1436, 'passion': 615, 'xz550': 2569, 'ud': 5624, 'assisting': 6478, 'comparable': 6361, 'scodal': 5286, 'wycliffe': 5860, 'greeted': 2018, 'makarov': 2583, 'brighton': 3510, 'nwu': 1899, 'beeping': 2587, 'ax': 2879, 'mentor': 1389, 'imposible': 4944, 'cwis': 1964, 'ghostview': 325, 'artsakh': 821, 'ma': 4534, 'conestoga': 539, 'spoken': 228, 'chatham': 3735, '636': 4754, 'kraken': 2350, 'bro': 653, 'sinking': 5138, 'f_gautjw': 3361, 'sundevil': 1683, 'feds': 3633, 'willson': 1985, 'rambling': 6060, 'lamps': 2106, 'niether': 717, 'usnail': 6082, 'eco': 3725, 'gooch': 2694, 'akgun': 1986, '633': 4751, 'adorn': 4663, 'elided': 1660, 'xtrealizewidget': 4256, 'tasted': 2783, 'mg': 4532, 'contextual': 2323, '100mb': 1061, 'husc': 6388, 'sakari': 1072, 'hog': 5326, 'orchestrated': 550, 'razing': 1757, 'irenaeus': 2849, 'hides': 2750, 'faithfully': 1712, 'ja': 4125, 'fontsrc': 4995, 'microtest': 584, 'knobs': 5519, 'test': 4781, 'deborah': 6121, 'quantities': 3958, 'equals': 3952, 'judicial': 3019, 'shortcut': 1078, 'mf': 4533, 'asala': 6449, 'xkc': 167, 'dives': 2810, 'location': 3031, 'mindlink': 5365, 'mj': 4541, 'evolutionary': 524, 'insitute': 207, 'pitfalls': 2952, 'details': 627, 'ultb': 4215, 'prophecies': 2474, '113p': 3778, 'olivia': 2943, 'nuclei': 2076, 'accorded': 1651, 'mantle': 3336, '2700': 1393, 'indicators': 4434, 'runs': 726, 'ppl': 2047, 'goes': 2102, 'technicians': 1075, 'ocis': 3739, '876': 5554, 'bickford': 2443, 'discription': 2060, 'mucus': 904, 'entrusted': 6034, 'vida': 6384, 'ihj': 3113, 'falsehoods': 5215, 'immunization': 3652, 'f10': 6336, 'revolver': 1928, 'societal': 296, 'banger': 6447, 'recalls': 4785, 'established': 3224, 'battery': 3615, 'barber': 5409, 'calculations': 399, 'angst': 1522, 'bottles': 3990, 'graduated': 3332, 'undetected': 683, 'century': 1727, 'cardinal': 2437, 'cadlab': 3397, 'canvas': 2774, 'ttacs1': 4909, 'across': 1549, 'doubts': 124, 'loon': 6234, 'rom': 2078, 'duodock': 6264, '34w': 1922, 'vaction': 1176, 'tcreyw5pzwwgribuyxlsb3igpexva2laywnjys5ubxn1lmvkdt4': 865, 'sherlock': 5765, '433': 832, 'convoy': 2714, 'bmoss': 3795, 'hydrocarbons': 6035, 'millennia': 3750, 'deltabox': 2912, 'enforced': 1178, 'oms': 1361, 'jkellett': 6141, 'ex': 3425, 'lunatics': 5884, 'w20': 2580, 'apparantly': 705, 'q9': 5028, 'concur': 2137, 'zener': 4041, 'kuopio': 5277, '6473': 382, '6e1t': 4668, 'cubs': 2485, 'mylar': 6401, 'rut': 3667, 'spaceball': 869, 'snyder': 619, 'blooded': 1487, 'y0': 6151, '2ah': 1341, 'pfc': 3053, 'coronado': 5271, 'hembruch': 2022, 'transmit': 5895, 'joust': 2666, 'q900': 1439, 'geeks': 3387, 'sea': 3002, 'oakhill': 5008, 'repenting': 1333, 'archbishop': 3083, 'emphasized': 2096, 'satanic': 4719, 'clears': 1347, 'ludicrously': 3267, 'ae': 2859, 'ecn': 3726, 'zmed16': 5829, 'capel': 2633, 'sebastian': 5262, 'r3000': 51, 'transitions': 1163, 'transient': 481, 'cuffel': 2430, 'assistant': 5371, 'lying': 2313, '4z': 1258, 'crudely': 4384, 'sank': 326, 'cornering': 3787, 'pochanayon': 4009, 'elephant': 2753, 'ruuttu': 4953, 'baltic': 3264, 'acid': 2406, 'pen': 4317, '_without_': 6137, 'jeffh': 3299, 'targa': 25, '199s': 658, 'spiral': 2540, 'djgpp': 2775, 'hooper': 2804, '75di': 2305, 'overstreet': 852, 'relationship': 2964, 'sheng': 4936, 'legged': 5425, 'weld': 6381, 'insofar': 4140, 'dismissed': 378, 'wilhelm': 5404, 'encrypt': 5958, 'qg': 5048, '9051467f': 3960, 'curricula': 2820, 'root': 1308, 'novitskey': 2687, 'pena': 4223, 'jih': 216, 'larrison': 134, 'yhwh': 1370, 'shifter': 3587, 'grandparents': 6223, 'forcibly': 694, 'a8': 2896, 'touted': 1880, 'copious': 212, 'camtec': 4335, 'tiga': 5542, 'guessing': 574, 'scorers': 2778, 'came': 5214, 'camino': 3713, 'dayton': 1684, 'thirsty': 2425, 'click': 3695, 'grounded': 1703, 'bmd': 4174, 'stowell': 3211, 'stainless': 748, 'sober': 4594, 'superuser': 4973, 'cowboys': 4788, '542b': 1881, 'thiokol': 533, 'protectors': 6395, 'invited': 5750, 'staticcolor': 2286, 'psalmist': 978, 'ym': 6163, 'thumpison': 5278, '1778': 1403, 'w24': 2579, 'cheaper': 4265, 'kates': 5832, 'successor': 2441, 'lpts': 1735, 'venerean': 1187, 'tagged': 3398, 'influence': 472, 'subdirs': 5466, 'puzzling': 2828, 'evade': 1665, 'geod': 4499, 'feigenbaum': 4604, 'rewording': 5174, 'optional': 4424, 'advocates': 6315, 'spice': 1594, 'jungle': 1514, 'enact': 5093, 'despised': 154, 'generator': 273, 'evaluated': 3858, 'm2': 4524, 'isv': 3906, 'arab': 3323, 'kasajian': 6405, 'dm9': 3831, 'teflon': 4010, 'rot': 2087, 'sevastyanova': 3366, '639': 4756, 'merced': 1614, 'babies': 2672, 'tsar': 4865, 'donald_mackie': 3671, 'xew': 3176, 'restores': 1441, 'aario': 2330, '30136': 1079, '77042': 2901, 'henneman': 3657, 'barrels': 5060, 'tl': 3814, 'fdhd': 1700, 'parity': 2523, 'jvwk': 3249, 'routines': 689, 'lasts': 6257, 'bred': 559, 'panel': 4465, 'natonal': 5395, 'aprox': 218, 'blgardne': 4081, 'stroll': 888, 'flamewar': 1293, 'r8e': 5821, 'wip': 6301, 'allowing': 2391, 'inline': 3551, 'reconstruction': 3226, 'workshift': 2328, 'burrill': 4606, 'indicative': 140, 'shaen': 3596, 'senate': 5579, 'bidding': 6233, 'ermeni': 6239, 'reboost': 6201, 'rim': 1822, 'priorities': 4587, 'drug': 3156, 'schmoe': 2545, '267': 3806, '989': 2195, '204845': 2119, 'reviewed': 1076, 'luminosity': 3147, '720k': 1395, 'enriched': 886, 'another': 698, 'formulation': 1843, 'vm_pray': 3133, 'iz': 3967, 'dozier': 2923, 'henize': 617, 'peg': 4321, 'asks': 1372, 'heller': 4841, 'u8': 5585, 'grece': 594, 'erotic': 2725, 'nirvana': 5192, 'xxxxx': 6052, 'portray': 4439, 'teacher': 823, 'tinder': 3240, 'a5': 2892, 'sanction': 4200, 'blatant': 1788, 'sim': 5455, 'tmi': 4462, 'dragon': 1654, 'codec': 3057, 'ash': 3574, 'gpc': 2298, 'nature': 117, 'refutes': 2013, '7200': 1388, 'regulations': 6275, 'vtwm': 3888, 'saudia': 2071, 'emx': 735, 'bowden': 3772, 'niemeyer': 4464, 'skeleton': 6116, 'humiliated': 3683, 'afs': 4370, 'rioters': 5338, 'nutritionist': 6195, 'contour': 5537, 'implausible': 5487, 'burt': 4015, 'mcwilliams': 1792, 'lk8': 1122, 'afb': 4364, 'virginia': 4780, 'comdex': 1688, 'ox1': 3604, 'mikuni': 6431, 'settling': 2412, 'visitors': 4735, 'potassium': 4942, 'explosion': 3371, 'lastdrive': 6417, 'symmetrical': 5247, 'reducing': 2700, 'priced': 5128, 'supporting': 3370, 'myhint': 1732, 'hps': 3205, 'hysterically': 1869, 'wendel': 2671, 'ee92jks': 1375, 'clarinews': 2476, '606': 949, 'ethics': 5484, 'curcio': 3849, 'repellant': 1413, 'exhibition': 4928, 'protestantism': 1312, 'yp': 6175, 'jaromir': 2363, 'e2big': 4914, 'pegged': 1529, 'accordance': 704, 'rebuild': 3477, 'coded': 3058, 'aorta': 795, 'v16t': 2510, 'savela': 1400, 'robertson': 1300, 'reformation': 1399, 'headline': 5217, 'voder': 1773, '27m': 33, 'introns': 2623, 'plea': 6435, '272': 17, 'struck': 1912, 'impelled': 707, 'premise': 1698, 'cal': 5999, '6j3': 856, 'palms': 169, 'bending': 5089, 'binding': 442, 'windshield': 1316, 'cultured': 2231, 'p3n': 2373, 'masons': 2679, 'detectors': 2621, 'rocks': 5867, 'grape': 3364, 'rebooted': 1326, 'telix': 224, 'unca': 4717, 'evangelicals': 4855, 'q2': 5023, 'compliments': 4249, 'earlham': 4823, 'tamsun': 5142, 'importing': 4438, 'j54': 1862, 'qp': 5034, 'sei': 3007, 'traffic': 279, 'transparency': 5845, 'rapids': 1597, 'rockefeller': 1041, 'holmdel': 4051, 'varsity': 4529, 'refered': 3843, 'olde': 400, 'kupajava': 4896, 'fairness': 2903, 'bitching': 3459, 'asymptomatic': 5292, 'aft': 4367, 'adult': 6438, '773': 3655, 'UNK': 1, '694': 5660, 'literal': 5075, 'icon': 2161, 'kincy': 1045, 'damico': 3191, 'enforcement': 547, 'kryptonite': 6217, 'transfusion': 1833, 'geoff': 1696, 'researchers': 2212, 'warring': 2692, 'fpa1': 423, '800x600x256': 4201, 'mythology': 6372, 'elman': 775, '78735': 5940, 'q3': 5022, 'gizwt': 998, 'visibly': 4514, 'imagery': 2936, '617': 374, 'motecc': 307, 'oracle': 4408, 'overdrive': 6199, 'blood': 4213, 'runner': 5200, 'bxlt': 3561, 'bhjnuy': 718, 'kartik': 4966, 'saved_cmdline': 720, '1715': 3846, 'il': 3980, 'yasna': 2945, '2340': 2428, 'nxy': 2710, '1157': 2684, 'dmp': 3839, 'consenting': 93, 'magstripe': 3241, 'video': 496, 'practise': 607, 'ballot': 3184, 'rigged': 3080, 'burn': 4014, 'dedicated': 3388, '8cl': 2421, 'ecb': 3724, '279': 24, 'cjhs': 2610, 'subscriber': 2190, 'fault': 2008, 'karras': 4034, 'jz': 4107, 'hku': 2411, 'brakes': 3654, 'telefax': 3548, 'reap': 3496, 'itti': 3511, 'maclennan': 589, 'madonna': 2670, 'navajo': 4342, 'condenser': 3284, 'xstones': 5768, 'boi': 1463, 'disputed': 692, 'xsendevent': 5597, 'neon': 913, 'inside': 5282, 'slant': 2887, '1999': 671, 'irus': 446, 'mbyets': 3023, 'killing': 4112, 'descriptions': 1177, 'madison': 2797, 'snooper': 3087, 'mccall': 1325, 'hebert': 5856, 'sony1': 4573, 'filinuk': 5443, 'fik': 67, 'qveiq': 195, 'directing': 6020, 'doelle': 5410, 'iridium': 1941, 'egalon': 4078, 'descriptor': 2747, 'rednecks': 2655, 'inferences': 3065, 'exercises': 5899, '7v_': 747, 'preventing': 3056, 'irb': 113, 'semitic': 1568, 'superieure': 3290, '2461': 568, 'ruiter': 5259, 'race': 5647, 'wolfram': 2582, 'sodom': 688, '599': 494, 'thomsonal': 4561, 'concurance': 2168, 'hafta': 1315, 'bwtwo1': 4765, 'hayden': 6191, 'coordinating': 2486, 'jrmst8': 2715, 'disposal': 4961, 'colling': 1689, '077': 5243, 'affirmed': 2796, 'iy': 3966, 'pallets': 1353, 'dbm0000': 1203, 'prevailed': 341, 'dalgarno': 2126, 'schism': 5146, 'legislative': 3116, 'stssdxb': 2805, 'hammered': 1780, 'curiouser': 83, 'thessaloniki': 2637, 'thrace': 13, 'lunacy': 3034, 'traer': 1615, 'reception': 3359, 'controllers': 3817, 'ppi': 2045, 'revolting': 3899, 'adults': 1552, 'gpb': 3917, 'zellner': 1354, 'unintentionally': 193, 'mains': 6061, 'clamps': 1966, 'behrens': 3559, 'beginner': 3104, 'm7ez': 466, 'ur': 5615, 'jill': 1167, 'orgs': 4087, 'committment': 1034, 'arno': 2543, 'localities': 4602, 'picea': 5328, 'mi': 4538, 'dafco': 3755, 'smk5': 1979, 'pusher': 841, 'renderman': 3120, 'nilsson': 6334, '2703': 2056, 'g3n': 1405, 'sdcc12': 4044, 'groups': 4691, 'theater': 3489, 'apartment': 2253, '872': 5558, '276': 21, 'anson': 4069, '9f9f9f9d': 3822, 'directory': 2250, 'shipments': 95, 'databooks': 6356, 'luck': 3893, '262': 3803, 'except': 4777, 'spokesperson': 1993, 'biberdorf': 5067, 'mori': 356, 'merritt': 682, 'supplementation': 5917, 'boils': 6317, 'fragmentary': 3235, 'rusty': 5196, 'friction': 248, 'interfaces': 4276, 'geography': 192, 'uz': 5608, 'constantly': 5279, 'exited': 2265, 'bmerh824': 5227, 'flaming': 3595, 'inode': 2658, 'higher': 2345, 'jovian': 2814, 'w3p': 6397, 'rotary': 5210, 'vc': 918, 'nrmendel': 2657, 'imply': 5649, 'simm': 3028, 'miriam': 5446, 'resisted': 1716, 'bzzt': 4885, 'grenades': 4934, 'unknown': 2454, 'koziol': 5124, 'limitation': 4656, 'election': 2037, 'samurai': 644, 'cvs': 591, 'mowing': 4978, 'vmmw': 1575, 'ua': 5626, 'books': 530, 'cyprus': 5135, 'falsifiable': 1789, 'keyless': 1694, 'empros': 2189, 'variational': 1972, 'bleed': 5838, 'i5': 3999, '34i': 1918, 'kol': 4241, 'trianglehead': 2320, 'b8i': 4723, 'tharp': 3162, 'experienced': 6209, 'odometer': 355, 'hurt': 2571, 'following': 202, 'wgw': 3261, 'a85w': 1082, 'rosereader': 3378, 'fairgrounds': 6097, 'halves': 4272, 'l3': 5793, 'dwallach': 1040, 'jonas': 4619, '16981': 4331, 'ceramic': 316, 'malmo': 3853, 'consciously': 4901, '9w': 3164, 'chewing': 5458, 'controversy': 38, 'aew': 571, 'hacks': 3500, 'marshall': 152, 'yelled': 5628, 'disposition': 4235, 'c610': 1829, 'rapists': 2763, 'ultimately': 4715, 'batting': 2149, 'riddance': 4250, 'literacy': 6321, 'camb': 5212, 'accustomed': 6270, 'handshake': 5252, 'activation': 3852, 'porsche': 3478, 'concept': 805, 'ironic': 2202, 'usable': 777, 'allocation': 2827, 'strains': 1215, 'baku': 4684, 'rafiq': 2452, 'asl': 3577, 'e5': 3442, 'motivation': 2306, 'gravitationally': 845, 'mr': 4549, '1984': 4470, 'shc': 3764, 'beating': 5947, 'pathologist': 3550, 'nutty': 4790, 'refuting': 582, 'moreover': 3476, 'eshnanie': 5713, 'hangings': 723, 'xsession': 6111, 'suburbs': 2539, 'gods': 5931, 'yossi': 3844, 'scheme': 6198, 'dmoney': 1003, 'hash': 344, 'mydisplay': 5984, 'polarized': 5516, 'montana': 2042, 'clamen': 1191, '3700': 4984, 'recompress': 5468, 'ooo': 3678, 'disorientation': 1916, 'codewks': 3943, 'enter': 4564, 'deblock': 4915, 'key': 1212, 'commitments': 2183, 'extent': 119, 'canadians': 1060, 'sounding': 6473, 'loos': 6237, 'i1': 3995, 'enthusiast': 1525, 'chemistry': 4301, 'importantly': 884, 'scotts': 564, 'meets': 1390, 'epfl': 5949, 'destruct': 2310, 'beezer': 1434, 'ie1': 2324, 'same': 4141, 'corporate': 133, 'verbal': 922, '5e8': 3618, 'u28037': 1427, '6176': 6119, 'corolla18': 1868, 'yb': 6168, 'm1': 4521, '1545': 5657, 'fit': 59, 'norwegian': 3305, 'bigotry': 3182, 'evangelists': 6071, 'shifted': 3586, 'klute': 1483, 'steel': 3121, 'desintegrated': 5009, 'ao': 2869, 'inadequate': 5076, 'accutane': 1806, 'ilstu': 2429, 'confessions': 2853, 'polio': 3875, 'povray': 6131, 'aohr': 175, 'kars': 3590, 'simi': 3027, 'scorn': 2643, 'kckluge': 1837, 'precedence': 4927, 'intentionally': 5129, 'et': 3427, 'bense': 3715, 'derivative': 526, 'hpcvccl': 4085, '48p': 1601, 'salerno': 5806, 'wha': 2469, 'translators': 4932, 'logins': 5380, 'doppler': 1024, 'dandy': 2399, 'mangoe': 151, 'welder': 5471, 'tmc': 4461, 'silva': 353, 'rni': 5938, 'wefiii': 3546, 'dish': 608, 'death': 915, 'ece': 3722, 'flyby': 806, 'crease': 479, 'honorary': 1715, 'hughes': 4760, 'cormack': 449, 'pritchard': 5172, 'rafik': 2451, 'martials': 1713, '430': 833, 'listings': 4077, 'become': 612, '93apr20': 1581, 'watchers': 5830, 'unrestricted': 4037, 'bearing': 3201, 'eaten': 1090, 'fallible': 4899, 'kids': 37, 'narrower': 5071, 'walls': 4227, 'norm': 318, 'scenario': 3310, 'andrews': 4843, 'fathom': 3719, '595': 490, 'lesher': 1733, 'sentencing': 56, 'bhjnux': 719, 'swamp': 716, 'whoever': 174, 'fidelity': 5375, 'natives': 2014, 'showed': 5194, 'heuvel': 1000, '423': 4649, 'colleague': 384, 'mors': 354, '120417': 5237, 'strips': 1734, 'bxltq6': 3499, 'entities': 567, 'winkler': 2416, 'outfielders': 30, 'valiant': 5144, 'arriving': 2768, 'deteriorate': 850, 'camaros': 2829, 'algeria': 2339, '1992': 667, 'cosuard': 3169, 'stockton': 2736, 'gillman': 4035, 'inputoutput': 4033, 'bob': 1468, 'jugular': 621, 'lurking': 2786, 'reprehensible': 3749, 'gyro': 4096, 'cursing': 2802, 'nicest': 163, 'centris': 3863, 'menus': 6140, 'reasoning': 2904, 'unconvincing': 5068, 'mus': 1996, 'hamfest': 2423, 'ellipse': 2374, 'eagle': 2138, 'kurds': 1714, 'houston': 523, 'religious': 965, 'manolo': 5394, 'taylordf': 2939, 'varco': 511, '154620': 882, 'homophobe': 5797, 'laced': 5489, 'adventures': 2652, 'isp': 3905, 'dialtone': 291, 'suite': 6285, 'clergyman': 3179, 'dictating': 2387, '273': 18, 'larsonian': 6365, 'seat': 1544, 'aw': 2876, '1147': 6482, 'creationists': 1668, '275': 20, 'surprisingly': 5354, 'blkbox': 5853, 'preface': 5134, 'gop': 4585, 'zbiciak': 4308, 'requires': 3685, 'americas': 1026, 'attention': 2332, 'hugs': 379, '34r': 1923, 'yd9w': 4655, 'caliber': 1038, '1z5': 1230, 'emails': 2322, 'flowing': 501, 'visible': 4515, 'makes': 508, '3fgx': 5154, 'foolish': 1743, 'knows': 1153, 'vw8': 801, 'revealed': 5327, 'extracting': 6472, 'uninstall': 6145, 'immunity': 2240, 'starvation': 3327, 'tj': 3819, '8618': 4724, 'aerg': 901, 'goedel': 6091, 'neurologist': 39, 'buick': 2538, 'tny': 673, 'gode': 5933, 'property': 5923, 'lud': 2170, 'licence': 5658, 'baserunning': 2104, 'grover': 3239, 'gehrels3': 4637, 'memex': 6325, 'amoral': 5297, 'contradicting': 3029, '1993may14': 6426, 'bonds': 5729, 'prints': 1939, 'transformers': 5423, 'hey': 5432, 'demographic': 1861, 'castro': 5828, 'successive': 6054, '0209': 4839, 'bnsc': 3585, 'combo': 4696, 'x_s': 4786, 'hayduke': 6476, 'kuwaiti': 4861, 'bernard': 4412, 'richest': 649, 'xtf': 5153, 'shi': 3766, 'spleen': 6347, 'such': 6331, 'muddy': 6107, 'commissioner': 5986, 'e7': 3444, 'procrastination': 4898, '4x4': 4503, '150a': 2461, 'omni': 5764, '12mb': 4253, '266': 3807, 'neuron': 3788, 'beyer': 49, 'asphalt': 4894, 'passcdebugflags': 4796, 'luddington': 2756, 'mt': 4543, 'chose': 2409, 'framing': 4103, 'arbitration': 6197, 'antithesis': 2343, '16550a': 1624, 'scsi2': 363, 'popupshell': 6295, 'worthless': 3016, 'maybe': 4059, 'monograph': 4620, '879': 5553, 'teamwork': 1831, 'oleg': 3873, 'tito': 1571, 'camped': 6345, 'commentary': 4252, 'swooped': 6251, 'kegs': 6399, 'matter': 3923, 'slalom': 4555, 'ilan': 4818, 'carrot': 4980, 'i6': 4001, 'infested': 5859, 'freddy': 945, 'srinivas': 569, 'mask': 5450, 'implying': 1351, 'designers': 778, 'bhkc': 4423, 'anonymously': 4991, 'represent': 4184, 'queers': 5319, '277': 22, 'spence': 2541, 'walla': 4226, 'sarkis': 1847, 'minerva': 3032, 'nen': 2615, '34u': 1921, 'read': 3494, 'remailer': 2089, 'uniondale': 909, 'surname': 3455, 'b8c': 789, '68010': 4740, 'fictitious': 1314, 'registries': 1501, 'incarnated': 4047, 'zamboni': 6023, 'toolbox': 1990, 'decenso': 5475, 'kitchen': 742, 'pleases': 2477, 'inconsistent': 249, 'abdulla': 4076, 'opener': 3437, 'gave': 2025, 'katinka': 6262, 'correspondents': 1635, 'redeemer': 3049, 'm7klj': 629, 'vivaldi': 838, 'dishonesty': 4302, 'olds': 85, '489': 1602, 'derby': 507, '98124': 2704, 'help': 6146, 'macho': 181, 'support': 1745, 'why': 2473, 'throught': 1336, 'aq': 2870, 'removeable': 4677, 'constants': 5165, 'tsai': 4864, '431': 834, 'lowering': 989, 'smoke': 3229, 'bow': 1462, 'cultists': 1012, 'm6m': 2934, 'offset': 2275, 'transaction': 3793, 'bendtsen': 3601, 'alison': 1094, 'genetically': 2307, 'futserv': 3538, '1500': 2456, 'periodic': 350, 'pathology': 2015, 'creates': 5881, 'ciba': 1968, 'backfire': 5535, 'armory': 4911, 'loom': 6235, 'rafia': 2450, 'jointed': 3482, 'contemplating': 4678, 'slcs': 3335, 'specifying': 4866, 'pasted': 4409, 'velapoldi': 1959, 'geo': 1536, 'yuck': 6133, 'macpaint': 636, 'hollow': 3014, 'typedef': 3472, 'hypo': 1049, 'pet': 4312, 'reprint': 2321, 'jur': 4805, 'panda': 646, 'goofed': 2019, 'appointment': 5459, 'videos': 4432, 'forwarding': 3451, 'grenada': 1942, 'terrorize': 4306, 'crud': 3632, 'clustering': 463, 'dms': 3840, 'boe': 1469, 'renamed': 2032, 'cooperating': 4589, 'rushed': 1878, 'rays': 4050, 'eicn': 5272, 'pagemaker': 3196, 'peacemakers': 2484, 'sacrifices': 3608, 'bxo': 3691, 'jv': 4110, 'ass': 3563, 'knocks': 1989, 'mv': 4545, 'quarrel': 4551, 'descendents': 6433, 'weyrich': 2496, 'suit': 5596, 'disinformation': 285, 'newsletter': 4935, 'flashlight': 1860, 'wintrumpet': 5680, 'mattone': 1973, 'decree': 3896, 'schedules': 4782, 'infrared': 3273, 'kbw': 4990, 'cat': 5993, 'uvic': 2413, 'conclusions': 5570, 'scouts': 999, 'belvedere': 4435, 'sombody': 1763, 'linknet': 3797, 'dwk': 4381, 'hydraulic': 2288, 'pearls': 4694, 'shl': 3768, 'squidly': 3130, 'ilbm': 1358, 'rudimentry': 2653, 'feast': 5880, 'efficiently': 3092, 'phosphate': 2184, 'enemy': 5531, 'u1': 5590, 'dykes': 1841, 'emf': 727, 'hypocrisy': 4566, 'delaney': 2274, 'am': 2867, 'whitsebd': 3937, 'felons': 2647, 'highlighted': 3168, 'surpassed': 996, '086': 1438, 'rampton': 1891, 'jodfishe': 2726, 'fuentez': 3547, 'a2x': 2674, 'warrenty': 1670, 'aliases': 5820, 'pacbell': 6232, 'shanti': 2821, 'momentum': 440, 'complex': 4631, 'robotic': 3173, 'blowing': 5794, 'extended': 1565, 'jstmp': 1220, 'yi': 6159, 'hq': 2467, 'conversations': 4711, 'jmgree01': 89, 'savasi': 210, '5em': 3621, 'jin': 214, '2285': 4842, 'karl': 3594, 'c64': 3490, 'alexei': 514, 'seeds': 3190, 'acadia': 975, 'ubvmsb': 4666, 'tech': 100, 'ludwig': 5406, 'gsulliva': 5224, 'xflush': 2581, 'boschman': 6019, 'supervisor': 3052, 'snatched': 2221, 'ebert': 1691, 'bagels': 2762, '2630': 1066, 'existance': 5546, 'monopoly': 302, 'eng': 4553, 'embarrassment': 5065, 'asw': 3565, 'sgi_rad': 1938, 'nnmc': 4348, 'trait': 474, 'garbled': 4699, 'peers': 4608, 'flawless': 697, 'chiropracty': 883, 'salem': 3523, 'learn': 370, 'it': 3973, '71441': 6212, 'rear': 3497, 'toval': 1828, 'ellison': 2925, 'works': 4455, 'oqy': 4013, 'designer': 4055, 'installing': 2099, '6086': 5413, 'recquiescat': 1018, '192105': 5456, 'invoke': 2319, 'trident': 2092, 'kitchel': 4433, 'portuguese': 2722, 'inet': 4976, 'werewolf': 4176, 'moment': 4298, 'mdata': 26, 'musone': 5879, 'anik': 1322, 'ramdrive': 4921, 'hamsters': 1677, 'ta86': 2447, 'johnny': 5441, '4066': 1243, 'tekig7': 3931, 'sobel': 4591, 'm9': 4525, 'herbert': 1283, 'xxmessage': 5030, 'subsystems': 2151, 'bcci': 2947, 'nnnn': 3279, 'diode': 2182, 'sounded': 6280, 'krypton': 4417, 'decimal': 5567, '583905': 3813, 'thorny': 4062, 'equilizer': 3105, 'nssdc': 434, 'mcgriff': 5725, 'tele': 3869, 'fegmania': 3171, 'angry': 5312, 'inel': 4974, 'uva': 696, 'xxxi': 5483, 'kleck': 4771, 'witt': 294, 'opec': 5344, 'auction': 4512, 'caj': 5994, 'benedikt': 44, 'i9': 3993, 'vandenboom': 3789, 'lanph872': 1364, 'snm6394': 3818, 'yasser': 1674, 'physchem': 4094, 'italics': 4372, 'aggressors': 6231, '_when': 1717, 'mediot': 6230, 'r_turgeo': 276, 'unchanged': 2009, 'fixate': 1543, 'elektronen': 6092, 'viktor': 3140, 'bike': 5823, 'skok': 6323, 'theodore': 1965, 'stings': 5982, 'uiboise': 1508, 'jl': 4113, 'alexander': 6220, 'bnr': 5253, 'inherited': 1197, 'mlinsenb': 3927, 'cbr900rr': 2237, 'bigcookie': 1765, 'citroen': 2980, 'coherence': 588, 'employing': 2258, 'habits': 4231, 'dlss2': 1762, 'unequivocally': 139, 'intimidating': 2544, 'coplanar': 2789, 'isolar': 3115, 'xvgr': 4939, 'litigation': 2481, 'regions': 4366, 'redgum': 2744, 'serbia': 6324, 'score': 2642, '190493111630': 4004, 'denizens': 1956, 'cannucks': 5141, 'ui': 5619, '434': 829, 'autoexec': 2153, 'overwhelmed': 413, '35t': 5767, 'argument': 5355, 'conferencing': 893, 'additives': 5111, 'betrothed': 5189, 'lawn': 5359, 'v085pwwpz': 390, 'sophomore': 4713, 'fbm': 840, 'magnets': 4576, 'heidelberg': 4304, 'st_size': 5061, '320x200': 4082, 'hogan': 5872, 'twork': 633, 'seas': 1542, 'factually': 3684, 'arabs': 6113, 'ee': 3417, 'ekg': 5143, 'applicant': 2757, 'fahrettin': 5199, 'haig': 1863, 'ranum': 453, 'hks': 2410, 'minded': 3537, '268': 3812, 'basemen': 6058, 'charlottetown': 1967, 'suction': 3544, 'rend386': 2134, 'milnet': 6204, 'poses': 5934, 'drastic': 853, '1h92': 4281, 'bembo20': 6068, 'newsletters': 4700, 'astounded': 2460, 'lineup': 3360, 'town': 4679, 'pseudo': 1442, 'casavant': 3948, 'thesaurus': 160, 'bulbs': 2111, 'screeching': 5013, 'uncharged': 1961, 'glasgow': 5228, 'turns': 813, 'laws': 5361, 'aspin': 2333, 'suppossed': 2248, 'loisc': 2822, 'javier': 3474, 'watered': 1121, 'violates': 4741, 'nutr': 681, 'hehehe': 5069, 'initiation': 438, 'minya': 518, 'battalion': 3036, 'nasm': 4951, 'muirm': 2982, 'lakeheadu': 5231, 'uabdpo': 620, 'politics': 4814, 'fertility': 3944, 'bratt': 899, 'donrm': 6221, 'jun': 4803, 'por': 2837, '3411': 5682, 'haley': 6187, 'odometers': 6477, 'umpiring': 3138, 'worker': 5241, 'guy': 4882, 'afternoon': 1417, 'melinda': 1740, 'superhighway': 3886, 'mechanism': 3129, 'summaries': 2355, 'datefield': 912, 'ballou': 3185, 'm3': 4523, 'qemm': 5070, 'i_': 3991, 'handlebars': 4868, 'recount': 4340, 'could': 538, 'infield': 5833, 'pathways': 2536, 'camarra': 2007, 'seds': 223, 'graciously': 5601, 'brew': 562, '1988': 4476, '1433': 1797, 'ism': 3913, 'uvm': 6150, 'couple': 452, 'l1': 5795, 'cesarean': 2356, 'scalable': 3277, 'sales': 3522, '_one_': 2419, 'farewell': 2135, 'pgf5': 3063, 'wm4u': 2629, 'pps': 2048, 'validated': 5850, 'foundation': 5182, '608': 955, 'unwilling': 3354, 'thereafter': 2957, 'xored': 1631, 'lobo': 846, 'ak333': 2742, 'popularity': 6211, 'scratched': 5314, 'tu': 3790, 'icop': 2155, 'cds': 3693, 'duos': 3225, 'clarity': 5187, 'inalienable': 5708, 'condor': 2984, 'defiance': 5232, 'gaia': 1259, 'governemnt': 1044, 'lifter': 5870, 'ratios': 2844, 'faster': 2072, 'fredrik': 2564, 'disagreed': 3471, 'advtech': 2917, 'mckinney': 1302, 'tgm': 3820, 'poeple': 4681, 'f16': 6337, 'deceit': 4040, 'belville': 2133, 'yourselves': 1118, 'constitutional': 6085, 'bass': 973, 'treason': 2249, 'maddison': 4863, 'bases': 6355, 'crosby': 5667, '768': 3636, 'impecable': 3743, 'ftpnuz': 5925, '597': 492, 'appreciative': 6390, 'whims': 4941, 'israel': 2269, 'randomized': 1173, 'commentators': 1895, 'kriz': 4969, 'seal': 1546, 'shirriff': 1489, 'shudder': 3100, 'molecules': 3142, 'resun': 2596, 'garnet': 4798, 'whosoever': 2772, '175334': 776, 'suing': 3244, '198': 328, 'gt0869a': 5125, '2w9': 2926, 'beaver': 3385, 'delegates': 1166, 'politely': 447, 'soderstrom': 2465, 'st902415': 5001, 'mistress': 3901, 'vandenberg': 2302, 'relevent': 5540, 'desiring': 3037, 'predicting': 1412, 'taipei': 773, 'anybody': 4924, 'irgun': 1017, 'comments': 3330, 'lenient': 4296, 'align': 5080, 'crowe': 142, '____________________________': 5502, 'satelite': 5976, 'jono': 3355, 'oberto': 4003, 'iss': 3903, '271': 16, 'succesfully': 2139, 'melting': 2029, 'copying': 4295, 'haik': 1864, 'beaufait': 5372, 'simpler': 6304, 'octal': 3630, 'stephane': 1987, 'rti': 3690, 'eg': 3419, 'resistant': 1366, 'impeach': 4309, 'hast': 346, 'rumored': 422, 'eh': 3414, 'mentality': 4246, 'm5': 4517, 'm0': 4522, 'bbddd': 1007, 'q6': 5027, 'jude': 2404, 'confounding': 4341, 'arenas': 4293, 'xall': 6330, 'yadallee': 4277, 'commoninteract': 4338, 'parikh': 1752, 'street': 4502, 'deductive': 5530, 'alfa': 815, 'compliance': 2915, '4c': 1272, 'generalize': 2251, 'vnet': 910, 'echl': 4571, 'ect': 3730, 'unbvm1': 685, 'romania': 872, 'buttons': 5727, 'ea': 3421, 'hofstra': 310, 'husc8': 1481, 'rode': 516, 'sorry': 1281, '2888': 6463, 'squat': 1510, 'dietz': 1845, 'pacastro': 2261, 'analyse': 1426, 'advancing': 6441, 'loudly': 2815, 'particulars': 3957, 'schilling': 3868, 'simpsons': 4828, '386sx': 4967, 'nasb': 4947, 'wielder': 1343, 'supporters': 3871, 'n1nwh': 4808, 'vidi': 6383, 'md': 4531, 'daker': 5956, 'chamberlain': 3940, 'merge': 3103, 'peu': 4313, 'boring': 5010, '0330': 4192, 'dumped': 3297, 'emotionalism': 4362, 'matyas': 4361, 'unleashed': 3939, 'pzm': 5082, 'turkiye': 2776, 'pacemakers': 5551, 'flexing': 2308, 'p13': 1156, 'output_program': 319, 'alois': 1774, 'biology': 616, 'opal12': 5457, 'suis': 5594, 'bruins': 1633, 'finns': 2035, 'banish': 590, 'alford': 920, 'lumber': 4977, 'postcard': 455, 'jonah': 4617, 'supportive': 6273, 'ema': 728, 'ximages': 5805, 'nazism': 1582, 'galvin': 3495, 'makey': 506, 'fitz': 5677, 'compulsory': 1001, 'cyrus': 1373, 'wiping': 4169, 'kmgoh': 2826, 'periodically': 6303, 'kurri': 4728, 'prael': 6462, 'exploit': 898, 'jamnia': 1995, 'assaulted': 1031, 'offspring': 4860, 'bombing': 5862, 'marcu': 3650, 'sepulchre': 1687, 'toes': 2260, 'iv': 3975, 'newsweek': 3710, 'unified': 4758, 'optimist': 118, 'isi': 3909, 'mc': 4535, 'stoakley': 703, 'overburdened': 1695, 'concealing': 3167, 'aras': 3321, 'prospect': 2782, 'ficus': 3947, 'screamin': 4917, 'paradyne': 2567, 'haddock': 1054, 'fairchild': 2062, 'ptorre': 1903, 'crop': 4346, 'understands': 407, 'pleased': 2480, 'tyre': 1205, 'cptully': 4505, 'subtlety': 2604, 'antimatter': 4645, 'wscrawl': 2162, 'seg': 2998, 'charitable': 4943, '8900': 5643, '487': 1604, 'nls': 2713, 'focusing': 2967, 'antibiotic': 2910, 'encounters': 4416, 'nikos': 6075, 'kdka': 743, 'soles': 4829, 'tuesday': 1216, 'jmm4h': 3086, 'software': 5800, 'nlm': 2727, 'launches': 5922, 'amend': 4761, 'fascinating': 6494, 'crary': 3677, 'vaunted': 2314, 'sep': 2994, 'logical': 5309, 'semis': 4490, 'easter': 1741, 'mccartney': 4324, 'freedoms': 4260, 'chorion': 937, 'viscosity': 5897, 'news2': 1897, 'stow': 3941, 'definitions': 2758, 'hizbollah': 2595, 'tendons': 120, 'aep': 570, 'adapter': 2651, 'shklovsky': 4794, 'brimstone': 6487, 'reverence': 97, 'y14': 4198, 'pham': 604, '6e1': 4670, 'drum': 3155, 'cameo': 2517, 'averaging': 2568, 'finals': 2245, 'fake': 5310, 'morton': 3718, 'pleasures': 2442, 'dmm': 3837, 'yr': 1561, 'sparc10': 1794, 'occasion': 1811, 'wolfgang': 4440, 'refuted': 2011, 'buffered': 5664, 'peng': 4221, 'rutherford': 201, 'garden': 3068, 'revenues': 5161, 'parallelism': 5453, 'paradise': 4879, 'midway': 1937, 'stratavision': 1855, 'yx': 6172, 'tantamount': 3950, 'tryndoch': 5334, 'autobahn': 5901, 'skinned': 4090, 'lymenet': 1194, 'causes': 1929, 'chasing': 1784, 'msw3': 5735, 'demonic': 1587, 'j979': 3152, 'malcolm': 3157, 'extra': 836, 'depriving': 2448, 'workstations': 5847, 'seqeb': 2396, 'nytimes': 1188, 'bure': 4012, 'adaptor': 5710, 'sun386i': 5275, 'router': 6445, 'sender': 2914, 'rod': 2082, 'piston': 5739, 'satisfying': 1548, 'bellies': 4274, 'nosc': 4156, 'wells': 5207, 'carved': 2875, 'inexpensive': 4586, 'milligan': 2607, 'm4': 4518, 'pmmu': 2988, '429': 4646, 'rasterops': 712, 'fission': 5538, 'duffey': 745, 'ho': 2475, 'tests': 4452, 'rectify': 5801, 'lx11': 2164, 'montreal': 230, 'tszeto': 638, 'bleeds': 2743, 'gpatapis': 1261, 'skylab': 5653, 'blessing': 2884, 'apple': 2838, 'shame': 3236, 'nokia': 6319, 'retinal': 2303, 'multitudes': 3484, 'index': 3074, 'keegan': 5245, 'cwa': 4390, 'fits': 5678, 'iex': 2315, 'wallowing': 5691, 'gnp': 749, 'sdsc': 4460, 'correlations': 5736, 'yc': 6167, '1033': 5092, 'ira': 112, 'storage': 3527, 'buffalo': 2395, 'products': 3699, 'cyclelok': 3096, 'punished': 293, 'penn': 4224, 'jj': 4117, 'olerud': 418, 'xvertext': 4889, 'convenient': 709, 'bos': 1461, 'e4': 3443, 'applicationshell': 3073, '20084': 5191, 'glock': 5077, 'bearpaw': 2508, 'xev': 3175, 'elijah': 5382, 'it175': 3232, 'collections': 2683, 'declares': 1545, 'j5j': 1856, 'accommodates': 2284, 'w1gsl': 5892, 'polyhedra': 2951, 'prosecution': 5635, 'oliveiro': 1809, 'declassified': 647, 'ambush': 3042, 'someplace': 4716, 'tnn': 676, 'labour': 3597, 'uhc': 4763, 'cdash': 1103, 'xtpointer': 1950, 'hospitalized': 2665, 'gehenna': 6006, 'magnum': 3270, 'bullets': 2244, 'eurom': 917, 'hasn': 343, 'aviris': 367, 'u4': 5587, 'sportscenter': 5578, 'sunbim': 456, 'zeineldine': 1288, 'holmes': 5663, 'qh': 5051, 'energia': 5294, 'uncecs': 2812, 'arain': 5300, 'solve': 5000, 'darius': 977, 'framemaker': 5339, 'pistol': 5740, 'webo': 3329, '38v': 6495, 'four': 5133, 'gpf': 2297, 'stroke': 4701, 'iigs': 1321, 'qq': 5033, 'participants': 4234, '481': 1610, 'azarbaijan': 5389, 'imake': 4268, 'scheduled': 4778, 'ment': 2627, 'whaley': 2228, 'yodicet': 170, 'behave': 3393, 'chair': 972, 'teenager': 2010, 'detail': 1896, 'toggle': 482, 'competence': 3132, '_your_': 2090, 'kinetic': 6152, 'benny': 6014, 'adlib': 1048, 'features': 6464, 'om4': 1357, 'mongering': 2591, 'rue': 3665, 'nextwork': 6286, 'fijh': 4079, 'plasma': 3320, 'nrizw': 4025, 'priori': 275, 'contemporaries': 2882, 'c5ydqc': 6354, 'rintintin': 5234, 'jacobs': 2281, 'reproductive': 4738, 'um': 5616, 'doubtfull': 597, 'grandfather': 4830, '1jpt78': 106, 'calves': 2585, 'shows': 3439, 'admiral': 5148, 'hyperhelp': 2366, 'lintlibdir': 3742, 'orbiting': 4906, 'jorge': 6344, 'welcoming': 1835, 'e9': 3440, 'varvio': 2097, 'tackling': 3469, 'loops': 2287, 'diphenhydramine': 278, 'cash': 2198, 'wholly': 5819, 'surfaced': 2185, 'bugsbunny': 4811, 'eventually': 264, 'bret': 563, 'questions': 2353, 'i2': 3998, 'mjp': 3131, 'niacin': 1613, 'calculate': 6413, 'mystery': 1663, 'sand': 323, 'garching': 1445, 'redundancy': 6007, 'emitting': 1815, 'dickens': 3791, 'raced': 5541, 'yalanci': 6279, 'circus': 1892, 'hype': 1051, 'defend': 4388, 'c61r0b': 5603, 'shagen': 1425, 'deluca': 3363, 'ferrari': 6057, 'goulet': 457, 'youngblood': 5815, 'steer': 3125, 'lui': 2172, 'detonated': 816, 'xcreateregion': 3102, 'hausner': 6486, 'bumpy': 5342, 'grounds': 2499, 'tomorrow': 873, 'accuracy': 5721, 'confine': 1753, 'cam': 5998, 'gizli': 6380, 'pliers': 5270, 'collider': 260, 'kaiser': 929, 'capacities': 1080, '195': 329, 'husbands': 81, 'socks': 1876, 'parcplace': 3674, 'edimg': 6259, 'max_col': 6015, 'interferes': 6244, 'wrought': 5170, 'attachments': 1161, 'off': 602, 'asynchronous': 4813, 'clubs': 4599, 'kris': 4968, 'grbs': 5178, 'beside': 2016, 'sir': 5377, 'expenditure': 3782, 'veggies': 5849, 'cunyvm': 268, 'jesus': 3112, 'cant': 1383, 'terminus': 4807, 'curious': 5580, 'acsc': 5454, '432': 831, 'santangelo': 1913, 'ineffective': 5307, 'delay': 5676, 'reads': 6242, 'discs': 6493, 'implimentation': 5222, 'turambar': 5263, 'jockeys': 4349, 'charles': 5968, 'litre': 203, 'handsome': 5439, 'lieutenant': 1870, 'cheapen': 4266, 'ecs': 3731, 'cokus': 6143, 'receiving': 10, 'astor': 1324, 'electronics': 4391, '27th': 3317, 'y_': 6184, 'eo': 3411, 'leaked': 4172, 'a1': 2888, 'yu': 6177, '634': 4752, 'consult': 2966, 'unconventional': 6378, 'cowardice': 1407, 'iie': 478, 'hips': 6214, 'garrison': 6226, 'teenagers': 2464, 'hakima': 3218, 'tekig1': 3929, 'cures': 4396, 'infringement': 2255, 'conquered': 4428, 'manning': 3611, 'quarter': 222, '699': 5665, 'fabric': 155, 'affiliates': 34, 'teachers': 4625, 'pmafire': 4654, '512x512': 1473, 'hfd': 1656, 'masks': 4982, 'wonder': 1547, 'norms': 6200, 'q8': 5029, 'sportscar': 1724, 'shipped': 5184, 'sounder': 6278, 'municipality': 1456, 'quibble': 227, '1990': 665, 'tactics': 6313, 'nunn': 3687, 'jiml': 4954, 'averages': 1142, 've7gda': 3918, 'serviced': 1685, 'earnest': 919, 'evolving': 3861, 'edmund': 4222, 'sebil': 2835, 'as010b': 5100, 'antiauthoritarian': 1033, 'she': 3765, 'asc': 3570, 'neal': 3961, 'cavalier': 2780, 'umkc': 5072, 'hybrid': 4449, 'polie': 3876, 'textbook': 5285, 'mdavcr': 2158, 'if': 3988, 'acs3': 5444, 'hereafter': 5499, 'grenade': 1944, '2b5u': 3231, 'checking': 5786, 'summarizes': 3874, 'cruiser': 5524, 'guaranteed': 3645, 'aero': 903, 'manson': 5226, 'stressed': 651, 'karner': 1749, 'dissolves': 4892, '5145': 3756, 'expansion': 3824, 'requirements': 4703, 'mule': 1622, 'dickey': 101, 'overstress': 5304, 'prepare': 3516, 'qj': 5053, 'rjacks': 2634, 'crayola': 3854, 'weak': 1824, '438': 825, 'muhammad': 5707, 'sarik': 299, 'isy': 3902, 'zog': 1394, 'itch': 4297, 'wspdpsf': 1120, '160k': 759, '35i': 5766, 'shouse': 1873, 'salvage': 1943, 'erin': 6406, 'didnot': 3373, 'espn': 2806, 'rigs': 5006, 'uku': 5349, 'tiff': 1747, 'nttcom': 755, 'bothered': 5704, '484': 1607, 'anatomy': 5898, 'pitched': 941, 'labs': 6193, 'examiner': 1228, 'ifn': 6185, 'e_': 3436, '1298': 2549, 'reitman': 5064, 'xlib': 5369, 'sdrc': 4725, 'fj1100': 6309, 'restraint': 2346, 'kee': 1209, '8232': 1124, 'steen': 3122, 'housekeeping': 4046, 'should': 5726, 'rodan': 4024, 'jvncnet': 5496, 'qualify': 5504, 'bson': 2445, 'bonuses': 5147, 'acs2': 5445, 'ntuvax': 6402, 'clones': 2851, 'but': 4480, 'nikon': 6076, 'cereal': 701, 'p04': 4956, 'respect': 5073, 'arround': 233, 'sinful': 4665, 'workplace': 259, 'idols': 388, 'environmentally': 892, 'xtresolvepathname': 2528, 'mathematica': 3526, 'recognition': 613, '4xx': 4511, 'scratching': 4877, 'neurologic': 2220, 'excesses': 1821, 'jacques': 785, 'dartmouth': 809, 'tvga': 1355, 'organ': 4415, '1z4': 1229, 'sheppard': 2316, 'w4711': 153, 'facist': 4466, 'qf': 5049, 'becasue': 942, 'guides': 4776, 'u2': 5593, 'vnews': 4789, 'areas': 4414, 'back': 5709, 'pmf9l0q': 5681, 'fragment': 3251, 'tsing': 4563, 'gadgets': 1946, 'after': 5855, 'stresses': 650, 'conjoined': 3781, 'rainier': 5964, 'chosen': 5684, 'saturns': 4450, 'heb': 5435, 'dwellings': 1199, 'au': 2874, 'foreigner': 1511, 'pharmaceutical': 4394, 'instability': 221, 'deb47099': 3467, 'breakable': 4844, 'delivery': 3197, 'restriction': 2588, 'nottingham': 1274, '269': 3811, 'descending': 2026, 'democratic': 5360, 'creationism': 3153, 'shitload': 5701, 'defragmented': 794, 'nmrdc1': 5289, 'yq': 6174, 'uxa': 373, 'opposes': 1087, 'watserv1': 3833, '194': 330, 'mantick': 4194, '300zx': 4904, 'british': 6033, '765': 3643, 't44': 544, 'eb': 3423, 'moving': 1580, 'discredit': 6246, 'd3ii': 1814, 'waldbronn': 631, 'winter': 2752, '234u': 2433, '763': 3639, 'vetos': 3584, 'selected': 1927, 'brainwashing': 5386, 'goo': 4578, 'translator': 6475, 'hamer': 226, 'xto': 5158, 'secretaries': 3143, 'resorted': 1408, 'respectability': 6049, 'chrome': 2660, 'quarterfinals': 4747, 'sbooth': 4946, 'checksum': 5305, 'disarm': 3535, 'visions': 1029, 'culturally': 3649, 'deporting': 5123, 'statutes': 3701, 'murmurs': 5363, 'fourteenth': 5717, 'summarizing': 3275, 'jimh': 4955, 'highest': 1260, 'entropic': 781, 'jacoby': 2282, 'ferraro': 6056, 'mqr': 2928, 'meaning': 2390, 'yz': 6173, 'buchhorn': 4456, 'gifs': 4640, 'cartwright': 3616, 'gemayel': 3716, 'underway': 522, 'blasting': 2755, 'price': 6053, 'espouse': 3925, 'understanding': 5303, 'manny': 4354, 'famers': 432, 'per': 4316, '340': 1908, 'crosspost': 1264, 'diagnoses': 1459, 'cards': 2145, 'drexel': 2720, 'dblspace': 6215, '1769': 5211, 'nasa': 4948, 'nextmail': 6123, 'roe': 2083, '6eu': 4673, 'soundblaster': 632, 'asp': 3564, 'imagine': 2954, 'demise': 3746, 'lightweight': 2509, 'reckon': 4891, '348': 1911, 'cruelty': 5126, 'stylewriter': 381, 'proudly': 2058, 'zech': 4720, 'glorification': 1701, 'withdrawn': 3269, 'prado': 2644, '359': 5781, '6pm': 3847, 'rac3': 5642, 'pmf9l3': 3242, 'shown': 3434, 'techie': 217, '49': 1238, 'erik': 6407, 'menu': 2628, 'rests': 6434, 'mechanical': 5723, '66491': 3003, 'irc': 114, 'oberg': 3900, 'madvlsi': 6414, 'mimics': 1810, 'ravel': 4451, 'permutation': 761, '1997': 670, 'ofb': 601, 'cleansing': 4862, '0111': 5463, 'hugo': 376, '7x': 5969, 'allegra': 372, 'believes': 2746, 'emd': 725, 'bigfoot': 531, 'advocate': 2358, 'mun': 2000, 'assess': 5802, 'exu': 2977, 'objected': 1246, '6600': 1092, 'criticize': 1002, '9419': 1936, 'applauded': 6208, 'queensland': 959, 'incessant': 1368, 'gretchen': 6467, 'supervised': 6106, 'joystick': 6086, '8h': 4501, 'kung': 6194, 'consultation': 1507, '66': 2839, 'scots': 2175, 'pads': 5225, 'reykjavik': 575, 'sentiments': 1146, 'contingent': 2843, 'jerks': 6072, '150k': 2462, 'surgical': 4820, 'bereft': 4225, 'mean': 6456, 'jeffj': 3300, 'impossible': 3450, '1993may15': 6425, 'otoh': 1978, 'completly': 148, 'record': 5117, 'congestion': 4039, 'telescopes': 2924, 'costs': 2832, 'wehrmacht': 6040, 'fnclub': 1369, 'oppression': 3210, 'tarihi': 928, '264': 3809, 'flavour': 2061, 'rdc8': 6158, 'witnessed': 3540, 'glorious': 4431, 'g3o': 1404, 'ar': 2873, '1982': 4472, 'finale': 2242, '9j5': 648, 'haapanen': 5700, '_____________________________________________': 6016, 'directional': 428, 'tredysvr': 40, 'aaronc': 5362, 'analgesics': 5633, 'hobbes': 3026, 'vuse': 3532, 'darth': 5521, 'prnt': 3612, 'dibble': 4910, 'rational': 6024, 'ppp': 2049, 'circumcising': 3079, 'vojak': 4642, 'consumables': 6491, 'mp': 4547, 'antisemites': 5919, 'ev': 3429, 'wrt': 5492, 'trc': 2337, 'pursuit': 3227, 'clintonites': 3066, 'kok': 4240, '1993': 666, 'shortened': 2341, 'polytchnic': 4178, 'armored': 4729, 'stills': 3877, 'whilce': 3189, 'erich': 468, 'unconditionally': 1392, 'substituting': 4869, 'precautions': 4644, 'twin': 2817, 'pivot': 289, 'illustrator': 943, 'circut': 1893, 'karr': 3589, 'magnetic': 634, 'thyroidal': 4404, 'st1ge': 5548, 'camp': 5209, 'diminishes': 1952, 'samuelson': 5236, 'neatly': 5512, 'regional': 2558, 'fronts': 3848, 'vest': 2921, 'conservative': 3502, 'heels': 3483, 'food': 3557, 'requests': 3285, 'positioning': 2955, 'auspices': 3696, 'diets': 1848, 'jimb': 4959, 'bubblejets': 1851, 'rousseaua': 4887, 'qualcomm': 3786, 'comedy': 521, 'legit': 4425, 'workable': 5865, 'interventions': 1102, 'antisemitic': 1294, '1970s': 5185, 'isr': 3904, 'evils': 4147, 'roc': 2081, 'pagan': 3010, 'hplabsz': 5569, 'zrm': 191, 'causal': 5669, 'reviewette': 5169, '590': 487, 'studied': 2732, 'agnostics': 4867, 'effectively': 4360, 'consuls': 2965, 'ripken': 348, '5616': 2636, 'institutes': 3005, 'dmittleman': 3741, 'irq': 108, 'sbgrad5': 4075, 'meter': 4378, 'fermented': 2348, 'starburst': 5840, 'my': 4550, 'cx_s': 540, 'timmons': 2983, 'ecclesiastes': 5162, '1150': 2685, 'aids': 1329, '8298v': 6460, 'change': 3376, 'slmr': 339, 's_1': 3109, 'sang': 322, 'sight': 3035, 'consubstantial': 4264, 'demonstrate': 5119, 'grammatical': 6089, 'emulation': 5341, 'mug': 1998, 'neither': 3774, 'yard': 1796, 'cvo': 593, 'deeds': 2941, 'ethinic': 3030, '3400': 1819, 'clavazzi': 1070, '1987': 4469, 'ger': 1531, 'steep': 3124, 'repel': 3698, '878': 5552, 'dnd': 42, 'wisconsin': 4880, '6ql': 80, 'riga': 5003, 'shalala': 3408, 'pepke': 5783, 'tracers': 722, 'cze': 5163, 'sybase': 4023, 'philc5n6d5': 5574, 'bnlux1': 5481, 'mcgary': 1262, 'napier': 5448, 'woods': 1, 'wis': 6300, 'fhd': 3856, 'revision': 475, 'tongue': 6392, 'thwart': 4386, 'mcclanahan': 3534, 'gab': 6, 'franklin': 4919, 'shocking': 392, 'straw': 1129, 'dupe': 1982, 'courses': 391, 'anic': 1323, 'ultrasonic': 6338, 'fnal': 6250, '3702': 4983, 'allowed': 5322, 'keeper': 3380, 'suicides': 3382, 'desirable': 5818, 'ksuvxb': 1011, 'supermarket': 2813, 'gentleman': 3283, 'utilizes': 4870, 'hfe': 1655, 'atheists': 2779, 'patent': 3301, 'schuweiler': 1131, 'slaying': 2105, '43y': 819, 'silicon': 5183, 'yajima': 5357, 'nutrition': 6044, 'constantinopolitan': 50, 'meal': 6455, 'jessea': 4975, 'madam': 4418, 'm_': 4530, 'evansville': 4400, 'vitale': 3038, 'veto': 5873, 'ig': 3987, 'boylan': 5488, 'uncivilized': 505, 'mcdowell': 1128, 'kicking': 1211, 'gases': 464, 'christs': 4621, 'buy': 4478, 'asserting': 2370, 'slaughter': 2224, 'egan': 4008, 'zabolotzky': 4907, 'precisely': 6332, 'taoism': 1498, '3401': 1818, 'wilkerson': 1768, 'martino': 4985, 'tiniest': 2382, 'sensors': 2602, 'potholes': 796, 'nerve': 3399, 'sprague': 4, '1500mb': 3598, '0x0': 4345, 'fprintf': 5675, 'bme': 4175, 'nosubdomain': 4588, 'inverter': 1894, 'blades': 1186, 'grinding': 1247, 'oyalcin': 1948, 'happen': 6022, 'breastfed': 76, 'crisis': 2110, 'hour': 1640, 'll5j': 4021, '350': 5780, 'declared': 1541, 'passenger': 166, 'wally': 4228, 'dineen': 1930, 'trusty': 6188, 'around': 5417, '168730': 4964, 'haunt': 473, 'caring': 5384, 'confessional': 1681, 'birmingham': 5250, '2tct': 1089, 'particulary': 3956, 'vessel': 2973, 'window': 3404, 'markings': 1490, 'optilink': 6263, 'veraart': 2589, 'degredation': 6376, 'jmann': 5233, 'deluxe': 4182, 'guberniia': 4446, '4fg': 2937, 'sinfulness': 1158, '95051': 3694, 'tell': 3870, 'rattle': 1345, 'iugold': 2229, 'mathematicians': 4988, 'vernor': 1359, 'prolactin': 1422, 'afg': 4363, 'bullwinkle': 2227, 'saarikoski': 4592, 'garry': 1340, 'tazmanian': 4593, 'model_init_form_view': 3343, 'evasive': 800, 'bust': 5668, 'mathematics': 3528, 'sorted': 219, 'beeper': 3199, 'nwo': 1901, 'debatable': 610, 'stickum': 5391, 'probing': 5066, 'customize': 2309, 'sdsu': 4463, 'hilarious': 5699, 'lipsie': 1275, 'bony1': 3466, 'nasp': 4945, 'intercon': 3322, 'omnipotent': 532, 'fuse': 762, 'uneasy': 6103, 'choppy': 5506, 'march': 3648, 'birinci': 2299, 'zimmer': 5673, 'prostitutes': 2548, 'bastard': 1183, 'erupted': 2962, 'plcc': 5640, 'usda': 3552, 'discourses': 3296, 'diaries': 958, 'hbloom': 2630, 'expensive': 1708, 'neosoft': 3705, 'lmsc': 1319, 'callsign': 2036, 'waffen': 3673, 'andover': 578, 's93020': 5769, 'intermittent': 4146, 'grossman': 5510, '1186': 1884, 'interfacing': 2226, 'afc': 4365, 'bumbling': 4994, 'as': 2872, 'utmost': 3625, 'expired': 6346, 'dyoung': 5967, 'blankenship': 6340, 'sy_': 98, 'tappits': 398, 'formatting': 3293, 'axa12': 2431, 'titanium': 48, 'drowned': 3867, 'aa': 2855, 'kgn': 2717, 'deutsche': 5167, 'diary': 5460, 'kilometer': 257, 'nezareti': 177, 'screened': 1711, 'gpz': 2300, 'already': 4590, 'blaise': 2304, 'perished': 199, 'af': 2862, 'placebo': 1830, 'engaging': 1667, 'excess': 976, 'hiss': 4350, 'nerdc': 2063, 'emr': 734, 'dynamics': 498, '4040': 394, '6q': 2898, 'patter': 6490, 'spain': 5758, 'completely': 6328, 'revised': 2773, 'ab4z': 1871, 'dots': 5240, 'ccoptions': 4730, 'pharvey': 6078, 'cinnamon': 4695, 'dtek': 5449, 'car': 5991, 'madmen': 4247, 'bends': 2946, 'fullest': 6155, '__________': 3082, 'fk': 874, 'paths': 4920, 'cryptography': 5906, 'fhg': 3857, 'plaintext': 4403, 'mainz': 6059, 'cranford': 4938, 'boosters': 1612, 'ramallah': 1832, 'contraceptive': 4492, 'meat': 6453, 'hasty': 5857, 'dissonant': 1298, 'cah': 5996, 'heavy': 1022, 'chasis': 4757, 'fwf': 1627, 'slip8250': 5426, 'jac2y': 1015, 'scws8': 5979, 'pundurs': 3392, 'zrb': 190, 'wouter': 5731, 'roy': 2086, 'watertown': 480, 'rack': 5648, 'l7': 5792, 'jesper': 2342, 'mishra': 94, 'specifies': 4159, 'neat': 3963, 'yv': 6179, 'al': 2868, '8237': 1125, 'knock': 1742, 'debunk': 5368, 'tobacco': 1200, 'championships': 663, 'codebreakers': 365, 'advantages': 867, '01752': 1816, 'mines': 5104, 'parkinson': 229, '1280x1024x24bit': 3600, 'never': 3862, 'energietechnik': 510, '1989': 4477, 'w471': 1693, 'those': 4134, 'selcal': 4387, 'redirection': 292, 'thorne': 4060, '921': 6100, '2plq': 5335, 'defenses': 28, 'uiuc': 2603, 'didnt': 1783, 'm8': 4526, 'djweisbe': 1875, 'mindtool': 1934, 'h3': 2436, '439': 826, 'vhs': 1595, 'theories': 5842, 'revolutions': 2203, 'lydick': 1291, 'bpita': 3613, 'iconize': 2638, 'parsec': 5631, '1020': 3146, 'gem': 1538, '3com': 3194, 'fj1200': 3136, 'dahlen': 4612, '482': 1609, 'jbis': 3738, 'welly': 5206, 'matched': 2771, 'e0': 3447, 'supply': 4283, 'analyst': 1430, 'fim': 70, 'automate': 358, 'jrutledg': 5099, 'cafeteria': 4661, '10000': 6240, 'ashton': 2394, 'kirilian': 1754, 'insults': 2530, 'backhand': 3832, 'aspartate': 176, 'datafiles': 2468, 'liturgy': 6256, 'ac': 2857, 'metabolism': 2144, 'encompass': 3166, 'minute': 185, 'pkcs': 4275, 'barton': 73, '507': 2850, 'gages': 5011, 'cunningham': 812, 'glyphs': 1379, 'slogans': 3077, 'teach': 4881, 'pulls': 5476, 'zapp': 1334, 'jbrown': 2501, 'evolves': 2927, 'chiropractic': 6012, 'ferguson': 4996, 'attract': 1949, 'univeristy': 6461, 'geb': 1534, 'impaired': 4997, 'acoustic': 2845, 'gentler': 783, 'rhetorical': 3045, 'combinations': 1047, 'bringing': 9, 'tekig5': 3932, 'ag': 2861, 'greetings': 914, 'ntfs': 1755, 'bicmos': 406, 'wiring': 5402, 'ej': 3416, 'extraterrestrial': 2729, '3v9f9f9f9f9': 4216, 'andi': 2112, 'dowding': 2272, 'unfinished': 1195, 'truck': 6341, 'afterlife': 4704, '8076': 5442, 'braunschweig': 3307, 'm0dtv5p': 2167, 'falsehood': 921, 'overdose': 4132, 'leakage': 5650, 'toledo': 1697, 'maxwell': 700, 'bahamas': 2605, 'laxman': 3061, 'vernon': 1362, 'gone': 2856, 'gist': 5388, 'arianespace': 3704, 'cryptographically': 993, 'aristotle': 626, 'commissioned': 5989, 'mount': 2909, 'medina': 2389, 'welcomed': 57, 'rosicrucians': 4636, 'victor': 499, 'arabic': 6139, 'defeats': 843, 'bortnick': 4822, 'dialogs': 27, 'xentry': 2127, 'suppressing': 4284, 'aggression': 5136, 'whi': 2472, 'chars': 6219, 'kendigianism': 3452, 'libdir': 1219, 'pennsylvania': 2970, 'iscnvx': 2217, 'supposition': 1523, 'doright': 2575, 'tiered': 1723, 'rendering': 787, 'contents': 708, 'censoring': 599, 'oregon': 6276, 'ask': 3736, 'le': 5747, 'gain': 1256, 'inimitable': 1699, 'hilton': 2427, 'lf': 5741, 'impeachment': 5730, '1145': 6484, 'riots': 317, 'ai': 2863, 'lawyer': 4195, 'damage': 2576, 'asante': 3357, 'hjy': 6249, 'more': 360, 'engagement': 2606, 'inches': 5600, 'gfeygin': 2504, 'willed': 1556, 'mole': 3350, 'twitching': 6442, 'wsnc': 1770, 'bs0tq6': 2398, 'affiliated': 36, 'refute': 968, 'suits': 6284, 'alleviated': 3513, 'bhattacharya': 3174, 'camborne': 5831, 'associating': 1839, '890': 5966, 'mutually': 4795, 'who': 2471, 'firings': 1160, 'validly': 5321, 'pegasus': 2942, 'banding': 3396, 'denominational': 6017, 'ifd': 6181, 'believed': 2748, 'cans': 1384, 'armchair': 2836, '02215': 338, 'bidzos': 4083, 'maximus': 342, 'hurdle': 4398, 'tricky': 1882, 'nguyen': 842, 'eustis': 2846, 'reinforcement': 3200, 'forward': 4326, 'ast': 3568, 'troublesome': 6050, 'heinlein': 2769, 'nose': 4157, 'vizquel': 2196, 'cubic': 4443, 'nermal': 4355, 'rsadsi': 4837, 'coulter': 4237, 'netcomsv': 2673, 'pear': 2969, 'baron': 3689, 'persistent': 6410, 'slipping': 4385, 'm6': 4520, 'hulman': 2516, 'fafnir': 642, 'diku': 6320, '1996': 4031, 'qb': 5045, '637': 4755, 'excerpt': 2034, 'struct': 433, 'walsteijn': 6021, 'ak954': 1738, 'wage': 115, 'fashionable': 238, 'dissolved': 4893, 'organizations': 5990, 'integrity': 635, 'rocky': 5866, 'cream': 308, 'instinctively': 1147, 'b23b': 3580, 'u6': 5589, 'neidecker': 1520, 'possesion': 6248, 'qo': 5056, 'rifleman': 5571, 'saints': 6062, 'assurance': 1500, 'nyongwa': 2041, 'gathas': 4852, 'siberia': 2584, 'untrained': 5201, 'gel': 1539, 'enabled': 6469, 'spacing': 430, 'chopin': 887, 'c5segz': 1154, 'ecf': 3721, 'interests': 4229, 'becomming': 4343, 'psychiatric': 5219, 'uy': 5606, 'clinch': 1618, 'case': 2197, 'wording': 409, 'rubbing': 4136, 'stipulates': 1382, 'uzun': 2335, 'taller': 3796, 'invites': 5752, '6jk': 848, 'videotape': 3897, 'conners': 6302, 'capsules': 5728, 'opened': 3435, 'kevin': 1509, 'e3': 3448, 'separately': 2364, 'tweekco': 211, 'onion': 3181, 'ap': 2871, 'oehler': 1346, '17301': 1675, 'isms': 6118, 'tvtwm': 4239, 'reseller': 1482, 'exact': 184, 'cambodia': 168, 'mb': 4536, 'treachery': 4737, 'communal': 1067, '34l': 1917, 'jc': 4127, 'etsu': 1680, 'jkjec': 1225, '27x': 35, 'consulate': 2556, 'ef': 3420, 'personal': 1317, 'condemned': 5920, 'wagle': 799, 'sgi502': 52, '_believe_': 1974, 'distinction': 3954, 'elwood': 1963, 'skeptical': 2361, 'exterminate': 410, 'vb30': 2497, 'tcora': 659, 'rand': 1658, 'dutentb': 2971, 'dexter': 254, 'uscf': 1342, 'petrich': 281, 'garrett': 1111, 'special_build': 1140, 'hollins': 6379, 'vaccination': 2051, 'buckeridge': 1477, '767': 3641, '480': 1611, 'safer': 1772, 'betrayal': 2697, 'baikar': 911, 'delaying': 3163, 'wrat': 5276, 'odysseas': 3754, 'vessels': 3259, 'extraordinary': 1671, 'poorly': 1289, 'tacky': 1636, '260': 3805, '437': 828, 'ukc': 5351, 'kuleuven': 2902, 'problematic': 2108, 'ruu': 3668, 'vertical': 5379, 'simonson': 402, 'gently': 5715, 'hooey': 5261, 'gnu': 4498, '1146': 6481, 'transistors': 5705, 'research': 395, 'a0': 2889, '196': 332, 'defensive': 5269, 'espy': 2807, 'whiskey': 1431, 'complexities': 6430, 'bowie': 4152, 'harbi': 4733, 'god': 4580, 'unsubstantiated': 880, 'atldbs': 5002, 'djul': 3651, 'biography': 1647, 'relieve': 1444, 'mu': 4542, 'perpendicular': 2367, 'smoggy': 739, 'lga': 5757, 'q_': 5031, 'termed': 5491, 'iplab': 6474, 'manon': 556, 'qt': 5037, 'kellett': 150, 'dmn': 3838, 'forgo': 1573, 'microsoft': 5523, 'patrick': 2219, 'portugal': 1726, 'frustrating': 1840, 'leung': 2397, 'campaigns': 5875, '5500': 1984, 'essay': 3064, 'br1': 662, 'u9': 5584, 'grimm': 3571, 'virtualbinding': 4322, 'ninjaite': 5760, 'padi': 5223, 'tennessee': 1707, 'community': 3013, 'frampton': 1540, 'publicize': 4447, 'mw': 4544, 'jhupp': 3519, 'misnomer': 961, 'vocabulary': 2885, 'rapnet': 772, 'disappointment': 4115, 'helmet': 4764, 'ciceran': 6203, 'micrografx': 1590, 'contradicted': 2243, 'af774': 2116, 'antitrust': 2619, 'carr': 6027, 'gordons': 2622, 'invasion': 6142, 'winqwk': 1657, 'grooming': 1569, 'upbringing': 5562, 'sims': 3025, 'caught': 876, 'anonymized': 4407, 'fung': 3018, 'adrenaline': 5088, 'olvwm': 3095, 'hubcap': 1056, 'histogram': 1255, '64kb': 2028, 'israelis': 1136, 'donahue': 5181, 'keh': 1208, 'bhandari': 4352, 'substantiated': 3591, 'csulo': 6099, 'belarus': 6450, 'mutant': 4849, 'wharton': 5296, 'csc32': 4900, 'plotted': 4926, 'environmentalism': 4872, '358': 5782, 'tort': 3098, 'lee139': 2825, 'barclay': 371, 'defiling': 6287, 'enthusiasm': 1528, '427': 4652, '195116': 6415, 'lamar': 2646, 'x11r5': 3675, 'u5': 5586, 'fifo': 5719, 'gaucher': 4940, 'isluga': 1888, 'bindings': 2418, 'rechenzentrum': 2801, 'beats': 1266, 'lapointe': 5407, '32bit': 1410, 'analog': 427, 'softquad': 5177, 'gambar': 3934, 'miner': 5103, 'demolition': 1648, '1qy': 4448, 'budge': 2434, 'ug': 5625, 'bowmanj': 194, 'assures': 2601, 'purpose': 82, 'vince': 6371, '486': 1605, 'inventions': 6064, 'ax7': 2788, 'capable': 1555, 'physiological': 3217, 'grounder': 274, 'bondra': 3462, 'eighty': 2121, 'end_of_file': 408, 'shy': 3760, 'staal': 527, 'ux': 5607, 'constitute': 1162, 'erlangen': 1098, 'polish': 2213, 'eck': 3728, 'cad': 6004, 'responds': 2503, 'multimedia': 500, 'pauls': 2140, '8cx': 2422, '500mb': 4042, 'geometrical': 4027, 'honorable': 2446, 'ecumenical': 6339, 'graphically': 1106, 'expires': 6343, 'fools': 956, 'kemp': 3377, 'havok': 5973, 'seq': 2993, 'lenny': 1521, 'batman': 1424, 'id': 3986, 'resuming': 1396, 'w8v': 1817, 'mcintyre': 1854, 'xtparent': 927, 'calderon': 1801, 'm7': 4519, 'estate': 1945, 'newkirk': 520, 'qualcom': 5438, 'fund': 3017, 'sams': 4143, 'distant': 1239, 'a9': 2895, 'nhlers': 441, 'ek': 3415, 'deadliest': 2819, 'labtam': 3222, 'inflation': 5985, 'mpd': 262, '1604': 768, 'huge': 375, 'reread': 736, 'picture': 2068, 'peaceably': 401, 'newnham': 4280, 'ministers': 3084, 'shootings': 2107, 'permenant': 3737, 'suppression': 477, 'admd': 503, 'lewb': 3338, 'amplification': 178, 'turpin': 5127, 'dittman': 4809, 'cesar': 3859, 'alpine': 2590, 'nwk': 1902, 'ed': 3418, 'bayonets': 3180, 'provably': 347, 'additional': 1254, '426': 4653, 'hierarchy': 6147, '0m75u': 1268, '607': 948, 'sunset': 3463, 'billings': 545, 'including': 1150, 'reciprocal': 751, 'kerosene': 2067, 'hen': 5436, 'dmv': 3842, 'opic': 784, 'verily': 3515, 'ended': 857, 'jubilee': 3827, 'koc': 4242, 'qv': 5039, 'worth': 640, 'statesman': 297, 'sucks': 1642, 'lubricants': 6283, 'gassing': 3405, 'konstantinoupolis': 5473, 'protein': 1563, 'gchin': 5547, '1776': 1402, 'cgkarras': 896, 'fenton': 5811, 'maps': 1650, 'drawn': 741, 'sects': 420, 'ma30': 2535, 'desjardins': 3400, 'confirmed': 3298, '428': 4647, 'cardiff': 1421, 't45': 543, 'cdac': 4710, '351': 5779, 'uccxkvb': 3291, 'province': 4933, 'approximations': 5195, 'diagnosed': 1464, 'xconfig': 4357, 'healing': 1771, 'guts': 2520, '68060': 930, 'represents': 2593, 'trans': 844, 'blvd': 3088, 'aspirations': 4070, 'simulations': 4667, 'emm': 729, 'resemblence': 1935, 'likelyhood': 1955, 'forth': 3262, 'mvs': 5877, 'skh8': 5904, 'blindfolded': 1790, 'woodbury': 1480, 'affair': 3748, 'rotten': 3697, 'v8': 1117, 'ul': 5617, 'glimpse': 2252, 'wcd82671': 2039, 'llama': 3069, '_the_': 5522, 'mq': 4546, 'memorial': 128, 'cheated': 3358, 'ready': 6243, 'misconstrued': 127, 'beast': 5087, 'q7': 5026, 'places': 5110, 'photometry': 4072, 'moseley': 1095, 'ascend': 3188, 'starting': 4183, 'intellectually': 3145, 'messenger': 639, 'skater': 4053, 'bof': 1470, 'ninja': 1013, 'giles': 820, 'zyxel': 4219, '7i': 5939, 'seder': 2003, 'schreiber': 3278, 'asm': 3576, 'pilgrimage': 711, 'buggers': 2831, 'jakhan': 6436, 'nietzsche': 6459, 'diplomat': 5085, 'aviv': 5332, 'gizmo': 2546, 'isl': 3914, 'down': 1420, 'mvi': 5882, 'acts': 1649, 'dutton': 3394, 'loyal': 5963, 'sami': 4138, 'sheila': 2415, 'trannies': 5503, 'epoch': 3486, 'isnt': 2279, '1183': 1886, 'noticeshell': 5290, 'ptr_obj': 6095, 'axp': 2793, 'withdrew': 1143, 'deviation': 2241, 'for_2': 5500, 'painter': 5079, 'lumpur': 5204, 'up': 5613, 'release_sig': 1722, 'dsav': 3518, 'slapped': 4905, 'girlfriend': 4173, 'pne1': 4336, 'qualifying': 936, 'danielle': 5839, 'i3': 3997, 'jiggers': 1576, 'pedes': 2698, 'calif': 1165, 'aust': 2222, 'vukota': 1377, 'leveled': 2402, 'basics': 5140, 'vette': 2799, 'stauber': 3503, 'bruno': 1823, '1998': 672, 'hojo': 5422, 'nemeth': 5718, 'csuchico': 1589, 'trench': 4831, '193': 335, 'offline': 396, 'affaires': 1751, 'dirt': 974, 'campi': 3309, 'condensers': 2613, 'sqrt': 1233, 'chandler': 4912, 'a87': 5732, 'absolutes': 1776, 'laserdisc': 5981, 'prowess': 4263, 'uphrrmk': 1491, 'wrs': 5493, 'martimer': 3989, '766': 3640, 'regardless': 835, 'jvmk7': 4610, 'startup': 5533, 'audiofd': 2521, 'emi': 731, 'gnd': 754, 'deviate': 5634, 'stompin': 1218, 'spraying': 4102, '10792': 6130, 'vladimir': 6428, 'plugs': 3634, 'weakly': 1391, 'copyrighted': 3465, 'planted': 3141, '0511': 1077, 'impedance': 2852, 'buckley': 3865, 'suburban': 4185, 'checked': 6039, 'branson': 5536, 'quad': 6047, 'loopholes': 6210, 'wyld': 6073, 'impression': 3312, 'layout': 5216, 'cathode': 924, 'ethernet': 6446, 'documents': 3128, 'smug': 3097, 'contemporary': 4098, 'marinara': 4022, 'ironman': 2276, 'drowsiness': 3889, 'container': 2972, 'mannheim': 932, 'commonplace': 2157, 'guis': 3289, 'ducar': 5900, 'cmh': 3890, 'jimt': 4952, 'leverage': 5511, 'pei': 4318, 'skates': 4054, 'pits': 5761, 'zhou': 630, 'lkg': 1115, 'scorch': 529, 'addiction': 4376, 'bor': 1460, 'afford': 2739, 'buf': 4484, 'amerika': 3106, 'shuts': 2824, 'quantitative': 5248, 'sweden': 1804, 'iscsvax': 5109, 'breakfast': 3457, 'lehigh': 6429, 'governor': 3627, 'yogi': 309, 'zubov': 2922, 'advertising': 979, 'spaceship': 3119, 'zrd': 189, 'hzri': 6055, 'xif': 5507, 'pitcher': 938, 'dmcgee': 3951, 'wmxg': 4339, '45th': 96, 'acadiau': 866, 'ak': 2865, 'yields': 5576, 'sec': 3001, 'scotty': 565, '270': 15, 'cwcolormap': 6067, 'fitness': 1585, '1501': 2457, 'jaar': 4406, 'clamp': 4232, '197': 331, 'specialize': 1629, 'danger': 235, 'foot': 3558, 'makefile': 5004, 'impulse': 6136, 'abner': 994, 'gps': 2301, 'schultz': 997, '8306': 1962, 'louisville': 5331, 'budweiser': 4721, 'mdbs': 2, 'universes': 6253, 'sphigs': 4817, 'batters': 3614, '422': 4650, 'rginzberg': 2645, 'newest': 606, 'jul': 4804, 'hpl': 3208, 'bernadette': 2294, 'vigorous': 548, 'else': 3623, 'ens': 4557, 'reduce': 5501, 'ocean': 2021, 'askuser': 147, 'irrigate': 2273, 'targets': 1452, 'diner': 3333, 'proud': 2163, 'tire': 6351, 'cartoon': 2960, 'prizes': 1782, 'exp': 2979, 'osfselect': 5926, 'ei': 3413, 'stuck': 2054, 'audi': 3020, 'memes': 6326, 'ingredients': 1267, 'nutrient': 4181, '1r3jgbinn35i': 2842, 'infusion': 5841, 'gong': 4300, 'nash': 4950, 'totten': 3268, 'maxcol': 3553, 'moines': 1958, 'refrained': 4421, 'loophole': 2130, 'thanking': 204, 'radicals': 1130, 'weapon': 6202, 'ron': 2079, 'associate': 1969, 'crafts': 6144, 'cleanly': 5908, 'with': 300, 'x256q': 641, 'donovan': 1617, 'trips': 306, 'ferriera': 600, 'flattened': 3530, 'enforcer': 1179, 'rites': 4708, '769': 3637, 'mischief': 2233, 'abcd': 4359, 'hamaza': 5325, 'uribe': 1174, 'developable': 1800, 'spokes': 231, 'steadfast': 4108, 'carbohydrates': 596, 'transformer': 3316, 'indiscriminate': 4567, 'adriatic': 5447, 'censor': 1598, 'hogue': 1232, 'colours': 891, 'r80gs': 284, 'agriculture': 3107, 'quitbye': 1226, 'kimura': 265, 'spills': 4130, 'summit': 3062, 'required': 3682, 'xdrawline': 1502, 'francis': 5670, 'recompile': 451, 'externally': 2900, '1985': 4471, 'messing': 5888, 'specification': 4504, '735806195': 5563, 'wquinnan': 5637, 'centripital': 2055, 'divergent': 4495, 'etdesg': 1494, 'uppsala': 1331, 'irish': 5813, 'jnielsen': 5834, 'kev': 1213, 'icing': 5295, 'mbeck': 2507, 'forgot': 1328, 'develop': 906, 'dsinc': 3075, '609': 954, 'robins': 5414, 'ew': 3428, 'humpty': 1201, 'nationals': 6322, 'zur': 4018, '0200': 4838, 'sutcliffe': 3473, 'crow': 4344, 'w1w3s': 1554, 'glue': 3177, 'carrier': 2534, 'vicinity': 4999, 'supercharged': 4444, 'toting': 894, 'crowd': 141, 'tiflis': 2012, 'rookie': 5854, '871': 5561, 'ripping': 5346, 'featured': 6465, 'broadly': 4680, 'mourning': 5874, 'radiators': 4217, 'adcom': 3406, 'rogowsky': 1432, 'mckinnon': 4330, 'wgs1': 1263, 'lgi': 5755, 'hugged': 4379, 'drutx': 1429, '1180': 1887, 'qumran': 4337, 'company': 362, 'anarres': 144, 'flaky': 6312, 'agency': 2515, 'notebook': 3091, 'minutes': 4488, '240at': 595, 'overwritten': 6065, 'c5fjsl': 1992, 'phelps': 3493, '1981': 4475, 'slump': 5602, 'qc': 5044, 'defragment': 4596, 'transferring': 3845, 'infectious': 5012, 'wedding': 4328, 'chicogo': 576, 'kah67': 315, 'landreneau': 5827, 'fibromyalgia': 4783, 'eckenwiler': 6247, 'ifi': 6186, 'delivers': 3198, 'cv4': 586, 'susan': 2277, 'hannu': 624, 'shk': 3767, 'pew': 4314, 'unplug': 5674, 'evening': 1010, '5e9': 3617, 'meng': 2632, 'fw8': 1621, 'proportion': 197, 'being': 272, 'detroit': 1960, 'racially': 3810, '354': 5776, 'bhhr': 3771, '344': 1904, 'pinched': 2696, 'passionate': 1577, 'extraction': 2661, 'ppd': 2044, 'schools': 5175, 'directors': 2247, 'lemay': 2659, '6463': 4180, 'yk': 6161, 'rectum': 5809, 'smorris': 4382, 'bb1t': 2935, 'e6': 3445, 'cousinetc': 2899, 'wrc': 5490, 'roi': 2077, '342': 1910, 'agnosticism': 2101, 'sigalrm': 5697, 'gec': 1533, '601': 950, 'look': 6236, 'millenia': 4028, 'therapy': 6451, 'intestines': 2800, 'rboudrie': 2453, 'toby': 6088, 'prized': 1781, 'illustrate': 699, 'next02cville': 1584, 'fusing': 4676, 'vandals': 2790, 'recognizes': 2432, 'fleming': 5902, 'sadness': 6112, 'opt': 3294, 'commect': 1367, 'specified': 4160, 'extro': 837, 'pep': 4315, 'easteee': 5959, '102811': 1721, 'yn': 6165, 'eric': 6408, 'themselves': 5605, 'vvv': 4632, 'is': 3970, 'jong': 3353, 'munsch': 5928, 'cradle': 1249, 'nukta': 6266, 'arto': 4128, 'spectators': 3679, 'thomson': 2761, 'waving': 311, 'author': 2204, 'newtek': 3784, 'decvax': 1309, 'killings': 5965, 'correlated': 1108, 'marketed': 6290, 'silence': 1088, 'xmgraph': 3209, 'propter': 2944, 'opposite': 241, 'readings': 263, 'xact': 2513, 'bake': 4687, '602': 953, 'wednesday': 12, '70hz': 4261, 'relievers': 4410, 'sizes': 3815, 'rarity': 4615, 'golem': 77, 'tandberg': 5313, 'enlightened': 695, 'bmdhh299': 5686, 'witnesses': 3541, '4366': 2235, 'controlled': 1222, 'rati': 4835, 'yo': 6164, 'decreasing': 1518, 'archangel': 1634, 'internals': 1221, 'rmugele': 5137, 'interfere': 1210, 'elephants': 1497, 'uu': 5609, 'w3s': 6398, 'dma': 3834, 'looting': 4727, 'fvs': 5415, 'sun4nl': 3460, 'pens': 4220, 'im': 3979, 'ip': 3969, 'mountainous': 3306, 'jh': 4116, 'rob': 2080, 'objecten': 1245, 'ib': 3984, 'ignores': 1775, 'bs0tq': 6366, 'ceased': 5824, 'feminist': 2214, 'evolved': 2929, 'sylvester': 4884, 'gospel': 4269, 'extend': 116, '93108': 2109, 'irresponsible': 2654, 'plotter': 824, 'awful': 3246, 'deliveries': 2084, 'xuserfilesearchpath': 78, 'qs': 5035, 'dispite': 220, 'zeos': 130, 'rods': 517, 'schemes': 5869, 'ppm': 2046, 'tno': 675, 'soldered': 6329, 'edvz': 868, 'wooden': 11, 'rossi': 290, 'sequences': 4787, 'sccsi': 417, 'prescribing': 2326, 'ossip': 5515, 'gentle': 5716, 'sass': 2552, 'uj': 5622, '594': 491, 'ripped': 2527, 'cools': 3245, 'reflector': 802, 'faqs': 2289, 'quicktime': 6443, 'services': 1686, 'us': 5614, 'dinosaurs': 54, 'undetermined': 3777, 'reactors': 5472, 'kettenring': 5893, 'near': 3962, 'credits': 3509, 'bijan': 4142, 'fbi': 839, 'flushed': 2070, 'doubledisk': 4659, 'alexandrian': 158, 'sel': 3006, 'everytime': 389, 'id9': 3292, 'contrived': 443, 'fluent': 4061, 'bury': 4017, 'bwsmith': 4613, 'uneducated': 6411, 'earlobe': 3669, 'unzip': 3067, 'trumpeted': 4582, 'gangs': 4149, 'country': 5235, 'runners': 2770, 'care': 6032, 'overwhelm': 2995, 'krupp': 730, 'muck': 618, 'megabytes': 84, 'curse': 5972, 'halandri': 2705, 'ifa': 6183, 'gopher': 122, '1144': 6483, 'phobia': 6229, '32mhz': 1099, 'catastrophic': 3151, 'deserting': 4144, 'equalize': 3090, 'qn': 5057, 'karina': 4635, 'p0n': 4962, 'ruud': 2978, 'excitement': 623, 'bwtwo0': 4766, 'gigs': 807, 'xset': 1278, 'scottj': 566, 'overpriced': 1980, 'uncc': 4718, 'burdensome': 4918, 'humphrey': 1171, '1163': 2502, 'srihari': 1526, 'cline': 2933, '356': 5774, 'caveats': 2905, 'honors': 6288, 'argentina': 4873, 'yuval': 4779, 'astrophys': 4258, 'latest': 6213, 'hc11': 497, 'shaman': 4278, 'giga': 810, 'curiosities': 3351, 'aron': 6360, 'guarantees': 3647, '1760': 5213, 'meth': 5696, 'stocking': 2986, 'paige': 803, 'binghamton': 4164, 'arguing': 1517, 'ximp': 6138, 'sketch': 1085, 'o22': 3706, 'joakimr': 1872, 'surplus': 2798, 'cuts': 4065, 'kaliski': 2948, 'defining': 4993, 'ue': 5623, 'wavelengths': 2759, 'toxicwaste': 782, 'visitor': 3936, 'national': 4420, 'medraut': 5246, 'persistently': 271, 'sunconnect': 2675, 'serve': 4598, '5980': 5, 'bks2': 5495, '8c_': 2424, '1991': 664, 'qw': 5038, 'tags': 3282, 'audacious': 2379, 'bulf': 967, 'gigabytes': 1678, 'sinning': 2938, 'diffie': 426, 'winhelp': 2354, 'incidents': 3386, 'nuts': 680, 'chatterjee': 895, 'precident': 652, 'studley': 5405, 'ext': 2976, 'u3': 5592, 'nightmares': 4616, 'inject': 4163, '34211': 4489, '874': 5556, 'dnet': 1662, 'exploiting': 2365, 'oxide': 5843, 'swap': 1280, 'grove': 2620, 'tamuts': 5672, 'ww1a': 1692, 'ucla': 4124, '265': 3808, 'jrl': 986, 'specialty': 6267, 'cropping': 5336, 'lubed': 5257, 'carried': 2532, 'boulevard': 5347, 'indecent': 6037, 'umontreal': 1419, 'crossposted': 4007, 'commodore': 6087, 'expos': 2024, 'parsons': 2246, 'wgn': 3257, 'aeon': 512, '1994': 669, 'transferred': 879, 'districts': 4698, 'jupiter': 1409, 'surest': 3529, 'elsewhere': 5599, 'accountable': 4148, 'automatic': 1799, 'rightfully': 3792, 'reese': 1397, 'inflated': 3524, 'rendezvous': 4562, 'f550iw': 3887, 'registration': 2641, 'serval': 1750, 'equated': 4802, '1877': 3583, 'exist': 2707, 'velapold': 931, 'bnc': 5256, 'schaeffer': 3295, 'armenia': 1826, 'supremacy': 3390, 'spanking': 2478, 'i2c': 3024, 'romeo': 2512, 'vlasis': 6104, 'pnei': 4332, 'elbow': 4038, 'injections': 4507, 'r8f': 5822, 'sans': 320, 'yoyo': 3319, 'patch': 107, '1r_q': 2444, 'thunder': 5145, 'sided': 3059, 'kolb': 5421, 'cwd': 4392, 'agendas': 2751, 'wacko': 3562, 'diety': 1846, 'iq': 3968, 'pobox': 2100, 'keyword': 3922, 'motto': 1365, 'veneras': 2808, 'whereby': 765, 'harmon': 208, 'cyberpunk': 2490, 'j3': 4084, 'carolinafan': 6081, 'metz': 5694, 'institutionalized': 2057, 'csulb': 6096, 'oldenburg': 6358, 'panicking': 1706, 'deg': 1975, 'gauntlet': 1551, 'sublet': 4133, 'fiat': 4883, 'rum': 3661, 'tnet': 2177, 'hammond': 713, 'sase': 2553, 'cochrane': 2688, 'akin': 6440, 'shm': 3769, 'bon': 1465, 'mcl': 3204, 'noxious': 528, 'brock': 3920, 'butts': 5745, 'ahmet': 92, 'sayeth': 1802, 'trains': 2833, 'slc4': 3341, '1993may13': 6420, 'presently': 1761, 'ems': 4393, 'adjusting': 4327, 'assigned': 1398, 'wc_c': 6404, 'sjsu': 1638, 'torturing': 2706, '1986': 4468, 'porting': 2505, 'corvettes': 3855, 'conlon': 4095, 'uterus': 1758, 'turned': 234, 'ez': 3426, 'instructors': 3033, 'forgiven': 3186, 'dictionaries': 6386, 'staring': 583, 'spl1': 1620, 'ent': 4558, 'compartment': 4243, 'assisted': 458, 'promising': 1558, 'indulge': 2834, 'apparent': 2740, 'desireable': 5112, 'emu': 733, 'camel': 2518, 'salvatore': 5550, 'accredited': 1787, 'rlward1': 1785, 'crown': 143, '33': 258, 'epson': 6102, 'disrepute': 5291, '0751': 6122, 'reflected': 3581, 'filling': 4574, 'dair': 1240, 'bittle': 1014, 'anes': 5952, 'cap': 5992, 'dmc': 3835, 'tobit': 6416, 'jimd': 4957, 'hunch': 3866, 'burr': 4016, 'hed': 5433, 'adresses': 3374, 'qa': 5043, 'swerving': 3220, 'bugger': 1981, 'distance': 6468, 'fully': 5771, 'hardened': 6218, 'disconnects': 2689, 'advancement': 137, 'distraction': 419, 'yearly': 5383, 'qd': 5047, 'terje': 4353, '1539': 6293, 'w3q': 6396, 'factorization': 2325, 'fischler': 4467, 'clobbered': 6489, 'emirates': 404, 'shx': 3759, 'inquisitors': 6090, 'arch': 2731, 'balcony': 2511, 'mterm': 6227, 'fid': 64, '34s': 1924, 'revolve': 4179, 'cosar': 611, 'sram': 5230, 'interactions': 3108, 'hail': 1865, 'tutorials': 1290, 'tempted': 103, 'oueichek': 1113, 'ms': 4548, 'anew': 5953, 'novber': 5317, 'fin': 68, 'mbell': 3276, 'egret': 6311, 'lhdsy1': 585, 'rapes': 157, 'rhode': 5754, 'thorn': 1889, 'std_disclaimer': 3334, 'borland': 2393, 'gsusgi1': 2173, 'eosvcr': 3851, 'greenbelt': 1414, 'nmsu': 3707, 'welded': 5470, 'constituted': 5329, 'jafoust': 5381, 'grahamt': 1063, 'brussel': 855, 'cocaine': 5151, 'eavesdropper': 1416, 'berlin': 1303, '8229': 4930, 'corriveau': 3015, 'pharmacy': 4638, 'ogrodnick': 5525, 'asshole': 5015, 'clunie': 6349, 'today': 2114, 'kbs': 4989, 'evangelical': 1718, 'flight': 2338, 'bosom': 1025, 'annexed': 4371, 'founding': 2318, 'merle': 3872, 'ballistic': 4595, '1600': 766, 'routes': 6444, 'boo': 1466, 'interpretations': 2194, 'mcgwier': 724, 'reflection': 3794, '486sx': 5978, 'maintenance': 3620, 'metric': 5478, 'sarima': 3607, 'freebie': 878, 'env': 4559, 'zuo': 4020, 'sauce': 383, 'daydream': 643, 'macedonian': 5220, 'wannabe': 5914, 'shielding': 2557, 'appeasement': 5863, 'monash': 4049, 'assigns': 269, 'get': 1532, 'propellants': 125, 'vesikalarla': 5957, 'hee': 5434, 'iqvg': 2560, 'servicing': 2721, '3570': 2492, 'iraqis': 1570, '0112': 5462, 'unipd': 2695, 'builders': 3521, 'fij': 66, 'insistence': 3965, 'gee': 1535, '01wb': 758, '1993may17': 6424, 'intolerable': 2285, 'ccmail': 2547, 'avinash': 4970, 'nysernet': 5469, 'dgbt': 1672, 'q1': 5020, 'etrat': 369, 'fluctuations': 2381, 'heavens': 6289, 'eroded': 779, 'ibid': 502, 'andrewm': 4840, '320x200x256': 5737, 'bub': 4483, 'bevans': 1682, 'seperately': 2293, 'sparc2': 1492, 'interior': 1513, 'boghos': 3202, 'superman': 2150, 'q5': 5024, 'coplex': 3779, 'bell': 435, 'break': 3892, 'hugh': 377, 'jaeger': 3860, 'fp': 863, 'kahn': 3517, 'pspod': 1485, 'gregmeister': 4821, 'vill': 6357, 'conflagration': 5753, 'killed': 4071, 'dam9543': 5912, 'consider': 4427, 'malachi': 6409, 'genesis': 88, 'turanist': 1159, 'shu': 3758, 'dchan': 5804, 'tories': 2125, '7vz': 744, '80000': 2017, 'measurable': 1451, 'keithley': 2735, 'desmond': 6043, 'servo': 4597, 'e1': 3446, 'flawlessly': 3461, 'hastings': 926, 'painted': 5078, 'believer': 2745, 'finou': 5915, 'truman': 2597, 'ankara': 5485, '34t': 1920, 'ermeniler': 6364, 'output_build': 2291, 'plunged': 5160, 'recreation': 386, 'cooperation': 740, 'quadratic': 5005, 'slash': 3658, 'parslow': 4402, '734981805': 1004, 'belated': 4171, 'lifes': 4746, 'mh': 4539, 'solder': 1486, 'cab': 6001, 'pettefar': 213, 'monitors': 864, 'newman': 5687, 'atlanta': 3159, 'sardis': 4282, 'bummer': 2193, 'bottleneck': 4189, 'protect': 4618, 'explaining': 4334, 'bandied': 5932, 'calkin': 5644, 'vigorously': 2073, 'slc5': 3342, 'scenes': 5889, 'ethical': 3945, '598': 495, 'escapes': 1779, 'rims': 2002, 'a3': 2890, 'considering': 1553, 'empty': 1064, 'entryway': 4064, 'transmission': 5646, 'i8': 3994, 'annex': 2886, '524737': 1386, 'fifties': 2493, 'chosing': 2352, 'mailboxes': 1135, 'chain': 173, 'y7': 6156, 'defroster': 4639, 'enemies': 5264, 'cast': 2199, 'mash': 5451, 'fix': 61, 'sharon': 3117, 'differentiate': 1679, 'wccnet': 5094, 'iifx': 5121, 'tekig6': 3930, 'obviously': 1071, 'shoppa': 5803, 'retailer': 1748, 'decrypting': 5955, 'extension': 5108, 'dismantling': 403, 'kem': 1207, 'erics': 470, 'twit': 2816, 'sunlight': 2053, 'totalitarianism': 2295, '1993may11': 6422, 'mpeg_play': 2263, 'foul': 5132, 'nutcase': 3624, 'breastfeeding': 3933, 'n8wed': 1069, 'nrsv': 255, '1qr': 2930, 'audience': 4155, 'spicy': 1592, '9f9f9f9f9f9': 5662, 'benz': 2296, 'hinduism': 3653, '153005': 3288, 'ld_run_path': 2506, 'retaliatory': 469, 'truecolor': 1932, 'tulane': 2142, 'adolescents': 2678, '6uin': 2031, 'aj': 2866, 'brinich': 2267, 'shuttle': 4441, 'laurie': 4374, 'oses': 5788, 'stephan': 2458, 'stlombo': 3554, 'sirtf': 3599, 'wrap': 5274, 'encouraging': 1970, 'flocks': 2830, 'screaming': 60, 'gaul': 5913, 'defensively': 1516, 'bless': 1019, 'ireland': 4286, 'procuracy': 1807, 'warfare': 5712, 'somalia': 4036, 'andy': 2113, 'alamo': 4641, 'confidential': 3536, 'monza': 3610, 'cipher': 555, 'diligent': 6362, 'relegated': 6394, 'officially': 934, 'squashed': 2141, 'eyedness': 4516, 'iix': 476, 'tappara': 6008, 'dune': 3569, '34j': 1919, 'beirut': 4088, 'condoned': 431, 'het': 5427, 'gov': 4584, 'oml': 1360, 'ihl': 3114, 'breech': 1852, 'eurocrypt': 5770, '1mu': 3480, 'lips': 1086, 'organs': 1037, 'approving': 200, 'pext': 1189, 'manifested': 3271, 'remarked': 2075, 'ronzone': 4011, 'earring': 6108, 'pjs269': 6077, 's17': 5301, 'oceanography': 1371, 'chzv': 5356, 'hosted': 3254, 'weighing': 5062, 'raining': 5131, 'crick': 2426, 'irs': 109, 'critisism': 3773, 'transplant': 1471, 'n9myi': 5529, 'incompatability': 1062, 'jplpost': 1850, 'enforces': 1180, 'set': 2991, 'nalbandian': 944, 'loosing': 1562, 'uoft': 2559, 'fest': 5921, 'bounces': 4923, 'calmed': 4791, 'gastrointestinal': 3884, '875': 5557, 'joan': 4161, 'named': 5568, 'appears': 3375, 'nary': 1145, 'moorcockpratchettdenislearydelasoulu2iainmbanksneworderheathersbatmanpjorourke': 3676, 'mora': 359, 'benowitz': 1619, 'q4': 5025, '28th': 6252, 'american': 1027, 'turner': 237, 'airspace': 1132, 'recommends': 2848, 'sophocles': 4570, 'sara': 6369, 'b8f': 792, 'crchh410': 2693, 'distracted': 1591, 'u0': 5591, 'ruf': 3663, 'pitches': 939, 'replying': 1890, 'lord': 5159, 'subdirectories': 3879, 'ofm': 603, 'osteopathic': 5046, 'hosts': 2522, 'jgarland': 2681, 'nmr': 3506, 'whereabouts': 4109, 'married': 2487, 'diaspar': 2650, 'mccreary': 5283, 'nunnery': 0, 'fur': 5139, 'hepatic': 5945, 'cunneyworth': 1137, 'wrath': 5348, '8238': 1126, 'isometric': 5929, 'sheild': 2417, 'resubmittion': 5970, 'unicity': 1032, 'awesome': 5320, '50s': 2916, 'xpm': 2375, 'mitch': 3280, 'lucy': 3891, 'antichrist': 513, 'tcmay': 4208, 'cimv': 1192, 'invents': 2132, 'hela': 6149, 'fueled': 206, 'solves': 2723, 'jerky': 6074, 'offerman': 3287, 'lambada': 5280, 'idiocy': 3549, 'ambient': 2823, 'jazz': 2171, 'docks': 4153, 'trying': 5171, '873': 5559, 'charging': 4560, '870': 5560, 'lifted': 5868, 'sucked': 5498, 'island': 4358, 'milt': 1579, 'needed': 86, 'practicing': 552, 'nagasiva': 2004, 'lk4': 1123, 'koala': 6205, 'concensus': 757, 'paid': 3072, 'elliotte': 1152, '697': 5659, 'sucker': 5494, 'geva': 65, 'sez': 2996, 'enabler': 6470, 'nextstep': 4878, 'gaskins': 5017, 'steed': 3123, '4b': 1271, 'best': 2640, 'matches': 2766, 'slated': 4972, 'f67709907': 2985, 'generous': 3178, 'rate': 4834, 'ia': 3983, 'minivans': 4705, 'im4u': 971, 'howdy': 1954, 'kimeldorf': 5844, 'anachronism': 2278, 'crackdown': 5595, 'glocks': 1709, 'rats': 4833, 'semetic': 6093, 'gripes': 2703, 'computational': 3043, 'pushing': 4971, 'catfish': 2206, 'exe': 2974, '8500': 5343, 'euro': 5564, 'surgically': 5364, 'ecc': 3723, 'designed': 4056, 'joplin': 2388, 'ripper': 2529, '44272': 1250, 'cb900c': 1028, 'nswc': 5218, 'unrest': 963, 'backs': 2385, 'ray4': 4058, 'hyatt': 47, 'druce': 2215, 'selves': 3403, 'squalor': 242, 'dicker': 483, 'rnd': 5942, 'withrow': 5905, 'behnke': 4454, 'a6': 2894, 'infections': 2794, 'qtct': 3339, 'f1g': 6333, '34f': 1915, 'etxmst': 519, 'irulesrc': 2716, 'standardized': 5157, 'distress': 2336, 'bname': 753, 'truthfully': 6038, '357': 5773, 'six': 4377, 'thoughtful': 5825, 'qr': 5036, 'polluting': 5654, 'masculine': 1759, '___________________________': 4100, 'vaticanus': 6010, 'routinely': 5090, 'dleonard': 5661, 'feminine': 1428, 'xt350': 862, 'utter': 2479, 'avery': 2566, 'deportations': 5239, 'speculate': 5497, 'consequences': 3747, 'cac': 6000, 'administering': 660, 't1': 3971, 'rockefellers': 4528, '74140': 3137, '635': 4753, 'ep': 3431, 'ruffinen': 3135, 'irl': 110, 'interactive': 4251, 'histories': 4101, 'postulate': 2608, '8797': 628, 'kgb': 2711, 'oncoming': 1083, 'nafb': 5796, 'bdrc': 5120, 'shz': 3761, 'rchland': 714, 'tertullian': 1933, 'direct': 1925, 'expelled': 5936, 'point': 1705, 'nitty': 5308, 'flattening': 6192, 'ancients': 4105, 'pariah': 4773, '630': 4748, 'links': 1144, 'manor': 554, 'tolerate': 4291, 'salesdroids': 2033, 'azerbaijani': 3992, 'sex': 2997, 'asd': 3572, 'obesity': 3071, 'ec': 3422, 'keywords': 5903, 'ahead': 3542, 'oft': 605, '274': 19, 'physics': 1042, '9995': 2038, 'samsung': 1270, '199': 327, 'loop': 6238, 'terrorists': 462, 'abus': 2792, 'xrcjd': 5401, 'expel': 5058, 'armies': 851, '9f9f9f9f': 3821, 'entire': 1764, 'ls400': 5249, 'weaponry': 4491, 'tng': 674, 'bellow': 135, 'meteorology': 702, 'prohibits': 3127, 'yh': 6160, 'endowment': 1983, 'pierce': 4288, 'cruzio': 5962, 'ship': 3485, 'fil': 69, 'chaim': 172, 'forerunner': 2311, 'cute': 4063, 'postcript': 3369, 'rna': 5941, 'seattleu': 4816, '1152x900': 2847, 'uupcb': 3775, 'felony': 2648, 'boards': 1139, 'rnk': 5937, 'noteworthy': 6352, 'el': 3410, 'matusevich': 2368, 'outlines': 5689, 'machism': 4850, 'eq': 3430, 'citadels': 4299, 'ql': 5055, '1993may12': 6421, 'reliability': 6114, 'deploy': 6342, 'negev': 2256, 'powerbooks': 205, 'stupidity': 3878, 'stevens': 6036, 'authoring': 4743, 'macros': 1204, 'spaceman': 2349, 'robotics': 4744, 'zri': 1050, 'icomsim': 1252, 'willner': 2488, 'xmgr': 5091, 'january': 6018, 'shifting': 2699, 'gaseous': 793, 'extender': 1567, '68124': 4104, '486s': 5692, 'ivan': 5577, 'kwolfer': 558, 'blaring': 4074, '2626': 4886, 'machnik': 4481, '341027': 5378, 'outreach': 4793, 'tartars': 5299, 'savior': 3686, 'row': 2088, 'hologram': 706, 'perpetuating': 4120, 'phrasing': 1641, 'c5huh1': 6026, 'trinitarian': 4290, 'binary': 5400, 'egyptians': 2920, 'makeshift': 1068, 'gen': 1537, '1995': 668, 'actual': 1138, 'syck': 1664, 'webb': 3328, 'transmitters': 3110, '486sx25': 860, 'uug': 2334, 'scsiha': 5722, 'chorley': 5604, 'drozinst': 2052, 'ajteel': 1560, 'oblivion': 6098, 'ok_line': 465, 'mappings': 1184, '081': 1437, 'racer': 5543, 'touchy': 243, 'alone': 6228, 'mahomes': 5032, 'oklahoma': 2554, 'generation': 2784, 'repentance': 5987, 'void': 1282, 'zterm': 2435, 'congratulations': 161, '071': 5244, 'qk': 5052, 'verses_': 5202, 'wasps': 3314, 'carthage': 6400, 'engineering': 5393, 'qy': 5040, 'africa': 1630, 'oboe': 3352, 'deragatory': 146, 'managing': 2181, 'dropped': 4702, 'levels': 3021, 'silicone': 2331, 'fulfilling': 2380, 'whl': 2470, 'isotropic': 1169, 'rolls': 3672, 'cfnr': 4187, 'jnmoyne': 1838, 'collision': 1645, 'uu2': 2329, 'hamishmar': 5733, 'dupont': 732, 'iso': 3911, 'basel': 6353, 'fwi': 1625, 'pinky': 5398, 'militello': 3266, 'pseudocollisions': 2270, '605': 946, 'uprising': 4212, 'iterated': 5063, 'starving': 5416, 'lone': 2376, 'recorder': 3504, 'funded': 5306, '0005111312': 1273, 'shower': 5197, 'hindsight': 5835, 'goldin': 5749, 'stty': 3160, 'winded': 6427, 'shavlik': 4092, 'ecg': 3720, '80at': 4129, 'undergrad': 3148, 'inflatable': 905, 'colormapped': 5539, 'mushrooms': 3826, 'uscrpac': 2570, 'tab00': 2656, 'samson': 4874, 'paying': 4759, 'deserve': 2239, 'manslaughter': 4832, 'indians': 3233, '1980': 4474, 'ppb': 2043, 'w24e': 2961, 'vuw': 267, 'parallel': 1951, 'tnt': 4026, 'bigger': 4875, 'epas': 2098, 'zrmc': 4987, 'prefered': 2777, 'armenie': 1825, 'card': 6031, 'rationalism': 1299, 'slipped': 2956, 'esther': 4825, 'begets': 3603, 'gaskets': 14, 'dodger': 5461, 'cyclones': 4626, '60w': 957, 'predicted': 2176, 'marble': 4210, 'brader': 2178, 'extrel': 1467, 'strange': 6377, 'wonderfull': 849, 'klonopin': 5790, 'antti': 6485, 'swam': 1276, 'concede': 5387, '0123456789': 3368, 'wacky': 3560, 'got': 4583, 'oriolefan': 715, 'voters': 3628, 'opponents': 5152, 'lusky': 352, 'sherron': 244, 'cattell': 5198, 'attracts': 2586, 'isa': 3916, 'gaut': 5911, 'quirk': 5258, 'stillwater': 4623, 'agony': 5851, '352': 5778, 'fusi': 763, 'quan': 6046, 'sgberg': 1637, 'solidarity': 5679, 'function': 3195, 'overheard': 1947, 'yy': 6171, '1777': 1401, 'end': 4552, 'wodziak': 4671, 'loyalties': 5176, 'rooi': 1304, 'violated': 4739, 'ooops': 1020, '5888': 3165, 'hotter': 3347, 'psychoactive': 6268, 'bunkers': 4508, '1993may10': 6423, 'surrounded': 6189, 'person': 871, 'drifting': 2950, 'pb160': 3192, 'barnaby': 3670, 'filing': 4908, 'wynn': 247, 'brookpark': 2312, 'geosynchronous': 1599, '1993apr06': 4629, 'rui': 3659, 'sqmv': 460, 'concerted': 5763, 'primality': 5059, 'abnormalities': 3456, 'yuca': 6134, 'ad': 2860, 'ken': 1206, 'competently': 5526, '98121': 2702, 'jus': 4806, 'r_tim_coslet': 2006, 'recordings': 5340, 'dwelling': 3883, 'jimc': 4960, 'precious': 3776, 'y2': 6153, 'printf': 1940, 'ped': 4319, 'thanos': 6109, 'disputes': 693, 'based': 6350, 'thruster': 6045, 'mirsky': 2649, 'bucky': 6373, 'warmly': 5514, 'cosmological': 4856, 'cx_g': 537, 'conspirator': 3626, 'lazer': 6308, 'roos': 1307, 'staub': 5118, 'materialism': 4965, 'fourteen': 1795, 'ei0mfq': 4688, 'oops': 4445, 'sides': 3060, 'diagnostics': 5018, 'droplet': 3212, 'narrowed': 5074, 'horowitz': 4006, 'ecq': 3733, 'rgbquad': 5203, 'nail': 1926, 'uk': 5621, 'jp2': 1337, 'rohm': 5102, 'bizarrely': 2883, 'coons': 1301, 'babak': 737, 'bozo': 2455, 'ye': 6169, 'baptists': 1296, 'staggered': 5706, 'jmeritt': 6277, 'automatically': 1418, 'advertisement': 270, 'sed': 3000, 'confines': 3022, 'klosters': 1777, 'uu4': 2327, 'darin': 4742, 'ay': 2878, 'xand': 1450, 'boil': 1805, 'similar': 1100, 'scrollbars': 678, 'sympathies': 2963, 'donna': 1411, 'aips': 5961, 'mcovingt': 907, 'b8e': 790, 'hplabs': 2616, 'je': 4119, 'goa': 4581, '90405': 3048, 'concludes': 2405, 'diffuse': 5390, 'advocated': 6314, 'massacring': 3454, 'kiefer': 2128, 'sightings': 2359, 'laird': 5440, 'bubba': 2949, 'bitblaster': 2407, 'a2': 2891, 'appropriations': 1704, 'rscharfy': 7, 'takeoff': 4686, 'brett': 380, 'p12': 1155, 'wisdom': 2609, 'chongo': 5683, 'tew0': 6128, 'wg2': 3263, 'e2': 3449, 'mayer': 239, 'ailin': 5122, 'gondwana': 5852, 'safeguards': 5412, 'bloom': 4214, 'verbose': 2919, 'wake': 1557, '1876': 3582, 'bagwell': 1639, 'presupposes': 1093, 'ctrl': 5397, '347': 1907, 'bedfellow': 4197, 'disparaging': 286, 'orange': 4992, 'mailings': 32, 'kravchuk': 345, 'bounding': 4963, 'exposed': 923, 'wherever': 2733, 'conditional': 5420, 'survivors': 5173, 'boeing': 3094, 'antithetical': 1479, 'scrollbar': 614, '877': 5555, 'majors': 1453, 'tdatirv': 6048, 'celse': 2136, 'onwards': 983, 'contingency': 5509, 'curiously': 560, '42m': 4658, 'census': 4657, 'haines': 5885, 'i18n': 4131, 'mulder': 5419, 'output_info': 5772, 'mongoose': 4774, 'reddy': 5549, 'uuencode': 3216, 'nimbus': 4207, '96': 2347, 'create': 4285, 'armen': 4643, 'karlsson': 786, 'charge': 2268, 'caldwell': 5293, 'forty': 3258, 'nmt': 3505, 'imagined': 250, 'lpt1': 1728, 'atase': 5513, 'quilty': 808, 'outlined': 5685, 'cytoskeleton': 1433, 'mythical': 6307, 'jpeg4': 6359, 'uwindsor': 1478, 'abuses': 305, 'payments': 1244, 'yj': 6162, 'alliance': 3193, 'sanjay': 4202, 'workbench': 2489, 'enclosure': 3895, 'alignment': 4303, 'drastically': 2165, 'created': 5878, 'nesbitt': 980, '1198': 2211, 'draws': 738, 'artc': 4126, 'otol': 340, 'nonlinear': 4836, 'fir': 58, 'stoves': 1730, 'frequent': 1505, 'fleury': 3531, 'mass': 5452, 'ogi': 4401, 'centering': 4607, 'benchmark': 3702, 'intelligent': 3101, 'h0': 2438, 'psize': 2290, 'sensational': 280, '1444': 2690, 'describing': 6255, 'sen': 3004, 'coloring': 4411, 'previewer': 188, 'chiron': 970, 'leadoff': 2201, 'admirals': 5916, 'addison': 4287, 'sakigake': 4067, 'jgfoot': 2463, 'sovereign': 788, 'sword': 3712, 'controlers': 5115, 'PAD': 0, 'u38134': 687, 'macbinary': 3093, 'examples': 4310, 'spacelab': 287, 'ya': 6166, 'xgiz': 349, 'monstrous': 2491, 'warships': 4399, 'consisted': 1572, 'malakhov': 3850, 'floyd': 4851, 'win': 6296, 'ingrained': 1652, 'slang': 2897, 'ecp': 3734, 'priesthood': 2131, 'c5lgaz': 3044, 'repost': 3315, 'taurus': 5288, 'jim': 215, 'depositing': 5179, 'udpa': 4383, 'in': 3982, 'dzk': 6105, 'mprgate': 4245, 'der': 4682, 'nicholls': 454, 'freezes': 6009, '762': 3638, 'cointelpro': 1023, 'cashman': 4333, 'holiness': 6418, 'raytrace': 5311, 'memmedov': 253, 'delaware': 6389, 'elvis': 902, 'downward': 461, 'ey': 3424, 'streamlined': 3149, 'secular': 416, 'hextall': 459, 'belen': 444, 'tricks': 314, '6_': 2918, 'kbos': 5016, 'sulfur': 3753, 'reflux': 4697, 'analyses': 5107, 'torrey': 6327, 'achieving': 4205, 'held': 6148, 'desqview': 1339, 'romans': 1504, 'topped': 5960, 'drafted': 1053, 'therein': 2371, 'ryerson': 5149, 'untrue': 4419, '6ej': 4674, 'philosophers': 940, 'highlights': 5864, 'pimentel': 2174, 'nakhchivanik': 811, 'cheshire': 5374, 'pfuetzner': 4356, 'probability': 3579, 'her': 5430, 'teaching': 5298, 'h5': 2440, 'famine': 3468, 'crynwr': 2854, 'periodicals': 637, 'macdonald': 2682, 'zeta': 5101, 'wangtek': 1586, 'sbcs': 4193, 'cuba': 2483, 'periphery': 5266, '60k': 960, 'hoax': 6241, 'gfci': 2940, 'radiophysics': 2989, '1536': 6292, 'reston': 5846, 'pee': 4320, 'scheifler': 2408, 'blamed': 3308, 'tweaking': 4913, 'cosy_pak_09': 4019, 'abuser': 304, 'i4': 4000, '1165': 2500, 'quoting': 1474, 'night': 780, 'dynasty': 1900, 'shifters': 4188, 'ikos': 1046, 'nieuwendyk': 4170, 'controller': 1223, 'grubbing': 5474, 'christen': 6367, 'absurdities': 136, 'israelites': 5116, 'zenith': 6079, 'ntaib': 5086, 'zionists': 1101, 'x6127': 4689, 'medical': 3051, 'inescn': 6028, 'pedophile': 1499, 'a4': 2893, 'describes': 3619, 'reactor': 2624, 'markc': 3543, 'boy': 1458, 'can': 5997, 'qs7': 4158, 'easiest': 2741, 'hpp': 3206, 'c4wkbp': 1344, 'helpful': 5095, 'august': 1550, 'xarchie': 1073, 'edison': 1767, 'gnv': 750, '1z_': 1237, 'effectiveness': 4605, '6700': 4271, 'timers': 5168, 'quantize': 1844, 'encoding': 1006, 'newbies': 5751, 'crphilli': 1836, 'transition': 870, 'predestination': 1423, 'release': 5703, 'emg': 4380, 'xjs': 4002, 'ends': 5742, 'andreasa': 1812, 'skinner': 4093, 'fwb': 1628, '1993may18': 6419, 'mo': 4537, 'metacard': 3622, 'jester': 3372, 'ccitt': 3545, 'husak': 6127, '6ei': 4675, 'hpk': 3207, 'moustic': 3346, 'bglenden': 2519, 'ranked': 2594, 'aem': 573, 'mentorg': 132, 'abdullah': 187, 'stubborn': 1643, 'casbah': 770, 'evanston': 3318, 'servotronic': 798, 'alphacdc': 439, 'swartzjh': 981, 'resumed': 1168, 'inbuilt': 2990, 'soaking': 3885, 'bigal': 198, 'jammers': 2908, 'congenially': 3935, 'hogging': 5746, 'atmospheric': 4436, 'wheelies': 5977, 'rvenkate': 4086, 'lava': 1564, 'savage': 6254, 'pipeline': 2369, 'seating': 282, 'sha': 3763, 'fairy': 1021, 'assured': 2599, 'kamterm': 4254, 'bassel': 3324, 'carb': 6030, 'settlements': 1074, 'elastic': 1877, 'wits': 295, 'camera': 1133, '355': 5775, 'asn': 3575, 'digression': 5954, '3v9f0': 3946, 'democrats': 5019, 'xdvi': 1181, 'tanks': 2094, 'basestealing': 4238, '485': 1606, 'scratches': 5316, 'investigations': 4091, 'mcgee': 3265, 'alexandrians': 2811, 'fatima': 5403, 'depressants': 2115, 'pronoun': 577, 'potent': 5534, 'carina': 5385, 'aidler': 1976, 'remus': 1813, 'splatterfest': 5826, 'cass': 2200, 'tribal': 5392, 'killer': 4068, 'cthulhu': 3898, 'ro0': 2095, 'solved': 2724, 'alliant': 4166, 'fragile': 3367, 'ges': 1530, 'pointing': 3533, 'competitors': 1349, 'probs': 1352, 'discretionary': 721, 'slaughtering': 3501, 'emphasis': 4732, 'cultivate': 4859, 'rrrrrrrrrrrrrrrabbits': 3281, 'trusts': 6190, 'jrwaters': 5890, 'rodney': 2498, 'hou': 5333, 'reconnaissance': 3964, 'xxxx': 5482, 'elisa': 1766, 'intuitive': 6269, 'outcomes': 5666, 'televised': 4736, 'stoppered': 3170, 'absense': 277, 'adamsj': 6466, 'destiny': 580, 'abdomen': 3880, 'defterleri': 2187, 'false': 551, 'computerized': 6115, 'ck8v': 3823, 'mz4': 1227, 'pbs': 3383, 'truncated': 2691, 'i0': 3996, 'spapp': 364, '61dk': 1084, 'warming': 2514, 'happening': 1440, 'reformatted': 2561, 'everlasting': 3223, 'denman': 1112, 'quivering': 677, 'representations': 2123, 'soceity': 4048, 'aura': 6069, '1fp4u': 6066, 'assistants': 1198, 'unplugging': 4453, '20khz': 337, 'unavailable': 6261, 'persists': 992, 'pioneers': 2676, 'benevolent': 4190, 'maple': 6196, 'irrational': 4707, 'helke': 4196, 'league': 1057, 'nervous': 4259, 'complacency': 5807, 'rightful': 4168, 'stumbling': 3139, 'griffith': 1858, '3693': 1338, 'haji': 5744, 'droptop': 3313, 'arts': 4122, 'initiated': 361, 'oryx': 5671, 'patricia': 3799, 'vermont': 764, 'tigard': 1778, 'ab': 2858, 'mum': 1999, 'lacin': 897, 'fantasies': 4622, 'l8': 5799, '1993apr04': 4628, 'bri': 655, 'resumes': 1170, '190': 334, 'rsvp': 2439, 'milwaukee': 2280, 'rap115': 5887, 'scratchy': 4672, 'iceland': 5896, 'volts': 525, 'qi': 5050, 'isc': 3915, 'stiffness': 2264, 'ethyl': 4775, 'peterborough': 6274, 'hymenaeus': 814, 'sphughes': 5418, 'deskwriter': 2526, 'kirszner': 553, 'footage': 3183, 'usenet': 29, 'liberterians': 5324, 'aerostich': 240, 'relays': 541, 'checker': 6042, 'bum': 4482, 'roof': 1306, 'clearasil': 3356, 'bacon': 5190, 'sweetener': 3407, '6q175u': 4815, 'fig': 63, 'zdk': 1332, 'entrenched': 5573, 'forte': 3260, '8y': 4513, 'raped': 156, '192': 336, 'punching': 5816, 'shirt': 2344, 'strive': 5785, 'secure': 3230, 'iisi': 5951, 'instrumental': 6135, 'dfrf': 1827, 'kou': 4244, 'surgery': 2809, 'y5': 6154, 'surges': 232, 'matters': 4305, 'iisakkila': 1632, 'billboards': 515, 'christine': 4154, 'eighth': 2124, 'goh': 4579, 'butsayev': 415, 'missile': 3703, 'simpson': 6412, 'bloomington': 5281, '1603': 767, 'diduck': 1149, 'euros': 916, '132318': 1447, 'enh': 4554, 'ucssun1': 5229, 'gtoal': 4683, 'blir': 4624, 'indiana': 3234, 'sherman': 4734, 'sparc1': 1493, 'ifp': 6180, 'lovely': 1376, 'fool': 3556, 'senad': 4871, 'windsor': 881, 'srandom': 5909, 'flybys': 3491, 'zd9': 1292, 'inscrutable': 1385, 'sceptre': 6452, 'kmac': 3744, 'az': 2880, 'causing': 2614, 'mend': 2631, 'unbreakable': 3708, 'bnh': 5254, 'k80': 549, 'grounding': 1185, '0114': 5464, 'wim': 6297, 'priestly': 6013, 'brucet': 6291, 'purported': 1588, 'gravisphere': 5784, 'pod': 2840, 'focus': 2257, '263': 3802, 'blotted': 4902, 'vwk': 797, 'hispanic': 5927, 'cbnewsc': 1235, 'examined': 1231, '204319': 4792, '8co': 2420, 'carriers': 679, 'perry': 1669, 'crossposting': 283, 'suckers': 5980, 'well': 6382, 'considerate': 1991, 'interpolation': 3631, 'modesty': 5858, 'shitless': 387, 'gruesome': 4895, 'toungues': 3256, 'brea': 561, 'disinterested': 4722, 'univesa': 165, 'lanmola': 5318, 'ecnebiyye': 5743, 'equates': 4800, 'commandments': 4847, 'dmu': 3841, '91711': 2059, 'compilers': 4506, 'abbott': 79, 'dusek': 5948, 'sundance': 2120, 'discrimination': 2225, 'mc98601': 4262, '488': 1603, 'maccs': 933, 'master': 87, '278': 23, 'tartarus': 2180, 'numbering': 1857, 'deon': 3700, 'av': 2877, 'wil': 6298, 'mhollowa': 5337, 'corelscsi': 288, 'polyray': 6306, 'disclosing': 5284, 'balboa': 2401, 'wolfe': 5975, 'special': 1164, 'microchannel': 2494, 'olesov': 2340, 'lclark': 3395, 'morgan': 5480, 'mach1': 186, 'a_': 2881, 'confront': 2362, 'lift': 2667, 'loose': 6124, 'c445585': 3401, 'terresterial': 6348, 'deviating': 6070, 'supplemented': 2495, 'wether': 1859, 'praying': 3644, 'doth': 5242, 'g0f': 5221, 'channel1': 5193, 'usefulness': 3770, 'ocsmd': 4890, 'graduates': 3331, 'cowards': 6370, 'bassen': 3325, 'coordinator': 2383, 'ironically': 5358, 'iw': 3974, 'fuss': 760, 'trees': 3605, 'bxn': 3692, 'en': 3412, 'xcopyright': 2191, 'iu': 3972, 'open': 5345, '12821': 6492, 'reluctant': 4186, 'absurdum': 1104, 'chlorine': 357, '600': 951, 'grappler': 179, 'voecking': 41, 'sponsoring': 6391, 'hex': 5431, 'continue': 5575, 'cooked': 1756, 'tomatoes': 4876, '088': 1435, 'sampling': 4745, 'brevity': 5350, 'staffers': 4347, 'revolvers': 5130, 'latent': 3274, 'uka': 5352, 'chyang': 266, 'asu': 3567, '890kb': 3303, 'activists': 424, 'jk': 4118, 'briarcliff': 1310, 'backx': 2384, 'feel': 3555, '631': 4749, 'ney': 2635, 'selective': 6126, 'ministere': 3085, 'basketball': 5188, 'whaling': 2563, 'tierney': 5518, 'massively': 2686, 'amber': 4797, 'condom': 2987, 'lube': 105, 'homemade': 4325, 'incrimination': 1081, 'ist': 3908, 'candle': 1744, 'stripe': 1736, 'emphasizes': 2093, 'district': 5411, 'ccalmr': 3785, 'academically': 4630, 'denote': 3203, '425': 4651, 'beggar': 5714, 'dxterm': 6094, 'rapist': 818, '7xx': 3762, 'ech': 3729, 'subsequently': 1786, 'macplus': 2730, 'prix': 1739, 'defterdarlik': 1335, 'persecution': 2709, 'luggage': 1931, 'b8g': 791, 'electorate': 4660, 'navstar': 4709, 'oser': 5789, 'iacovou': 1052, 'myriad': 4273, 'graduating': 5651, 'willard': 3470, 'bra': 656, 'rustow': 4603, 'u7': 5588, 'carries': 2533, 'singleton': 3578, 'foundations': 5479, 'weigh': 4257, 'exalted': 2091, 'carleton': 5762, 'hew': 5428, 'butte': 5748, 'crystalscan': 1519, 'quintus': 4211, 'soenke': 1661, 'astrophysicists': 966, 'willamette': 3949, 'honored': 5946, 'kkeller': 2738, 'ij': 3978, 'drain': 4248, 'jks2x': 5582, 'modify': 6125, 'nailed': 4903, 'qx': 5041, 'abortions': 1224, 'jra': 5935, 'drunk': 3012, 'ghod': 2146, 'organisms': 1348, 'wavetracer': 3798, 'b4q': 5370, 'refering': 5690, 'xtappcontext': 3924, 'taught': 3894, 'bobsbox': 4145, 'production': 686, 'jeffp': 3302, 'how': 5330, 'filipivich': 5267, 'jimf': 4958, 'nomenclature': 4114, 'canine': 1202, 'tuesdays': 1690, '1141': 6480, 'tackle': 4177, 'max_program_size': 5150, 'imaging': 2953, 'randomizer': 1172, 'provable': 351, 'concluded': 2403, 'calendar': 4106, 'blender': 414, 'asus': 2981, 'pogroms': 3144, 'fiction': 1971, 'mst4298': 3453, '596': 493, 'finder': 2357, 'honesty': 4080, 'collectively': 425, 'exceed': 2524, 'joakim': 2611, 'inland': 4685, 'ingres': 5353, 'cedar': 5787, 'vishnepolsky': 397, 'tally': 3046, 's3c': 691, 'scstech': 771, 'talking': 4600, 'imho': 2639, 'lactose': 4493, 'mold': 3349, 'addition': 3780, 'karn': 3593, 'em': 3409, 'smiley': 1105, '341': 1909, '764': 3642, 'obfuscation': 4664, 'bjones': 1448, '_some_': 6041, 'shady': 5918, 'tms': 4459, 'electrician': 3011, 'withdrawal': 6222, 'jhu': 4032, 'global': 3362, 'sudan': 4162, 'plastics': 4397, 'studies': 2734, '982': 2210, 'observatory': 2968, 'magnified': 2351, 'gastroenterology': 598, 'savoy': 5323, 'wig': 6294, 'io': 3981, 'oldest': 3215, 'durban': 534, 'inerrancy': 991, 'shayne': 3508, 'locales': 1834, 'samaria': 5894, 'santo': 3041, 'troop': 1356, 'dumping': 690, 'december': 3389, 'israeline': 3816, 'aquired': 6282, 'telex': 4819, 'cwi': 4389, 'womb': 2259, 'ah': 2864, 'subscribed': 2188, 'condone': 4801, 'bnl': 5255, 'stuffit': 411, 'minimum': 1646, 'football': 2069, 'hurricane': 1867, 'whitespace': 1330, 'kelvin': 2208, 'mormons': 4812, 'kbl': 4986, 'santa': 3040, 'caricature': 4123, 'omran': 171, 'definitive': 3801, 'introduced': 1874, 'hygiene': 3955, 'whois': 4139, 'joshua': 1295, 'clinton': 5583, 'ii': 3976, 'pli': 4203, '435': 830, 'flack': 4099, 'animator': 804, 'boomer': 3828, 'professionally': 126, 'sane': 324, 'disclaim': 995, 'aggravation': 4931, '603': 952, 'narain': 3646, 'polytechnical': 4925, 'rub': 3662, 'hobie': 4634, 'puncture': 2392, 'mixture': 4611, 'thickness': 6120, 'mound': 2913, 'sponsorship': 1524, '353': 5777, 'producers': 4770, '________________________________________________________________': 1476, 'golda': 3864, 'tylenol': 2148, 'memorization': 3243, 'ppv': 2050, 'spouses': 2618, 'ys': 6176, 'metronet': 889, 'invested': 2708, 'urbana': 2598, 'decades': 2765, 'oplinger': 5268, 'infringing': 1110, 'squeaky': 3588, 'rkim': 1746, 'italians': 3381, 'japan': 5861, 'berlet': 5944, 'harkey': 4073, 'expiration': 3161, 'arranging': 5639, 'instant': 4426, 'suspect': 1455, 'jf': 4121, 'rog': 2085, 'isaiah': 5645, 'guided': 4772, '2238': 159, 'ovation': 4497, 'codex': 3055, 'hindenburg': 3344, '660': 1119, 'amolitor': 4846, 'jurgen': 5315, 'yellow': 2555, 'cbfsb': 4437, '1meg': 4442, 'indo': 1193, 'nonexistence': 4577, 'travesty': 1527, 'retired': 3379, 'camps': 3311, 'pointless': 2701, 'boivert': 6051, 'legislated': 4457, 'ggw': 4614, 'strongly': 4810, 'qm': 5054, 'nx2000': 121, 'fulbright': 5738, 'clergy': 4209, 'fuel': 3752, 'una': 4784, '3406': 1820, 'lpt2': 1729, 'brinton': 1566, 'demagogue': 1109, 'gravitational': 5810, 'ultimatum': 3740, 'randomly': 1035, 'montenegro': 4726, 'benoit': 2818, 'stk1203': 4043, '421': 4648, 'saudi': 4191, 'trondheim': 2592, '_societally_': 3365, 'viveiros': 1175, 'anchored': 890, 'gauge': 2625, 'pta': 3221, 'mystique': 2617, 'finish': 3487, 'genetic': 587, 'damsus': 5014, 'mvp': 5876, 'gazing': 5798, '1rgrsvinnmpr': 3252, 'deplore': 1791, 'menudo': 5205, 'herrin': 149, 'apanjabi': 3711, 'room': 1305, 'benali': 5836, 'cwru': 2749, 'rushes': 1879, 'redeemed': 3047, 'motifs': 5698, 'picking': 3953, 'cultures': 2232, 'smiled': 1107, 'coefficient': 6432, 'chkdsk': 4572, 'crew': 1318, 'p17': 1157, 'halici': 1097, 'wrong': 55, 'confernce': 252, 'fates': 4167, 'n0nzo': 5396, 'opera': 4714, 'televise': 5486, 'exploited': 4422, 'quotations': 6316, 'screens': 4848, 'cxterm': 1236, 'correspondence': 861, '1400': 5655, 'strydom': 3237, 'kuiper': 3081, 'jensen': 6117, 'symptomatic': 5988, 'pleasant': 4845, 'poseidon': 4057, 'obese': 123, 'jitters': 245, '604': 947, 'k8v': 546, 'subtext': 3525, 'true': 5950, 'taxed': 3441, 'sliders': 6245, 'annals': 1454, 'characterization': 3475, 'colonic': 1311, 'cardinals': 5907, 'dining': 4731, 'retractable': 5098}\n",
      "vocab_size: 6498\n"
     ]
    }
   ],
   "source": [
    "word2id = {\"PAD\": 0, \"UNK\": 1}\n",
    "fvocab = open(VOCAB_FILE, \"rb\")\n",
    "for i, line in enumerate(fvocab):\n",
    "    word, count = line.decode('utf-8').strip().split(\"\\t\")\n",
    "    if int(count) <= MIN_OCCURS:\n",
    "        break\n",
    "    word2id[word] = i\n",
    "fvocab.close()\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "print(\"vocab_size: {:d}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6498, 300)\n"
     ]
    }
   ],
   "source": [
    "E = np.zeros((vocab_size, WORD_EMBED_SIZE))\n",
    "E[1] = np.random.random(WORD_EMBED_SIZE)\n",
    "fglove = open(GLOVE_FILE, \"rb\")\n",
    "for line in fglove:\n",
    "    cols = line.decode('utf-8').strip().split(\" \")\n",
    "    word = cols[0]\n",
    "    if not word in word2id:\n",
    "        continue\n",
    "    vec = np.array([float(x) for x in cols[1:]])\n",
    "    idx = word2id[word]\n",
    "    E[idx] = vec\n",
    "fglove.close()\n",
    "print(E.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "ng_data = fetch_20newsgroups(subset='all',\n",
    "                             data_home=DATA_DIR,\n",
    "                             shuffle=True, \n",
    "                             random_state=42)\n",
    "num_docs = len(ng_data.data)\n",
    "print(num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 300)\n"
     ]
    }
   ],
   "source": [
    "D = np.zeros((num_docs, WORD_EMBED_SIZE))\n",
    "for i, text in enumerate(ng_data.data):\n",
    "    doc_vec = np.zeros(WORD_EMBED_SIZE)\n",
    "    num_words = 0\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        sent = sent.encode(\"utf8\").decode(\"ascii\", \"ignore\").lower()\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            try:\n",
    "                doc_vec += E[word2id[word]]\n",
    "            except KeyError:\n",
    "                doc_vec += E[word2id[\"UNK\"]]\n",
    "            num_words += 1\n",
    "    doc_vec /= num_words\n",
    "    D[i] = doc_vec\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 20)\n"
     ]
    }
   ],
   "source": [
    "y = ng_data.target\n",
    "Y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13192, 300) (13192, 20) (5654, 300) (5654, 20)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(D, Y, train_size=0.7)\n",
    "print(Xtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(WORD_EMBED_SIZE, ))\n",
    "fc1 = Dense(100, activation=\"relu\")(inputs)\n",
    "fc1_dropout = Dropout(0.2)(fc1)\n",
    "fc2 = Dense(50, activation=\"relu\")(fc1_dropout)\n",
    "fc2_dropout = Dropout(0.2)(fc2)\n",
    "outputs = Dense(NUM_CLASSES, activation=\"softmax\")(fc1_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 32,120\n",
      "Trainable params: 32,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11872 samples, validate on 1320 samples\n",
      "Epoch 1/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5779 - acc: 0.1615 - val_loss: 2.5295 - val_acc: 0.1939\n",
      "Epoch 2/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5782 - acc: 0.1546 - val_loss: 2.5065 - val_acc: 0.1803\n",
      "Epoch 3/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5876 - acc: 0.1556 - val_loss: 2.4911 - val_acc: 0.1932\n",
      "Epoch 4/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5854 - acc: 0.1536 - val_loss: 2.5040 - val_acc: 0.2068\n",
      "Epoch 5/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5770 - acc: 0.1569 - val_loss: 2.4887 - val_acc: 0.1841\n",
      "Epoch 6/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5728 - acc: 0.1555 - val_loss: 2.5211 - val_acc: 0.1894\n",
      "Epoch 7/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5819 - acc: 0.1564 - val_loss: 2.4862 - val_acc: 0.1992\n",
      "Epoch 8/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5780 - acc: 0.1536 - val_loss: 2.4756 - val_acc: 0.1735\n",
      "Epoch 9/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.5760 - acc: 0.1581 - val_loss: 2.4817 - val_acc: 0.1962\n",
      "Epoch 10/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5767 - acc: 0.1600 - val_loss: 2.4901 - val_acc: 0.2114\n",
      "Epoch 11/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5713 - acc: 0.1565 - val_loss: 2.4908 - val_acc: 0.1924\n",
      "Epoch 12/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5720 - acc: 0.1583 - val_loss: 2.4942 - val_acc: 0.2091\n",
      "Epoch 13/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5630 - acc: 0.1582 - val_loss: 2.4760 - val_acc: 0.2023\n",
      "Epoch 14/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5771 - acc: 0.1579 - val_loss: 2.4916 - val_acc: 0.1985\n",
      "Epoch 15/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5687 - acc: 0.1601 - val_loss: 2.4906 - val_acc: 0.1977\n",
      "Epoch 16/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5749 - acc: 0.1601 - val_loss: 2.4797 - val_acc: 0.1985\n",
      "Epoch 17/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5654 - acc: 0.1643 - val_loss: 2.5012 - val_acc: 0.1848\n",
      "Epoch 18/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5719 - acc: 0.1596 - val_loss: 2.4707 - val_acc: 0.2106\n",
      "Epoch 19/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5552 - acc: 0.1588 - val_loss: 2.4782 - val_acc: 0.2136\n",
      "Epoch 20/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.5651 - acc: 0.1632 - val_loss: 2.4845 - val_acc: 0.1962\n",
      "Epoch 21/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5669 - acc: 0.1625 - val_loss: 2.4724 - val_acc: 0.2045\n",
      "Epoch 22/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5623 - acc: 0.1639 - val_loss: 2.4700 - val_acc: 0.2114\n",
      "Epoch 23/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5592 - acc: 0.1611 - val_loss: 2.4750 - val_acc: 0.1977\n",
      "Epoch 24/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5540 - acc: 0.1640 - val_loss: 2.4713 - val_acc: 0.2136\n",
      "Epoch 25/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5592 - acc: 0.1614 - val_loss: 2.4635 - val_acc: 0.2068\n",
      "Epoch 26/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5711 - acc: 0.1559 - val_loss: 2.4555 - val_acc: 0.2038\n",
      "Epoch 27/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.5574 - acc: 0.1630 - val_loss: 2.4590 - val_acc: 0.2045\n",
      "Epoch 28/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.5580 - acc: 0.1589 - val_loss: 2.4579 - val_acc: 0.2038\n",
      "Epoch 29/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5646 - acc: 0.1619 - val_loss: 2.4565 - val_acc: 0.2114\n",
      "Epoch 30/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5539 - acc: 0.1675 - val_loss: 2.4576 - val_acc: 0.2129\n",
      "Epoch 31/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5624 - acc: 0.1643 - val_loss: 2.4584 - val_acc: 0.2068\n",
      "Epoch 32/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5591 - acc: 0.1689 - val_loss: 2.4554 - val_acc: 0.2068\n",
      "Epoch 33/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5536 - acc: 0.1643 - val_loss: 2.4535 - val_acc: 0.2129\n",
      "Epoch 34/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5514 - acc: 0.1653 - val_loss: 2.4639 - val_acc: 0.1924\n",
      "Epoch 35/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5541 - acc: 0.1624 - val_loss: 2.4622 - val_acc: 0.2045\n",
      "Epoch 36/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5556 - acc: 0.1651 - val_loss: 2.4558 - val_acc: 0.2144\n",
      "Epoch 37/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5496 - acc: 0.1662 - val_loss: 2.4506 - val_acc: 0.2076\n",
      "Epoch 38/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5519 - acc: 0.1648 - val_loss: 2.4434 - val_acc: 0.2068\n",
      "Epoch 39/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5547 - acc: 0.1630 - val_loss: 2.4660 - val_acc: 0.2061\n",
      "Epoch 40/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5557 - acc: 0.1613 - val_loss: 2.4463 - val_acc: 0.2061\n",
      "Epoch 41/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5582 - acc: 0.1617 - val_loss: 2.4487 - val_acc: 0.2061\n",
      "Epoch 42/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5541 - acc: 0.1620 - val_loss: 2.4542 - val_acc: 0.2076\n",
      "Epoch 43/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5450 - acc: 0.1645 - val_loss: 2.4539 - val_acc: 0.2038\n",
      "Epoch 44/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5534 - acc: 0.1644 - val_loss: 2.4544 - val_acc: 0.2121\n",
      "Epoch 45/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5380 - acc: 0.1706 - val_loss: 2.4388 - val_acc: 0.2098\n",
      "Epoch 46/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5499 - acc: 0.1654 - val_loss: 2.4352 - val_acc: 0.2152\n",
      "Epoch 47/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5456 - acc: 0.1676 - val_loss: 2.4408 - val_acc: 0.2061\n",
      "Epoch 48/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5397 - acc: 0.1664 - val_loss: 2.4424 - val_acc: 0.2144\n",
      "Epoch 49/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5443 - acc: 0.1656 - val_loss: 2.4367 - val_acc: 0.2106\n",
      "Epoch 50/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5497 - acc: 0.1700 - val_loss: 2.4428 - val_acc: 0.2129\n",
      "Epoch 51/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5404 - acc: 0.1707 - val_loss: 2.4456 - val_acc: 0.2167\n",
      "Epoch 52/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5374 - acc: 0.1687 - val_loss: 2.4390 - val_acc: 0.2114\n",
      "Epoch 53/1000\n",
      "11872/11872 [==============================] - 0s 34us/step - loss: 2.5493 - acc: 0.1675 - val_loss: 2.4487 - val_acc: 0.2129\n",
      "Epoch 54/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5487 - acc: 0.1722 - val_loss: 2.4359 - val_acc: 0.2083\n",
      "Epoch 55/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5399 - acc: 0.1664 - val_loss: 2.4403 - val_acc: 0.2159\n",
      "Epoch 56/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5446 - acc: 0.1677 - val_loss: 2.4333 - val_acc: 0.2152\n",
      "Epoch 57/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5321 - acc: 0.1723 - val_loss: 2.4243 - val_acc: 0.2091\n",
      "Epoch 58/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5396 - acc: 0.1708 - val_loss: 2.4396 - val_acc: 0.2045\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5402 - acc: 0.1698 - val_loss: 2.4406 - val_acc: 0.2258\n",
      "Epoch 60/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5398 - acc: 0.1711 - val_loss: 2.4263 - val_acc: 0.2053\n",
      "Epoch 61/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5400 - acc: 0.1707 - val_loss: 2.4440 - val_acc: 0.2152\n",
      "Epoch 62/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5355 - acc: 0.1729 - val_loss: 2.4233 - val_acc: 0.2038\n",
      "Epoch 63/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.5337 - acc: 0.1714 - val_loss: 2.4359 - val_acc: 0.2167\n",
      "Epoch 64/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5323 - acc: 0.1702 - val_loss: 2.4409 - val_acc: 0.2235\n",
      "Epoch 65/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5424 - acc: 0.1723 - val_loss: 2.4390 - val_acc: 0.2121\n",
      "Epoch 66/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5284 - acc: 0.1712 - val_loss: 2.4323 - val_acc: 0.2167\n",
      "Epoch 67/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.5332 - acc: 0.1717 - val_loss: 2.4331 - val_acc: 0.2174\n",
      "Epoch 68/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5326 - acc: 0.1712 - val_loss: 2.4355 - val_acc: 0.2167\n",
      "Epoch 69/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5301 - acc: 0.1730 - val_loss: 2.4261 - val_acc: 0.2258\n",
      "Epoch 70/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5328 - acc: 0.1714 - val_loss: 2.4611 - val_acc: 0.2205\n",
      "Epoch 71/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5316 - acc: 0.1727 - val_loss: 2.4180 - val_acc: 0.2152\n",
      "Epoch 72/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.5392 - acc: 0.1704 - val_loss: 2.4299 - val_acc: 0.2121\n",
      "Epoch 73/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5324 - acc: 0.1738 - val_loss: 2.4281 - val_acc: 0.2129\n",
      "Epoch 74/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5339 - acc: 0.1699 - val_loss: 2.4320 - val_acc: 0.2076\n",
      "Epoch 75/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.5336 - acc: 0.1680 - val_loss: 2.4215 - val_acc: 0.2227\n",
      "Epoch 76/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.5302 - acc: 0.1749 - val_loss: 2.4185 - val_acc: 0.2098\n",
      "Epoch 77/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.5235 - acc: 0.1756 - val_loss: 2.4247 - val_acc: 0.2265\n",
      "Epoch 78/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5289 - acc: 0.1762 - val_loss: 2.4414 - val_acc: 0.2197\n",
      "Epoch 79/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5255 - acc: 0.1754 - val_loss: 2.4280 - val_acc: 0.2205\n",
      "Epoch 80/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5252 - acc: 0.1780 - val_loss: 2.4142 - val_acc: 0.2189\n",
      "Epoch 81/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5263 - acc: 0.1723 - val_loss: 2.4042 - val_acc: 0.2114\n",
      "Epoch 82/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5346 - acc: 0.1675 - val_loss: 2.4112 - val_acc: 0.2227\n",
      "Epoch 83/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5323 - acc: 0.1703 - val_loss: 2.4242 - val_acc: 0.2280\n",
      "Epoch 84/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.5233 - acc: 0.1744 - val_loss: 2.4572 - val_acc: 0.2220\n",
      "Epoch 85/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5185 - acc: 0.1779 - val_loss: 2.4018 - val_acc: 0.2144\n",
      "Epoch 86/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5366 - acc: 0.1701 - val_loss: 2.4299 - val_acc: 0.1924\n",
      "Epoch 87/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5222 - acc: 0.1783 - val_loss: 2.4080 - val_acc: 0.2061\n",
      "Epoch 88/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.5188 - acc: 0.1790 - val_loss: 2.4068 - val_acc: 0.2265\n",
      "Epoch 89/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5220 - acc: 0.1746 - val_loss: 2.4247 - val_acc: 0.2235\n",
      "Epoch 90/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5214 - acc: 0.1730 - val_loss: 2.3971 - val_acc: 0.2136\n",
      "Epoch 91/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5213 - acc: 0.1741 - val_loss: 2.3953 - val_acc: 0.2023\n",
      "Epoch 92/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5213 - acc: 0.1763 - val_loss: 2.4034 - val_acc: 0.2174\n",
      "Epoch 93/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5244 - acc: 0.1728 - val_loss: 2.4416 - val_acc: 0.2076\n",
      "Epoch 94/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.5162 - acc: 0.1781 - val_loss: 2.4130 - val_acc: 0.2167\n",
      "Epoch 95/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5287 - acc: 0.1765 - val_loss: 2.4075 - val_acc: 0.2242\n",
      "Epoch 96/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5145 - acc: 0.1740 - val_loss: 2.4048 - val_acc: 0.2152\n",
      "Epoch 97/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5297 - acc: 0.1745 - val_loss: 2.4151 - val_acc: 0.2288\n",
      "Epoch 98/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.5194 - acc: 0.1781 - val_loss: 2.4014 - val_acc: 0.2258\n",
      "Epoch 99/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5083 - acc: 0.1783 - val_loss: 2.4064 - val_acc: 0.2288\n",
      "Epoch 100/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5293 - acc: 0.1753 - val_loss: 2.4002 - val_acc: 0.2235\n",
      "Epoch 101/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5224 - acc: 0.1752 - val_loss: 2.3986 - val_acc: 0.2205\n",
      "Epoch 102/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5171 - acc: 0.1811 - val_loss: 2.3968 - val_acc: 0.2326\n",
      "Epoch 103/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5133 - acc: 0.1761 - val_loss: 2.3965 - val_acc: 0.2250\n",
      "Epoch 104/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5233 - acc: 0.1755 - val_loss: 2.3978 - val_acc: 0.2303\n",
      "Epoch 105/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5237 - acc: 0.1765 - val_loss: 2.4259 - val_acc: 0.2121\n",
      "Epoch 106/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5290 - acc: 0.1734 - val_loss: 2.3976 - val_acc: 0.2242\n",
      "Epoch 107/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5184 - acc: 0.1766 - val_loss: 2.4236 - val_acc: 0.2273\n",
      "Epoch 108/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5212 - acc: 0.1778 - val_loss: 2.4044 - val_acc: 0.2311\n",
      "Epoch 109/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5188 - acc: 0.1803 - val_loss: 2.4073 - val_acc: 0.2152\n",
      "Epoch 110/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.5211 - acc: 0.1787 - val_loss: 2.4049 - val_acc: 0.2333\n",
      "Epoch 111/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5230 - acc: 0.1756 - val_loss: 2.4009 - val_acc: 0.2159\n",
      "Epoch 112/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5193 - acc: 0.1738 - val_loss: 2.3956 - val_acc: 0.2273\n",
      "Epoch 113/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.5183 - acc: 0.1772 - val_loss: 2.4014 - val_acc: 0.2311\n",
      "Epoch 114/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5086 - acc: 0.1779 - val_loss: 2.4018 - val_acc: 0.2280\n",
      "Epoch 115/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5148 - acc: 0.1762 - val_loss: 2.3932 - val_acc: 0.2273\n",
      "Epoch 116/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5143 - acc: 0.1797 - val_loss: 2.3941 - val_acc: 0.2318\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5128 - acc: 0.1802 - val_loss: 2.3928 - val_acc: 0.2311\n",
      "Epoch 118/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5013 - acc: 0.1805 - val_loss: 2.3889 - val_acc: 0.2106\n",
      "Epoch 119/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5102 - acc: 0.1798 - val_loss: 2.4029 - val_acc: 0.2220\n",
      "Epoch 120/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5119 - acc: 0.1781 - val_loss: 2.3892 - val_acc: 0.2242\n",
      "Epoch 121/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.5165 - acc: 0.1824 - val_loss: 2.3922 - val_acc: 0.2189\n",
      "Epoch 122/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5167 - acc: 0.1749 - val_loss: 2.4138 - val_acc: 0.2083\n",
      "Epoch 123/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5151 - acc: 0.1794 - val_loss: 2.3853 - val_acc: 0.2205\n",
      "Epoch 124/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5139 - acc: 0.1807 - val_loss: 2.4063 - val_acc: 0.2303\n",
      "Epoch 125/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5150 - acc: 0.1827 - val_loss: 2.3971 - val_acc: 0.2326\n",
      "Epoch 126/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5161 - acc: 0.1804 - val_loss: 2.3771 - val_acc: 0.2250\n",
      "Epoch 127/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5134 - acc: 0.1785 - val_loss: 2.3964 - val_acc: 0.2348\n",
      "Epoch 128/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5125 - acc: 0.1802 - val_loss: 2.4037 - val_acc: 0.2235\n",
      "Epoch 129/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5070 - acc: 0.1810 - val_loss: 2.4028 - val_acc: 0.2295\n",
      "Epoch 130/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5084 - acc: 0.1801 - val_loss: 2.3979 - val_acc: 0.2220\n",
      "Epoch 131/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5104 - acc: 0.1783 - val_loss: 2.3867 - val_acc: 0.2280\n",
      "Epoch 132/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5113 - acc: 0.1820 - val_loss: 2.4011 - val_acc: 0.2311\n",
      "Epoch 133/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5136 - acc: 0.1771 - val_loss: 2.4064 - val_acc: 0.2250\n",
      "Epoch 134/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5087 - acc: 0.1821 - val_loss: 2.3880 - val_acc: 0.2311\n",
      "Epoch 135/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5199 - acc: 0.1744 - val_loss: 2.4196 - val_acc: 0.2212\n",
      "Epoch 136/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5013 - acc: 0.1820 - val_loss: 2.3745 - val_acc: 0.2250\n",
      "Epoch 137/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5073 - acc: 0.1763 - val_loss: 2.3749 - val_acc: 0.2326\n",
      "Epoch 138/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.5090 - acc: 0.1819 - val_loss: 2.3919 - val_acc: 0.2288\n",
      "Epoch 139/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5156 - acc: 0.1807 - val_loss: 2.3722 - val_acc: 0.2280\n",
      "Epoch 140/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5067 - acc: 0.1825 - val_loss: 2.3800 - val_acc: 0.2152\n",
      "Epoch 141/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.5066 - acc: 0.1801 - val_loss: 2.3927 - val_acc: 0.2341\n",
      "Epoch 142/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5068 - acc: 0.1797 - val_loss: 2.4001 - val_acc: 0.2341\n",
      "Epoch 143/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5047 - acc: 0.1782 - val_loss: 2.3868 - val_acc: 0.2295\n",
      "Epoch 144/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5105 - acc: 0.1786 - val_loss: 2.4341 - val_acc: 0.2174\n",
      "Epoch 145/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5174 - acc: 0.1791 - val_loss: 2.3960 - val_acc: 0.2280\n",
      "Epoch 146/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4963 - acc: 0.1863 - val_loss: 2.4472 - val_acc: 0.2114\n",
      "Epoch 147/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5040 - acc: 0.1823 - val_loss: 2.3949 - val_acc: 0.2348\n",
      "Epoch 148/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5065 - acc: 0.1806 - val_loss: 2.4007 - val_acc: 0.2295\n",
      "Epoch 149/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5090 - acc: 0.1830 - val_loss: 2.3934 - val_acc: 0.2273\n",
      "Epoch 150/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.5089 - acc: 0.1818 - val_loss: 2.3956 - val_acc: 0.2341\n",
      "Epoch 151/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5082 - acc: 0.1830 - val_loss: 2.3792 - val_acc: 0.2303\n",
      "Epoch 152/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.5105 - acc: 0.1847 - val_loss: 2.4010 - val_acc: 0.2432\n",
      "Epoch 153/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.5039 - acc: 0.1817 - val_loss: 2.3876 - val_acc: 0.2341\n",
      "Epoch 154/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5030 - acc: 0.1851 - val_loss: 2.3859 - val_acc: 0.2333\n",
      "Epoch 155/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4973 - acc: 0.1879 - val_loss: 2.4127 - val_acc: 0.2265\n",
      "Epoch 156/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4927 - acc: 0.1835 - val_loss: 2.3810 - val_acc: 0.2432\n",
      "Epoch 157/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5012 - acc: 0.1887 - val_loss: 2.4020 - val_acc: 0.2189\n",
      "Epoch 158/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5040 - acc: 0.1824 - val_loss: 2.3744 - val_acc: 0.2303\n",
      "Epoch 159/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4995 - acc: 0.1856 - val_loss: 2.3739 - val_acc: 0.2265\n",
      "Epoch 160/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5013 - acc: 0.1859 - val_loss: 2.3900 - val_acc: 0.2326\n",
      "Epoch 161/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5022 - acc: 0.1834 - val_loss: 2.3823 - val_acc: 0.2379\n",
      "Epoch 162/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4949 - acc: 0.1864 - val_loss: 2.3815 - val_acc: 0.2356\n",
      "Epoch 163/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4994 - acc: 0.1841 - val_loss: 2.3863 - val_acc: 0.2318\n",
      "Epoch 164/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4976 - acc: 0.1857 - val_loss: 2.3698 - val_acc: 0.2341\n",
      "Epoch 165/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4985 - acc: 0.1822 - val_loss: 2.3654 - val_acc: 0.2227\n",
      "Epoch 166/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4926 - acc: 0.1847 - val_loss: 2.3630 - val_acc: 0.2318\n",
      "Epoch 167/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4895 - acc: 0.1834 - val_loss: 2.3579 - val_acc: 0.2273\n",
      "Epoch 168/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4953 - acc: 0.1835 - val_loss: 2.3688 - val_acc: 0.2386\n",
      "Epoch 169/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.5020 - acc: 0.1834 - val_loss: 2.3870 - val_acc: 0.2409\n",
      "Epoch 170/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.5020 - acc: 0.1846 - val_loss: 2.3668 - val_acc: 0.2326\n",
      "Epoch 171/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5015 - acc: 0.1846 - val_loss: 2.3861 - val_acc: 0.2379\n",
      "Epoch 172/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.5020 - acc: 0.1819 - val_loss: 2.4139 - val_acc: 0.2311\n",
      "Epoch 173/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4977 - acc: 0.1856 - val_loss: 2.3634 - val_acc: 0.2273\n",
      "Epoch 174/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4975 - acc: 0.1871 - val_loss: 2.3660 - val_acc: 0.2379\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4936 - acc: 0.1891 - val_loss: 2.3794 - val_acc: 0.2394\n",
      "Epoch 176/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4975 - acc: 0.1871 - val_loss: 2.3638 - val_acc: 0.2379\n",
      "Epoch 177/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4917 - acc: 0.1910 - val_loss: 2.3876 - val_acc: 0.2439\n",
      "Epoch 178/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4978 - acc: 0.1894 - val_loss: 2.3876 - val_acc: 0.2439\n",
      "Epoch 179/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4924 - acc: 0.1857 - val_loss: 2.3914 - val_acc: 0.2333\n",
      "Epoch 180/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4969 - acc: 0.1875 - val_loss: 2.3911 - val_acc: 0.2167\n",
      "Epoch 181/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4946 - acc: 0.1856 - val_loss: 2.3974 - val_acc: 0.2197\n",
      "Epoch 182/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4865 - acc: 0.1920 - val_loss: 2.3649 - val_acc: 0.2394\n",
      "Epoch 183/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4909 - acc: 0.1911 - val_loss: 2.3627 - val_acc: 0.2356\n",
      "Epoch 184/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4889 - acc: 0.1882 - val_loss: 2.3675 - val_acc: 0.2318\n",
      "Epoch 185/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4969 - acc: 0.1843 - val_loss: 2.3582 - val_acc: 0.2386\n",
      "Epoch 186/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4922 - acc: 0.1887 - val_loss: 2.3446 - val_acc: 0.2333\n",
      "Epoch 187/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.5000 - acc: 0.1840 - val_loss: 2.3719 - val_acc: 0.2189\n",
      "Epoch 188/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4956 - acc: 0.1879 - val_loss: 2.3537 - val_acc: 0.2318\n",
      "Epoch 189/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4976 - acc: 0.1867 - val_loss: 2.4093 - val_acc: 0.2371\n",
      "Epoch 190/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4916 - acc: 0.1925 - val_loss: 2.3768 - val_acc: 0.2235\n",
      "Epoch 191/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4919 - acc: 0.1930 - val_loss: 2.3716 - val_acc: 0.2447\n",
      "Epoch 192/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4970 - acc: 0.1878 - val_loss: 2.3684 - val_acc: 0.2371\n",
      "Epoch 193/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4966 - acc: 0.1856 - val_loss: 2.3536 - val_acc: 0.2364\n",
      "Epoch 194/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4861 - acc: 0.1915 - val_loss: 2.3713 - val_acc: 0.2417\n",
      "Epoch 195/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4980 - acc: 0.1930 - val_loss: 2.4725 - val_acc: 0.2129\n",
      "Epoch 196/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.5017 - acc: 0.1840 - val_loss: 2.3693 - val_acc: 0.2417\n",
      "Epoch 197/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4906 - acc: 0.1937 - val_loss: 2.3746 - val_acc: 0.2432\n",
      "Epoch 198/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4886 - acc: 0.1908 - val_loss: 2.3698 - val_acc: 0.2455\n",
      "Epoch 199/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4834 - acc: 0.1931 - val_loss: 2.3662 - val_acc: 0.2417\n",
      "Epoch 200/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4897 - acc: 0.1952 - val_loss: 2.3842 - val_acc: 0.2386\n",
      "Epoch 201/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4906 - acc: 0.1910 - val_loss: 2.3581 - val_acc: 0.2439\n",
      "Epoch 202/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4919 - acc: 0.1920 - val_loss: 2.3441 - val_acc: 0.2455\n",
      "Epoch 203/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4822 - acc: 0.1931 - val_loss: 2.3795 - val_acc: 0.2447\n",
      "Epoch 204/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4884 - acc: 0.1877 - val_loss: 2.3583 - val_acc: 0.2394\n",
      "Epoch 205/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4874 - acc: 0.1886 - val_loss: 2.4202 - val_acc: 0.2288\n",
      "Epoch 206/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4953 - acc: 0.1909 - val_loss: 2.3580 - val_acc: 0.2409\n",
      "Epoch 207/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4833 - acc: 0.1892 - val_loss: 2.3658 - val_acc: 0.2379\n",
      "Epoch 208/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4854 - acc: 0.1972 - val_loss: 2.3567 - val_acc: 0.2424\n",
      "Epoch 209/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4855 - acc: 0.1899 - val_loss: 2.3410 - val_acc: 0.2348\n",
      "Epoch 210/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4921 - acc: 0.1930 - val_loss: 2.3535 - val_acc: 0.2432\n",
      "Epoch 211/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4899 - acc: 0.1899 - val_loss: 2.3862 - val_acc: 0.2386\n",
      "Epoch 212/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4791 - acc: 0.1950 - val_loss: 2.3601 - val_acc: 0.2439\n",
      "Epoch 213/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4832 - acc: 0.1956 - val_loss: 2.3456 - val_acc: 0.2379\n",
      "Epoch 214/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4904 - acc: 0.1877 - val_loss: 2.3574 - val_acc: 0.2417\n",
      "Epoch 215/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4867 - acc: 0.1903 - val_loss: 2.3365 - val_acc: 0.2341\n",
      "Epoch 216/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4836 - acc: 0.1957 - val_loss: 2.3530 - val_acc: 0.2447\n",
      "Epoch 217/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4795 - acc: 0.1973 - val_loss: 2.3640 - val_acc: 0.2371\n",
      "Epoch 218/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4890 - acc: 0.1914 - val_loss: 2.3569 - val_acc: 0.2409\n",
      "Epoch 219/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4857 - acc: 0.1897 - val_loss: 2.3592 - val_acc: 0.2424\n",
      "Epoch 220/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4879 - acc: 0.1937 - val_loss: 2.3747 - val_acc: 0.2379\n",
      "Epoch 221/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4815 - acc: 0.1930 - val_loss: 2.3466 - val_acc: 0.2462\n",
      "Epoch 222/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4849 - acc: 0.1951 - val_loss: 2.3477 - val_acc: 0.2432\n",
      "Epoch 223/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4813 - acc: 0.1938 - val_loss: 2.3606 - val_acc: 0.2424\n",
      "Epoch 224/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4710 - acc: 0.1947 - val_loss: 2.3354 - val_acc: 0.2379\n",
      "Epoch 225/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4789 - acc: 0.1942 - val_loss: 2.3457 - val_acc: 0.2447\n",
      "Epoch 226/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4959 - acc: 0.1939 - val_loss: 2.3293 - val_acc: 0.2394\n",
      "Epoch 227/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4790 - acc: 0.1932 - val_loss: 2.3297 - val_acc: 0.2402\n",
      "Epoch 228/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4773 - acc: 0.1960 - val_loss: 2.3571 - val_acc: 0.2523\n",
      "Epoch 229/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4853 - acc: 0.1882 - val_loss: 2.3916 - val_acc: 0.2379\n",
      "Epoch 230/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4725 - acc: 0.1968 - val_loss: 2.3723 - val_acc: 0.2386\n",
      "Epoch 231/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4901 - acc: 0.1890 - val_loss: 2.3494 - val_acc: 0.2409\n",
      "Epoch 232/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4817 - acc: 0.1922 - val_loss: 2.3701 - val_acc: 0.2197\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4777 - acc: 0.1930 - val_loss: 2.3284 - val_acc: 0.2409\n",
      "Epoch 234/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4807 - acc: 0.1963 - val_loss: 2.3459 - val_acc: 0.2515\n",
      "Epoch 235/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4831 - acc: 0.1933 - val_loss: 2.3225 - val_acc: 0.2417\n",
      "Epoch 236/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4763 - acc: 0.1936 - val_loss: 2.3316 - val_acc: 0.2447\n",
      "Epoch 237/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4790 - acc: 0.1954 - val_loss: 2.3462 - val_acc: 0.2258\n",
      "Epoch 238/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4692 - acc: 0.1983 - val_loss: 2.3485 - val_acc: 0.2439\n",
      "Epoch 239/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4837 - acc: 0.1934 - val_loss: 2.3541 - val_acc: 0.2470\n",
      "Epoch 240/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4841 - acc: 0.1955 - val_loss: 2.3470 - val_acc: 0.2470\n",
      "Epoch 241/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4885 - acc: 0.1974 - val_loss: 2.3207 - val_acc: 0.2432\n",
      "Epoch 242/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4681 - acc: 0.1957 - val_loss: 2.3518 - val_acc: 0.2470\n",
      "Epoch 243/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4735 - acc: 0.1982 - val_loss: 2.3388 - val_acc: 0.2530\n",
      "Epoch 244/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4839 - acc: 0.1985 - val_loss: 2.3635 - val_acc: 0.2447\n",
      "Epoch 245/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4791 - acc: 0.2006 - val_loss: 2.3520 - val_acc: 0.2500\n",
      "Epoch 246/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4776 - acc: 0.1949 - val_loss: 2.3484 - val_acc: 0.2500\n",
      "Epoch 247/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4765 - acc: 0.1951 - val_loss: 2.3660 - val_acc: 0.2371\n",
      "Epoch 248/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4753 - acc: 0.2020 - val_loss: 2.3288 - val_acc: 0.2462\n",
      "Epoch 249/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4798 - acc: 0.1968 - val_loss: 2.3335 - val_acc: 0.2379\n",
      "Epoch 250/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4793 - acc: 0.1977 - val_loss: 2.3587 - val_acc: 0.2530\n",
      "Epoch 251/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4819 - acc: 0.1968 - val_loss: 2.3166 - val_acc: 0.2500\n",
      "Epoch 252/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4683 - acc: 0.1955 - val_loss: 2.3241 - val_acc: 0.2515\n",
      "Epoch 253/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4794 - acc: 0.1995 - val_loss: 2.3341 - val_acc: 0.2447\n",
      "Epoch 254/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4763 - acc: 0.1968 - val_loss: 2.3606 - val_acc: 0.2432\n",
      "Epoch 255/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4804 - acc: 0.1964 - val_loss: 2.3763 - val_acc: 0.2311\n",
      "Epoch 256/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4874 - acc: 0.1901 - val_loss: 2.3244 - val_acc: 0.2462\n",
      "Epoch 257/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4790 - acc: 0.1935 - val_loss: 2.3406 - val_acc: 0.2455\n",
      "Epoch 258/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4837 - acc: 0.1907 - val_loss: 2.3276 - val_acc: 0.2447\n",
      "Epoch 259/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4684 - acc: 0.1995 - val_loss: 2.3593 - val_acc: 0.2364\n",
      "Epoch 260/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4710 - acc: 0.1982 - val_loss: 2.3558 - val_acc: 0.2417\n",
      "Epoch 261/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4708 - acc: 0.2036 - val_loss: 2.3242 - val_acc: 0.2530\n",
      "Epoch 262/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4808 - acc: 0.2008 - val_loss: 2.3253 - val_acc: 0.2477\n",
      "Epoch 263/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4694 - acc: 0.1981 - val_loss: 2.3510 - val_acc: 0.2477\n",
      "Epoch 264/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4682 - acc: 0.2008 - val_loss: 2.3441 - val_acc: 0.2538\n",
      "Epoch 265/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4673 - acc: 0.1980 - val_loss: 2.3403 - val_acc: 0.2402\n",
      "Epoch 266/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4768 - acc: 0.1995 - val_loss: 2.3268 - val_acc: 0.2500\n",
      "Epoch 267/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4746 - acc: 0.2011 - val_loss: 2.3282 - val_acc: 0.2598\n",
      "Epoch 268/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4771 - acc: 0.1996 - val_loss: 2.3333 - val_acc: 0.2561\n",
      "Epoch 269/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4706 - acc: 0.1973 - val_loss: 2.3249 - val_acc: 0.2492\n",
      "Epoch 270/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4742 - acc: 0.1971 - val_loss: 2.3577 - val_acc: 0.2371\n",
      "Epoch 271/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4799 - acc: 0.1970 - val_loss: 2.3363 - val_acc: 0.2386\n",
      "Epoch 272/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4819 - acc: 0.1973 - val_loss: 2.3542 - val_acc: 0.2432\n",
      "Epoch 273/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4694 - acc: 0.1982 - val_loss: 2.3204 - val_acc: 0.2508\n",
      "Epoch 274/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4748 - acc: 0.1958 - val_loss: 2.3322 - val_acc: 0.2561\n",
      "Epoch 275/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4720 - acc: 0.2017 - val_loss: 2.3305 - val_acc: 0.2432\n",
      "Epoch 276/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4687 - acc: 0.2043 - val_loss: 2.3161 - val_acc: 0.2530\n",
      "Epoch 277/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4788 - acc: 0.1966 - val_loss: 2.3515 - val_acc: 0.2439\n",
      "Epoch 278/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4684 - acc: 0.2032 - val_loss: 2.3025 - val_acc: 0.2508\n",
      "Epoch 279/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4809 - acc: 0.1934 - val_loss: 2.3202 - val_acc: 0.2530\n",
      "Epoch 280/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4682 - acc: 0.2038 - val_loss: 2.3342 - val_acc: 0.2485\n",
      "Epoch 281/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4667 - acc: 0.2017 - val_loss: 2.3056 - val_acc: 0.2561\n",
      "Epoch 282/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4626 - acc: 0.2054 - val_loss: 2.3272 - val_acc: 0.2515\n",
      "Epoch 283/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4698 - acc: 0.2021 - val_loss: 2.3652 - val_acc: 0.2492\n",
      "Epoch 284/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4726 - acc: 0.1997 - val_loss: 2.3173 - val_acc: 0.2523\n",
      "Epoch 285/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4638 - acc: 0.2013 - val_loss: 2.3130 - val_acc: 0.2545\n",
      "Epoch 286/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4671 - acc: 0.2029 - val_loss: 2.3713 - val_acc: 0.2371\n",
      "Epoch 287/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4772 - acc: 0.1940 - val_loss: 2.3704 - val_acc: 0.2394\n",
      "Epoch 288/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4719 - acc: 0.2004 - val_loss: 2.3583 - val_acc: 0.2424\n",
      "Epoch 289/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4677 - acc: 0.2028 - val_loss: 2.3187 - val_acc: 0.2591\n",
      "Epoch 290/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4740 - acc: 0.1974 - val_loss: 2.3277 - val_acc: 0.2477\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4695 - acc: 0.1979 - val_loss: 2.3107 - val_acc: 0.2508\n",
      "Epoch 292/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4661 - acc: 0.2024 - val_loss: 2.3617 - val_acc: 0.2455\n",
      "Epoch 293/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4748 - acc: 0.1976 - val_loss: 2.3130 - val_acc: 0.2561\n",
      "Epoch 294/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4583 - acc: 0.2022 - val_loss: 2.3243 - val_acc: 0.2598\n",
      "Epoch 295/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4567 - acc: 0.2064 - val_loss: 2.3248 - val_acc: 0.2477\n",
      "Epoch 296/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4625 - acc: 0.2038 - val_loss: 2.3176 - val_acc: 0.2508\n",
      "Epoch 297/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4666 - acc: 0.2022 - val_loss: 2.3235 - val_acc: 0.2545\n",
      "Epoch 298/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4641 - acc: 0.2024 - val_loss: 2.3117 - val_acc: 0.2583\n",
      "Epoch 299/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4492 - acc: 0.2022 - val_loss: 2.3369 - val_acc: 0.2417\n",
      "Epoch 300/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4674 - acc: 0.2009 - val_loss: 2.3473 - val_acc: 0.2561\n",
      "Epoch 301/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4543 - acc: 0.2043 - val_loss: 2.3136 - val_acc: 0.2523\n",
      "Epoch 302/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4547 - acc: 0.2008 - val_loss: 2.3357 - val_acc: 0.2538\n",
      "Epoch 303/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4662 - acc: 0.2040 - val_loss: 2.3174 - val_acc: 0.2598\n",
      "Epoch 304/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4605 - acc: 0.2046 - val_loss: 2.3022 - val_acc: 0.2629\n",
      "Epoch 305/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4609 - acc: 0.2081 - val_loss: 2.3235 - val_acc: 0.2523\n",
      "Epoch 306/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4550 - acc: 0.2007 - val_loss: 2.3230 - val_acc: 0.2538\n",
      "Epoch 307/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4662 - acc: 0.2006 - val_loss: 2.3011 - val_acc: 0.2576\n",
      "Epoch 308/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4624 - acc: 0.1996 - val_loss: 2.3210 - val_acc: 0.2576\n",
      "Epoch 309/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4679 - acc: 0.2039 - val_loss: 2.3465 - val_acc: 0.2417\n",
      "Epoch 310/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4631 - acc: 0.2027 - val_loss: 2.3069 - val_acc: 0.2652\n",
      "Epoch 311/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4678 - acc: 0.2077 - val_loss: 2.3486 - val_acc: 0.2492\n",
      "Epoch 312/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4668 - acc: 0.2030 - val_loss: 2.3325 - val_acc: 0.2424\n",
      "Epoch 313/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4641 - acc: 0.2043 - val_loss: 2.3526 - val_acc: 0.2386\n",
      "Epoch 314/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4619 - acc: 0.2055 - val_loss: 2.3012 - val_acc: 0.2652\n",
      "Epoch 315/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4684 - acc: 0.2033 - val_loss: 2.3210 - val_acc: 0.2614\n",
      "Epoch 316/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4651 - acc: 0.2023 - val_loss: 2.3240 - val_acc: 0.2606\n",
      "Epoch 317/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4579 - acc: 0.2034 - val_loss: 2.3097 - val_acc: 0.2591\n",
      "Epoch 318/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4599 - acc: 0.2068 - val_loss: 2.3385 - val_acc: 0.2576\n",
      "Epoch 319/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4612 - acc: 0.2051 - val_loss: 2.2982 - val_acc: 0.2674\n",
      "Epoch 320/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4681 - acc: 0.1998 - val_loss: 2.3255 - val_acc: 0.2629\n",
      "Epoch 321/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4595 - acc: 0.2055 - val_loss: 2.3327 - val_acc: 0.2568\n",
      "Epoch 322/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4606 - acc: 0.2039 - val_loss: 2.3025 - val_acc: 0.2606\n",
      "Epoch 323/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4654 - acc: 0.2002 - val_loss: 2.3038 - val_acc: 0.2576\n",
      "Epoch 324/1000\n",
      "11872/11872 [==============================] - 1s 46us/step - loss: 2.4619 - acc: 0.2050 - val_loss: 2.2931 - val_acc: 0.2614\n",
      "Epoch 325/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4488 - acc: 0.2059 - val_loss: 2.3354 - val_acc: 0.2530\n",
      "Epoch 326/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4577 - acc: 0.2054 - val_loss: 2.3071 - val_acc: 0.2591\n",
      "Epoch 327/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4661 - acc: 0.2033 - val_loss: 2.3128 - val_acc: 0.2629\n",
      "Epoch 328/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4633 - acc: 0.2081 - val_loss: 2.2883 - val_acc: 0.2667\n",
      "Epoch 329/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4600 - acc: 0.2032 - val_loss: 2.3011 - val_acc: 0.2598\n",
      "Epoch 330/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4620 - acc: 0.2034 - val_loss: 2.2837 - val_acc: 0.2614\n",
      "Epoch 331/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4569 - acc: 0.2054 - val_loss: 2.3026 - val_acc: 0.2553\n",
      "Epoch 332/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4666 - acc: 0.2072 - val_loss: 2.2972 - val_acc: 0.2591\n",
      "Epoch 333/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4585 - acc: 0.2090 - val_loss: 2.3049 - val_acc: 0.2568\n",
      "Epoch 334/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4470 - acc: 0.2103 - val_loss: 2.2993 - val_acc: 0.2705\n",
      "Epoch 335/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4590 - acc: 0.2096 - val_loss: 2.3380 - val_acc: 0.2583\n",
      "Epoch 336/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4548 - acc: 0.2097 - val_loss: 2.3535 - val_acc: 0.2485\n",
      "Epoch 337/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4640 - acc: 0.2026 - val_loss: 2.3052 - val_acc: 0.2659\n",
      "Epoch 338/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4624 - acc: 0.2073 - val_loss: 2.3564 - val_acc: 0.2280\n",
      "Epoch 339/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4586 - acc: 0.2053 - val_loss: 2.2933 - val_acc: 0.2644\n",
      "Epoch 340/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4661 - acc: 0.2043 - val_loss: 2.3080 - val_acc: 0.2583\n",
      "Epoch 341/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4582 - acc: 0.2097 - val_loss: 2.3237 - val_acc: 0.2644\n",
      "Epoch 342/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4542 - acc: 0.2042 - val_loss: 2.2866 - val_acc: 0.2712\n",
      "Epoch 343/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4577 - acc: 0.2035 - val_loss: 2.2825 - val_acc: 0.2621\n",
      "Epoch 344/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4609 - acc: 0.2067 - val_loss: 2.3088 - val_acc: 0.2591\n",
      "Epoch 345/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4607 - acc: 0.2055 - val_loss: 2.3057 - val_acc: 0.2538\n",
      "Epoch 346/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4580 - acc: 0.2022 - val_loss: 2.3909 - val_acc: 0.2508\n",
      "Epoch 347/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4565 - acc: 0.2064 - val_loss: 2.2963 - val_acc: 0.2712\n",
      "Epoch 348/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4712 - acc: 0.2015 - val_loss: 2.3046 - val_acc: 0.2674\n",
      "Epoch 349/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4577 - acc: 0.2090 - val_loss: 2.3123 - val_acc: 0.2614\n",
      "Epoch 350/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4556 - acc: 0.2048 - val_loss: 2.2963 - val_acc: 0.2652\n",
      "Epoch 351/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4571 - acc: 0.2049 - val_loss: 2.2898 - val_acc: 0.2674\n",
      "Epoch 352/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4647 - acc: 0.2026 - val_loss: 2.3169 - val_acc: 0.2674\n",
      "Epoch 353/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4461 - acc: 0.2068 - val_loss: 2.3113 - val_acc: 0.2697\n",
      "Epoch 354/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4497 - acc: 0.2062 - val_loss: 2.2906 - val_acc: 0.2667\n",
      "Epoch 355/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4433 - acc: 0.2126 - val_loss: 2.3331 - val_acc: 0.2462\n",
      "Epoch 356/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4475 - acc: 0.2057 - val_loss: 2.3064 - val_acc: 0.2629\n",
      "Epoch 357/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4543 - acc: 0.2100 - val_loss: 2.3099 - val_acc: 0.2568\n",
      "Epoch 358/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4589 - acc: 0.2056 - val_loss: 2.2836 - val_acc: 0.2568\n",
      "Epoch 359/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4498 - acc: 0.2033 - val_loss: 2.2822 - val_acc: 0.2652\n",
      "Epoch 360/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.4627 - acc: 0.2061 - val_loss: 2.3395 - val_acc: 0.2515\n",
      "Epoch 361/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4574 - acc: 0.2102 - val_loss: 2.3185 - val_acc: 0.2515\n",
      "Epoch 362/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4365 - acc: 0.2098 - val_loss: 2.2946 - val_acc: 0.2568\n",
      "Epoch 363/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4445 - acc: 0.2091 - val_loss: 2.3158 - val_acc: 0.2697\n",
      "Epoch 364/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4564 - acc: 0.2082 - val_loss: 2.2736 - val_acc: 0.2644\n",
      "Epoch 365/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4551 - acc: 0.2082 - val_loss: 2.2963 - val_acc: 0.2720\n",
      "Epoch 366/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.4461 - acc: 0.2096 - val_loss: 2.2820 - val_acc: 0.2697\n",
      "Epoch 367/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4509 - acc: 0.2071 - val_loss: 2.2897 - val_acc: 0.2720\n",
      "Epoch 368/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4581 - acc: 0.2016 - val_loss: 2.2842 - val_acc: 0.2614\n",
      "Epoch 369/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4579 - acc: 0.2064 - val_loss: 2.3017 - val_acc: 0.2659\n",
      "Epoch 370/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4616 - acc: 0.2058 - val_loss: 2.2835 - val_acc: 0.2720\n",
      "Epoch 371/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4546 - acc: 0.2065 - val_loss: 2.2884 - val_acc: 0.2674\n",
      "Epoch 372/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4630 - acc: 0.2100 - val_loss: 2.2880 - val_acc: 0.2712\n",
      "Epoch 373/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4494 - acc: 0.2109 - val_loss: 2.3122 - val_acc: 0.2705\n",
      "Epoch 374/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4418 - acc: 0.2123 - val_loss: 2.3219 - val_acc: 0.2689\n",
      "Epoch 375/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4509 - acc: 0.2120 - val_loss: 2.3204 - val_acc: 0.2561\n",
      "Epoch 376/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4598 - acc: 0.2084 - val_loss: 2.2886 - val_acc: 0.2773\n",
      "Epoch 377/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4527 - acc: 0.2114 - val_loss: 2.2914 - val_acc: 0.2621\n",
      "Epoch 378/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4529 - acc: 0.2119 - val_loss: 2.3296 - val_acc: 0.2591\n",
      "Epoch 379/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4439 - acc: 0.2043 - val_loss: 2.2795 - val_acc: 0.2614\n",
      "Epoch 380/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4564 - acc: 0.2089 - val_loss: 2.3125 - val_acc: 0.2545\n",
      "Epoch 381/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4364 - acc: 0.2138 - val_loss: 2.3151 - val_acc: 0.2629\n",
      "Epoch 382/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4491 - acc: 0.2109 - val_loss: 2.2915 - val_acc: 0.2629\n",
      "Epoch 383/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4495 - acc: 0.2105 - val_loss: 2.2828 - val_acc: 0.2720\n",
      "Epoch 384/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4426 - acc: 0.2168 - val_loss: 2.2996 - val_acc: 0.2682\n",
      "Epoch 385/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4473 - acc: 0.2073 - val_loss: 2.2943 - val_acc: 0.2674\n",
      "Epoch 386/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4398 - acc: 0.2125 - val_loss: 2.2784 - val_acc: 0.2667\n",
      "Epoch 387/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4428 - acc: 0.2129 - val_loss: 2.2822 - val_acc: 0.2652\n",
      "Epoch 388/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4641 - acc: 0.2045 - val_loss: 2.3193 - val_acc: 0.2439\n",
      "Epoch 389/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4465 - acc: 0.2085 - val_loss: 2.2811 - val_acc: 0.2705\n",
      "Epoch 390/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4389 - acc: 0.2155 - val_loss: 2.2873 - val_acc: 0.2780\n",
      "Epoch 391/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4392 - acc: 0.2120 - val_loss: 2.2815 - val_acc: 0.2765\n",
      "Epoch 392/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4391 - acc: 0.2160 - val_loss: 2.3138 - val_acc: 0.2568\n",
      "Epoch 393/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4605 - acc: 0.2071 - val_loss: 2.3031 - val_acc: 0.2644\n",
      "Epoch 394/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4465 - acc: 0.2059 - val_loss: 2.3259 - val_acc: 0.2629\n",
      "Epoch 395/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4482 - acc: 0.2120 - val_loss: 2.2859 - val_acc: 0.2750\n",
      "Epoch 396/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4468 - acc: 0.2145 - val_loss: 2.3010 - val_acc: 0.2591\n",
      "Epoch 397/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4522 - acc: 0.2043 - val_loss: 2.3006 - val_acc: 0.2667\n",
      "Epoch 398/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4446 - acc: 0.2119 - val_loss: 2.3528 - val_acc: 0.2561\n",
      "Epoch 399/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4550 - acc: 0.2062 - val_loss: 2.3063 - val_acc: 0.2621\n",
      "Epoch 400/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4501 - acc: 0.2100 - val_loss: 2.3222 - val_acc: 0.2606\n",
      "Epoch 401/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4366 - acc: 0.2146 - val_loss: 2.3254 - val_acc: 0.2462\n",
      "Epoch 402/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4548 - acc: 0.2083 - val_loss: 2.2680 - val_acc: 0.2674\n",
      "Epoch 403/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4487 - acc: 0.2110 - val_loss: 2.2781 - val_acc: 0.2735\n",
      "Epoch 404/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4402 - acc: 0.2109 - val_loss: 2.2969 - val_acc: 0.2644\n",
      "Epoch 405/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4429 - acc: 0.2139 - val_loss: 2.3159 - val_acc: 0.2500\n",
      "Epoch 406/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4511 - acc: 0.2137 - val_loss: 2.2728 - val_acc: 0.2705\n",
      "Epoch 407/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4481 - acc: 0.2133 - val_loss: 2.3175 - val_acc: 0.2530\n",
      "Epoch 408/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4441 - acc: 0.2102 - val_loss: 2.2747 - val_acc: 0.2727\n",
      "Epoch 409/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4483 - acc: 0.2088 - val_loss: 2.2902 - val_acc: 0.2727\n",
      "Epoch 410/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4487 - acc: 0.2119 - val_loss: 2.3058 - val_acc: 0.2598\n",
      "Epoch 411/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4511 - acc: 0.2081 - val_loss: 2.2851 - val_acc: 0.2598\n",
      "Epoch 412/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4428 - acc: 0.2129 - val_loss: 2.3184 - val_acc: 0.2606\n",
      "Epoch 413/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4483 - acc: 0.2139 - val_loss: 2.2787 - val_acc: 0.2720\n",
      "Epoch 414/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4477 - acc: 0.2136 - val_loss: 2.2961 - val_acc: 0.2682\n",
      "Epoch 415/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4475 - acc: 0.2147 - val_loss: 2.3043 - val_acc: 0.2788\n",
      "Epoch 416/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4569 - acc: 0.2100 - val_loss: 2.2633 - val_acc: 0.2697\n",
      "Epoch 417/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4390 - acc: 0.2111 - val_loss: 2.3357 - val_acc: 0.2621\n",
      "Epoch 418/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4355 - acc: 0.2155 - val_loss: 2.2970 - val_acc: 0.2629\n",
      "Epoch 419/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4549 - acc: 0.2121 - val_loss: 2.2709 - val_acc: 0.2697\n",
      "Epoch 420/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4415 - acc: 0.2160 - val_loss: 2.3253 - val_acc: 0.2394\n",
      "Epoch 421/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4505 - acc: 0.2086 - val_loss: 2.2716 - val_acc: 0.2742\n",
      "Epoch 422/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4424 - acc: 0.2103 - val_loss: 2.2971 - val_acc: 0.2621\n",
      "Epoch 423/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4449 - acc: 0.2099 - val_loss: 2.2741 - val_acc: 0.2773\n",
      "Epoch 424/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4426 - acc: 0.2118 - val_loss: 2.2746 - val_acc: 0.2636\n",
      "Epoch 425/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4421 - acc: 0.2137 - val_loss: 2.3248 - val_acc: 0.2500\n",
      "Epoch 426/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4439 - acc: 0.2137 - val_loss: 2.3015 - val_acc: 0.2568\n",
      "Epoch 427/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4387 - acc: 0.2113 - val_loss: 2.2781 - val_acc: 0.2697\n",
      "Epoch 428/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4460 - acc: 0.2154 - val_loss: 2.2783 - val_acc: 0.2773\n",
      "Epoch 429/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4319 - acc: 0.2173 - val_loss: 2.2922 - val_acc: 0.2621\n",
      "Epoch 430/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4417 - acc: 0.2144 - val_loss: 2.2589 - val_acc: 0.2720\n",
      "Epoch 431/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4520 - acc: 0.2112 - val_loss: 2.2732 - val_acc: 0.2765\n",
      "Epoch 432/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4488 - acc: 0.2102 - val_loss: 2.2814 - val_acc: 0.2735\n",
      "Epoch 433/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4399 - acc: 0.2146 - val_loss: 2.2763 - val_acc: 0.2697\n",
      "Epoch 434/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4515 - acc: 0.2150 - val_loss: 2.2848 - val_acc: 0.2720\n",
      "Epoch 435/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4440 - acc: 0.2107 - val_loss: 2.2552 - val_acc: 0.2788\n",
      "Epoch 436/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4349 - acc: 0.2103 - val_loss: 2.2718 - val_acc: 0.2765\n",
      "Epoch 437/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4414 - acc: 0.2129 - val_loss: 2.3003 - val_acc: 0.2705\n",
      "Epoch 438/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4379 - acc: 0.2144 - val_loss: 2.2660 - val_acc: 0.2742\n",
      "Epoch 439/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4370 - acc: 0.2151 - val_loss: 2.2989 - val_acc: 0.2674\n",
      "Epoch 440/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4438 - acc: 0.2107 - val_loss: 2.2812 - val_acc: 0.2712\n",
      "Epoch 441/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4442 - acc: 0.2116 - val_loss: 2.2942 - val_acc: 0.2803\n",
      "Epoch 442/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4415 - acc: 0.2102 - val_loss: 2.2804 - val_acc: 0.2742\n",
      "Epoch 443/1000\n",
      "11872/11872 [==============================] - 0s 34us/step - loss: 2.4396 - acc: 0.2129 - val_loss: 2.2740 - val_acc: 0.2780\n",
      "Epoch 444/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4365 - acc: 0.2146 - val_loss: 2.2937 - val_acc: 0.2742\n",
      "Epoch 445/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4455 - acc: 0.2164 - val_loss: 2.3034 - val_acc: 0.2561\n",
      "Epoch 446/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4568 - acc: 0.2148 - val_loss: 2.2933 - val_acc: 0.2689\n",
      "Epoch 447/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4347 - acc: 0.2151 - val_loss: 2.2538 - val_acc: 0.2780\n",
      "Epoch 448/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4295 - acc: 0.2171 - val_loss: 2.2689 - val_acc: 0.2750\n",
      "Epoch 449/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4385 - acc: 0.2145 - val_loss: 2.3306 - val_acc: 0.2629\n",
      "Epoch 450/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4405 - acc: 0.2110 - val_loss: 2.2557 - val_acc: 0.2750\n",
      "Epoch 451/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4547 - acc: 0.2071 - val_loss: 2.3198 - val_acc: 0.2621\n",
      "Epoch 452/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4402 - acc: 0.2179 - val_loss: 2.2737 - val_acc: 0.2773\n",
      "Epoch 453/1000\n",
      "11872/11872 [==============================] - 1s 46us/step - loss: 2.4335 - acc: 0.2131 - val_loss: 2.2892 - val_acc: 0.2689\n",
      "Epoch 454/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4401 - acc: 0.2166 - val_loss: 2.2814 - val_acc: 0.2705\n",
      "Epoch 455/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4432 - acc: 0.2147 - val_loss: 2.2644 - val_acc: 0.2712\n",
      "Epoch 456/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4353 - acc: 0.2138 - val_loss: 2.2988 - val_acc: 0.2667\n",
      "Epoch 457/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4419 - acc: 0.2134 - val_loss: 2.2586 - val_acc: 0.2689\n",
      "Epoch 458/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4415 - acc: 0.2150 - val_loss: 2.2523 - val_acc: 0.2750\n",
      "Epoch 459/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4381 - acc: 0.2122 - val_loss: 2.3308 - val_acc: 0.2523\n",
      "Epoch 460/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4352 - acc: 0.2106 - val_loss: 2.3030 - val_acc: 0.2727\n",
      "Epoch 461/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4371 - acc: 0.2161 - val_loss: 2.2862 - val_acc: 0.2750\n",
      "Epoch 462/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4299 - acc: 0.2181 - val_loss: 2.2970 - val_acc: 0.2750\n",
      "Epoch 463/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4399 - acc: 0.2127 - val_loss: 2.3008 - val_acc: 0.2727\n",
      "Epoch 464/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4286 - acc: 0.2189 - val_loss: 2.2717 - val_acc: 0.2780\n",
      "Epoch 465/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4315 - acc: 0.2139 - val_loss: 2.2853 - val_acc: 0.2652\n",
      "Epoch 466/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4431 - acc: 0.2115 - val_loss: 2.3025 - val_acc: 0.2659\n",
      "Epoch 467/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4391 - acc: 0.2091 - val_loss: 2.2752 - val_acc: 0.2697\n",
      "Epoch 468/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4422 - acc: 0.2139 - val_loss: 2.2695 - val_acc: 0.2826\n",
      "Epoch 469/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4379 - acc: 0.2127 - val_loss: 2.2927 - val_acc: 0.2598\n",
      "Epoch 470/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4445 - acc: 0.2136 - val_loss: 2.3068 - val_acc: 0.2636\n",
      "Epoch 471/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4447 - acc: 0.2130 - val_loss: 2.2748 - val_acc: 0.2720\n",
      "Epoch 472/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4382 - acc: 0.2113 - val_loss: 2.2685 - val_acc: 0.2803\n",
      "Epoch 473/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4319 - acc: 0.2171 - val_loss: 2.2820 - val_acc: 0.2750\n",
      "Epoch 474/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4331 - acc: 0.2137 - val_loss: 2.2480 - val_acc: 0.2803\n",
      "Epoch 475/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4412 - acc: 0.2126 - val_loss: 2.2733 - val_acc: 0.2720\n",
      "Epoch 476/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4354 - acc: 0.2149 - val_loss: 2.2639 - val_acc: 0.2780\n",
      "Epoch 477/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4311 - acc: 0.2209 - val_loss: 2.2592 - val_acc: 0.2795\n",
      "Epoch 478/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4424 - acc: 0.2102 - val_loss: 2.2718 - val_acc: 0.2727\n",
      "Epoch 479/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4331 - acc: 0.2171 - val_loss: 2.2539 - val_acc: 0.2848\n",
      "Epoch 480/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4344 - acc: 0.2152 - val_loss: 2.2884 - val_acc: 0.2727\n",
      "Epoch 481/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4322 - acc: 0.2112 - val_loss: 2.2427 - val_acc: 0.2833\n",
      "Epoch 482/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4480 - acc: 0.2143 - val_loss: 2.2703 - val_acc: 0.2742\n",
      "Epoch 483/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4362 - acc: 0.2147 - val_loss: 2.2504 - val_acc: 0.2803\n",
      "Epoch 484/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4284 - acc: 0.2204 - val_loss: 2.2471 - val_acc: 0.2811\n",
      "Epoch 485/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4342 - acc: 0.2214 - val_loss: 2.3463 - val_acc: 0.2364\n",
      "Epoch 486/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4282 - acc: 0.2168 - val_loss: 2.2665 - val_acc: 0.2720\n",
      "Epoch 487/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4290 - acc: 0.2147 - val_loss: 2.2859 - val_acc: 0.2742\n",
      "Epoch 488/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4394 - acc: 0.2145 - val_loss: 2.2754 - val_acc: 0.2697\n",
      "Epoch 489/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4421 - acc: 0.2143 - val_loss: 2.2757 - val_acc: 0.2742\n",
      "Epoch 490/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4380 - acc: 0.2214 - val_loss: 2.2521 - val_acc: 0.2773\n",
      "Epoch 491/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4358 - acc: 0.2208 - val_loss: 2.2624 - val_acc: 0.2811\n",
      "Epoch 492/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4285 - acc: 0.2204 - val_loss: 2.2728 - val_acc: 0.2773\n",
      "Epoch 493/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4407 - acc: 0.2103 - val_loss: 2.2955 - val_acc: 0.2712\n",
      "Epoch 494/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4279 - acc: 0.2166 - val_loss: 2.2495 - val_acc: 0.2773\n",
      "Epoch 495/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4402 - acc: 0.2128 - val_loss: 2.2955 - val_acc: 0.2735\n",
      "Epoch 496/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4239 - acc: 0.2184 - val_loss: 2.3212 - val_acc: 0.2455\n",
      "Epoch 497/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4286 - acc: 0.2129 - val_loss: 2.2661 - val_acc: 0.2667\n",
      "Epoch 498/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4188 - acc: 0.2166 - val_loss: 2.2620 - val_acc: 0.2833\n",
      "Epoch 499/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4311 - acc: 0.2133 - val_loss: 2.2542 - val_acc: 0.2788\n",
      "Epoch 500/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4304 - acc: 0.2175 - val_loss: 2.2893 - val_acc: 0.2652\n",
      "Epoch 501/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4273 - acc: 0.2182 - val_loss: 2.2678 - val_acc: 0.2848\n",
      "Epoch 502/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4349 - acc: 0.2155 - val_loss: 2.2776 - val_acc: 0.2720\n",
      "Epoch 503/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4286 - acc: 0.2145 - val_loss: 2.3017 - val_acc: 0.2667\n",
      "Epoch 504/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4345 - acc: 0.2144 - val_loss: 2.2730 - val_acc: 0.2735\n",
      "Epoch 505/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4402 - acc: 0.2149 - val_loss: 2.3185 - val_acc: 0.2659\n",
      "Epoch 506/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4340 - acc: 0.2177 - val_loss: 2.2439 - val_acc: 0.2826\n",
      "Epoch 507/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4418 - acc: 0.2171 - val_loss: 2.2536 - val_acc: 0.2758\n",
      "Epoch 508/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4352 - acc: 0.2122 - val_loss: 2.2565 - val_acc: 0.2811\n",
      "Epoch 509/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4172 - acc: 0.2158 - val_loss: 2.2726 - val_acc: 0.2727\n",
      "Epoch 510/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4364 - acc: 0.2174 - val_loss: 2.2432 - val_acc: 0.2811\n",
      "Epoch 511/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4364 - acc: 0.2166 - val_loss: 2.2646 - val_acc: 0.2818\n",
      "Epoch 512/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4397 - acc: 0.2118 - val_loss: 2.2470 - val_acc: 0.2848\n",
      "Epoch 513/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4305 - acc: 0.2139 - val_loss: 2.2610 - val_acc: 0.2788\n",
      "Epoch 514/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4295 - acc: 0.2165 - val_loss: 2.2454 - val_acc: 0.2773\n",
      "Epoch 515/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4291 - acc: 0.2120 - val_loss: 2.2663 - val_acc: 0.2758\n",
      "Epoch 516/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4341 - acc: 0.2108 - val_loss: 2.2465 - val_acc: 0.2864\n",
      "Epoch 517/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4287 - acc: 0.2211 - val_loss: 2.2623 - val_acc: 0.2833\n",
      "Epoch 518/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4323 - acc: 0.2126 - val_loss: 2.2672 - val_acc: 0.2811\n",
      "Epoch 519/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4304 - acc: 0.2151 - val_loss: 2.2724 - val_acc: 0.2788\n",
      "Epoch 520/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4309 - acc: 0.2175 - val_loss: 2.2997 - val_acc: 0.2758\n",
      "Epoch 521/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4303 - acc: 0.2160 - val_loss: 2.2607 - val_acc: 0.2742\n",
      "Epoch 522/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4302 - acc: 0.2165 - val_loss: 2.2825 - val_acc: 0.2765\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4259 - acc: 0.2188 - val_loss: 2.2698 - val_acc: 0.2742\n",
      "Epoch 524/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4248 - acc: 0.2170 - val_loss: 2.2533 - val_acc: 0.2841\n",
      "Epoch 525/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4259 - acc: 0.2188 - val_loss: 2.3026 - val_acc: 0.2636\n",
      "Epoch 526/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4292 - acc: 0.2123 - val_loss: 2.2578 - val_acc: 0.2750\n",
      "Epoch 527/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4340 - acc: 0.2139 - val_loss: 2.2892 - val_acc: 0.2568\n",
      "Epoch 528/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4415 - acc: 0.2160 - val_loss: 2.2385 - val_acc: 0.2818\n",
      "Epoch 529/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4305 - acc: 0.2153 - val_loss: 2.2639 - val_acc: 0.2841\n",
      "Epoch 530/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4287 - acc: 0.2174 - val_loss: 2.2525 - val_acc: 0.2864\n",
      "Epoch 531/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4307 - acc: 0.2176 - val_loss: 2.2522 - val_acc: 0.2811\n",
      "Epoch 532/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4381 - acc: 0.2120 - val_loss: 2.2533 - val_acc: 0.2818\n",
      "Epoch 533/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4401 - acc: 0.2155 - val_loss: 2.2526 - val_acc: 0.2795\n",
      "Epoch 534/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4282 - acc: 0.2106 - val_loss: 2.2492 - val_acc: 0.2841\n",
      "Epoch 535/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4250 - acc: 0.2134 - val_loss: 2.2749 - val_acc: 0.2659\n",
      "Epoch 536/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4371 - acc: 0.2163 - val_loss: 2.2517 - val_acc: 0.2765\n",
      "Epoch 537/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4326 - acc: 0.2145 - val_loss: 2.2739 - val_acc: 0.2705\n",
      "Epoch 538/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4233 - acc: 0.2203 - val_loss: 2.2681 - val_acc: 0.2727\n",
      "Epoch 539/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4407 - acc: 0.2177 - val_loss: 2.2405 - val_acc: 0.2864\n",
      "Epoch 540/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4187 - acc: 0.2217 - val_loss: 2.2430 - val_acc: 0.2886\n",
      "Epoch 541/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4306 - acc: 0.2168 - val_loss: 2.2708 - val_acc: 0.2742\n",
      "Epoch 542/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4205 - acc: 0.2189 - val_loss: 2.2838 - val_acc: 0.2758\n",
      "Epoch 543/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4136 - acc: 0.2202 - val_loss: 2.2952 - val_acc: 0.2705\n",
      "Epoch 544/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4260 - acc: 0.2229 - val_loss: 2.2645 - val_acc: 0.2758\n",
      "Epoch 545/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4443 - acc: 0.2073 - val_loss: 2.2691 - val_acc: 0.2773\n",
      "Epoch 546/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4296 - acc: 0.2204 - val_loss: 2.2600 - val_acc: 0.2833\n",
      "Epoch 547/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4253 - acc: 0.2146 - val_loss: 2.2744 - val_acc: 0.2720\n",
      "Epoch 548/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4367 - acc: 0.2154 - val_loss: 2.2534 - val_acc: 0.2826\n",
      "Epoch 549/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4193 - acc: 0.2201 - val_loss: 2.2549 - val_acc: 0.2833\n",
      "Epoch 550/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4333 - acc: 0.2149 - val_loss: 2.2787 - val_acc: 0.2788\n",
      "Epoch 551/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4336 - acc: 0.2165 - val_loss: 2.2335 - val_acc: 0.2856\n",
      "Epoch 552/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4291 - acc: 0.2156 - val_loss: 2.2765 - val_acc: 0.2765\n",
      "Epoch 553/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4187 - acc: 0.2182 - val_loss: 2.2881 - val_acc: 0.2674\n",
      "Epoch 554/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4236 - acc: 0.2174 - val_loss: 2.2559 - val_acc: 0.2803\n",
      "Epoch 555/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4252 - acc: 0.2180 - val_loss: 2.2644 - val_acc: 0.2727\n",
      "Epoch 556/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4297 - acc: 0.2184 - val_loss: 2.2372 - val_acc: 0.2894\n",
      "Epoch 557/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4162 - acc: 0.2239 - val_loss: 2.2545 - val_acc: 0.2803\n",
      "Epoch 558/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4314 - acc: 0.2137 - val_loss: 2.2539 - val_acc: 0.2795\n",
      "Epoch 559/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4219 - acc: 0.2220 - val_loss: 2.2444 - val_acc: 0.2841\n",
      "Epoch 560/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4150 - acc: 0.2202 - val_loss: 2.2605 - val_acc: 0.2780\n",
      "Epoch 561/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4250 - acc: 0.2183 - val_loss: 2.2495 - val_acc: 0.2848\n",
      "Epoch 562/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4346 - acc: 0.2138 - val_loss: 2.2770 - val_acc: 0.2765\n",
      "Epoch 563/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4176 - acc: 0.2148 - val_loss: 2.2529 - val_acc: 0.2811\n",
      "Epoch 564/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4293 - acc: 0.2173 - val_loss: 2.2395 - val_acc: 0.2902\n",
      "Epoch 565/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4239 - acc: 0.2166 - val_loss: 2.2364 - val_acc: 0.2811\n",
      "Epoch 566/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4219 - acc: 0.2191 - val_loss: 2.2304 - val_acc: 0.2871\n",
      "Epoch 567/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4206 - acc: 0.2186 - val_loss: 2.2478 - val_acc: 0.2864\n",
      "Epoch 568/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4336 - acc: 0.2194 - val_loss: 2.2949 - val_acc: 0.2697\n",
      "Epoch 569/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4269 - acc: 0.2133 - val_loss: 2.2794 - val_acc: 0.2697\n",
      "Epoch 570/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4286 - acc: 0.2167 - val_loss: 2.2468 - val_acc: 0.2841\n",
      "Epoch 571/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4231 - acc: 0.2209 - val_loss: 2.2681 - val_acc: 0.2742\n",
      "Epoch 572/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4284 - acc: 0.2155 - val_loss: 2.2785 - val_acc: 0.2773\n",
      "Epoch 573/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4278 - acc: 0.2163 - val_loss: 2.2738 - val_acc: 0.2818\n",
      "Epoch 574/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4264 - acc: 0.2150 - val_loss: 2.2591 - val_acc: 0.2818\n",
      "Epoch 575/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4222 - acc: 0.2165 - val_loss: 2.2437 - val_acc: 0.2811\n",
      "Epoch 576/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4274 - acc: 0.2166 - val_loss: 2.3228 - val_acc: 0.2462\n",
      "Epoch 577/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4153 - acc: 0.2206 - val_loss: 2.2418 - val_acc: 0.2811\n",
      "Epoch 578/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4298 - acc: 0.2135 - val_loss: 2.2511 - val_acc: 0.2856\n",
      "Epoch 579/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4161 - acc: 0.2209 - val_loss: 2.2895 - val_acc: 0.2720\n",
      "Epoch 580/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4245 - acc: 0.2203 - val_loss: 2.2695 - val_acc: 0.2727\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4291 - acc: 0.2194 - val_loss: 2.3060 - val_acc: 0.2447\n",
      "Epoch 582/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4405 - acc: 0.2134 - val_loss: 2.2563 - val_acc: 0.2818\n",
      "Epoch 583/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4255 - acc: 0.2134 - val_loss: 2.2790 - val_acc: 0.2864\n",
      "Epoch 584/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4265 - acc: 0.2143 - val_loss: 2.2725 - val_acc: 0.2795\n",
      "Epoch 585/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4179 - acc: 0.2189 - val_loss: 2.2262 - val_acc: 0.2894\n",
      "Epoch 586/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4237 - acc: 0.2188 - val_loss: 2.2836 - val_acc: 0.2795\n",
      "Epoch 587/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4250 - acc: 0.2146 - val_loss: 2.2620 - val_acc: 0.2780\n",
      "Epoch 588/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4277 - acc: 0.2124 - val_loss: 2.2710 - val_acc: 0.2803\n",
      "Epoch 589/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4257 - acc: 0.2175 - val_loss: 2.2557 - val_acc: 0.2811\n",
      "Epoch 590/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4164 - acc: 0.2193 - val_loss: 2.2790 - val_acc: 0.2765\n",
      "Epoch 591/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4236 - acc: 0.2214 - val_loss: 2.2909 - val_acc: 0.2591\n",
      "Epoch 592/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4362 - acc: 0.2152 - val_loss: 2.2619 - val_acc: 0.2780\n",
      "Epoch 593/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4139 - acc: 0.2225 - val_loss: 2.2431 - val_acc: 0.2833\n",
      "Epoch 594/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4276 - acc: 0.2170 - val_loss: 2.2289 - val_acc: 0.2841\n",
      "Epoch 595/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4225 - acc: 0.2181 - val_loss: 2.2801 - val_acc: 0.2659\n",
      "Epoch 596/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4184 - acc: 0.2153 - val_loss: 2.2271 - val_acc: 0.2841\n",
      "Epoch 597/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4276 - acc: 0.2149 - val_loss: 2.2708 - val_acc: 0.2780\n",
      "Epoch 598/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4266 - acc: 0.2179 - val_loss: 2.2516 - val_acc: 0.2841\n",
      "Epoch 599/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4309 - acc: 0.2189 - val_loss: 2.2815 - val_acc: 0.2705\n",
      "Epoch 600/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4190 - acc: 0.2157 - val_loss: 2.2561 - val_acc: 0.2811\n",
      "Epoch 601/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4288 - acc: 0.2186 - val_loss: 2.2474 - val_acc: 0.2902\n",
      "Epoch 602/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4199 - acc: 0.2220 - val_loss: 2.2441 - val_acc: 0.2932\n",
      "Epoch 603/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4201 - acc: 0.2171 - val_loss: 2.2580 - val_acc: 0.2848\n",
      "Epoch 604/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4164 - acc: 0.2187 - val_loss: 2.2261 - val_acc: 0.2833\n",
      "Epoch 605/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4095 - acc: 0.2204 - val_loss: 2.2835 - val_acc: 0.2795\n",
      "Epoch 606/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4170 - acc: 0.2184 - val_loss: 2.2379 - val_acc: 0.2917\n",
      "Epoch 607/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4129 - acc: 0.2203 - val_loss: 2.2400 - val_acc: 0.2886\n",
      "Epoch 608/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4180 - acc: 0.2173 - val_loss: 2.2551 - val_acc: 0.2886\n",
      "Epoch 609/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4225 - acc: 0.2166 - val_loss: 2.2549 - val_acc: 0.2795\n",
      "Epoch 610/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4245 - acc: 0.2218 - val_loss: 2.2443 - val_acc: 0.2788\n",
      "Epoch 611/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4080 - acc: 0.2212 - val_loss: 2.2475 - val_acc: 0.2864\n",
      "Epoch 612/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4068 - acc: 0.2230 - val_loss: 2.2444 - val_acc: 0.2833\n",
      "Epoch 613/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4422 - acc: 0.2135 - val_loss: 2.2509 - val_acc: 0.2856\n",
      "Epoch 614/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4225 - acc: 0.2197 - val_loss: 2.2255 - val_acc: 0.2902\n",
      "Epoch 615/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4203 - acc: 0.2194 - val_loss: 2.2869 - val_acc: 0.2583\n",
      "Epoch 616/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4162 - acc: 0.2214 - val_loss: 2.2614 - val_acc: 0.2795\n",
      "Epoch 617/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4139 - acc: 0.2217 - val_loss: 2.2553 - val_acc: 0.2720\n",
      "Epoch 618/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4194 - acc: 0.2203 - val_loss: 2.2501 - val_acc: 0.2795\n",
      "Epoch 619/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4296 - acc: 0.2161 - val_loss: 2.3070 - val_acc: 0.2545\n",
      "Epoch 620/1000\n",
      "11872/11872 [==============================] - 0s 34us/step - loss: 2.4249 - acc: 0.2150 - val_loss: 2.2466 - val_acc: 0.2765\n",
      "Epoch 621/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4158 - acc: 0.2195 - val_loss: 2.2565 - val_acc: 0.2818\n",
      "Epoch 622/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4158 - acc: 0.2188 - val_loss: 2.2452 - val_acc: 0.2773\n",
      "Epoch 623/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4090 - acc: 0.2241 - val_loss: 2.2233 - val_acc: 0.2856\n",
      "Epoch 624/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4108 - acc: 0.2220 - val_loss: 2.2789 - val_acc: 0.2636\n",
      "Epoch 625/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4315 - acc: 0.2188 - val_loss: 2.2331 - val_acc: 0.2894\n",
      "Epoch 626/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4185 - acc: 0.2210 - val_loss: 2.2749 - val_acc: 0.2636\n",
      "Epoch 627/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4124 - acc: 0.2252 - val_loss: 2.2446 - val_acc: 0.2879\n",
      "Epoch 628/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4187 - acc: 0.2190 - val_loss: 2.2358 - val_acc: 0.2932\n",
      "Epoch 629/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4221 - acc: 0.2179 - val_loss: 2.2375 - val_acc: 0.2803\n",
      "Epoch 630/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4156 - acc: 0.2197 - val_loss: 2.2829 - val_acc: 0.2758\n",
      "Epoch 631/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4283 - acc: 0.2172 - val_loss: 2.2528 - val_acc: 0.2833\n",
      "Epoch 632/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4122 - acc: 0.2242 - val_loss: 2.2815 - val_acc: 0.2742\n",
      "Epoch 633/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4174 - acc: 0.2190 - val_loss: 2.2319 - val_acc: 0.2924\n",
      "Epoch 634/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4129 - acc: 0.2237 - val_loss: 2.2582 - val_acc: 0.2758\n",
      "Epoch 635/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4214 - acc: 0.2207 - val_loss: 2.2357 - val_acc: 0.2894\n",
      "Epoch 636/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4258 - acc: 0.2202 - val_loss: 2.2535 - val_acc: 0.2826\n",
      "Epoch 637/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4209 - acc: 0.2174 - val_loss: 2.2448 - val_acc: 0.2886\n",
      "Epoch 638/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4137 - acc: 0.2194 - val_loss: 2.2776 - val_acc: 0.2811\n",
      "Epoch 639/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4197 - acc: 0.2175 - val_loss: 2.2384 - val_acc: 0.2917\n",
      "Epoch 640/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4176 - acc: 0.2232 - val_loss: 2.2234 - val_acc: 0.2917\n",
      "Epoch 641/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4182 - acc: 0.2189 - val_loss: 2.2524 - val_acc: 0.2864\n",
      "Epoch 642/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4212 - acc: 0.2214 - val_loss: 2.2646 - val_acc: 0.2765\n",
      "Epoch 643/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4162 - acc: 0.2193 - val_loss: 2.2234 - val_acc: 0.2795\n",
      "Epoch 644/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4130 - acc: 0.2183 - val_loss: 2.2874 - val_acc: 0.2689\n",
      "Epoch 645/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4185 - acc: 0.2203 - val_loss: 2.2313 - val_acc: 0.2879\n",
      "Epoch 646/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4190 - acc: 0.2216 - val_loss: 2.3057 - val_acc: 0.2659\n",
      "Epoch 647/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4220 - acc: 0.2169 - val_loss: 2.2276 - val_acc: 0.2894\n",
      "Epoch 648/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4258 - acc: 0.2188 - val_loss: 2.2517 - val_acc: 0.2902\n",
      "Epoch 649/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4254 - acc: 0.2182 - val_loss: 2.2503 - val_acc: 0.2871\n",
      "Epoch 650/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4136 - acc: 0.2194 - val_loss: 2.2501 - val_acc: 0.2841\n",
      "Epoch 651/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4210 - acc: 0.2185 - val_loss: 2.2495 - val_acc: 0.2811\n",
      "Epoch 652/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4136 - acc: 0.2193 - val_loss: 2.2289 - val_acc: 0.2848\n",
      "Epoch 653/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4069 - acc: 0.2200 - val_loss: 2.2971 - val_acc: 0.2614\n",
      "Epoch 654/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4224 - acc: 0.2192 - val_loss: 2.2503 - val_acc: 0.2879\n",
      "Epoch 655/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4205 - acc: 0.2218 - val_loss: 2.2968 - val_acc: 0.2667\n",
      "Epoch 656/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4305 - acc: 0.2127 - val_loss: 2.3185 - val_acc: 0.2508\n",
      "Epoch 657/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4185 - acc: 0.2234 - val_loss: 2.2643 - val_acc: 0.2886\n",
      "Epoch 658/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4199 - acc: 0.2183 - val_loss: 2.2503 - val_acc: 0.2902\n",
      "Epoch 659/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4193 - acc: 0.2218 - val_loss: 2.3084 - val_acc: 0.2523\n",
      "Epoch 660/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4188 - acc: 0.2180 - val_loss: 2.2526 - val_acc: 0.2864\n",
      "Epoch 661/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4137 - acc: 0.2220 - val_loss: 2.2450 - val_acc: 0.2864\n",
      "Epoch 662/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4182 - acc: 0.2209 - val_loss: 2.2590 - val_acc: 0.2758\n",
      "Epoch 663/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4221 - acc: 0.2213 - val_loss: 2.2469 - val_acc: 0.2871\n",
      "Epoch 664/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4282 - acc: 0.2171 - val_loss: 2.2371 - val_acc: 0.2977\n",
      "Epoch 665/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4199 - acc: 0.2183 - val_loss: 2.2165 - val_acc: 0.2879\n",
      "Epoch 666/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4181 - acc: 0.2212 - val_loss: 2.2432 - val_acc: 0.2788\n",
      "Epoch 667/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4203 - acc: 0.2171 - val_loss: 2.2279 - val_acc: 0.2955\n",
      "Epoch 668/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4089 - acc: 0.2232 - val_loss: 2.2564 - val_acc: 0.2788\n",
      "Epoch 669/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4199 - acc: 0.2174 - val_loss: 2.2472 - val_acc: 0.2894\n",
      "Epoch 670/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4064 - acc: 0.2209 - val_loss: 2.2186 - val_acc: 0.2864\n",
      "Epoch 671/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4236 - acc: 0.2179 - val_loss: 2.2343 - val_acc: 0.2924\n",
      "Epoch 672/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4172 - acc: 0.2194 - val_loss: 2.2433 - val_acc: 0.2780\n",
      "Epoch 673/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4200 - acc: 0.2189 - val_loss: 2.2468 - val_acc: 0.2811\n",
      "Epoch 674/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4027 - acc: 0.2244 - val_loss: 2.2790 - val_acc: 0.2667\n",
      "Epoch 675/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4165 - acc: 0.2209 - val_loss: 2.2298 - val_acc: 0.2902\n",
      "Epoch 676/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4186 - acc: 0.2228 - val_loss: 2.2240 - val_acc: 0.2917\n",
      "Epoch 677/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4094 - acc: 0.2224 - val_loss: 2.2463 - val_acc: 0.2962\n",
      "Epoch 678/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4156 - acc: 0.2232 - val_loss: 2.2546 - val_acc: 0.2818\n",
      "Epoch 679/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4062 - acc: 0.2233 - val_loss: 2.2398 - val_acc: 0.2811\n",
      "Epoch 680/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4167 - acc: 0.2231 - val_loss: 2.2360 - val_acc: 0.2947\n",
      "Epoch 681/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4107 - acc: 0.2193 - val_loss: 2.2592 - val_acc: 0.2765\n",
      "Epoch 682/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4125 - acc: 0.2229 - val_loss: 2.2514 - val_acc: 0.2773\n",
      "Epoch 683/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4188 - acc: 0.2169 - val_loss: 2.2392 - val_acc: 0.2894\n",
      "Epoch 684/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4060 - acc: 0.2242 - val_loss: 2.2247 - val_acc: 0.2826\n",
      "Epoch 685/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4119 - acc: 0.2222 - val_loss: 2.2376 - val_acc: 0.2871\n",
      "Epoch 686/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4213 - acc: 0.2130 - val_loss: 2.2445 - val_acc: 0.2856\n",
      "Epoch 687/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4067 - acc: 0.2242 - val_loss: 2.2142 - val_acc: 0.2917\n",
      "Epoch 688/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4098 - acc: 0.2166 - val_loss: 2.2225 - val_acc: 0.2909\n",
      "Epoch 689/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4025 - acc: 0.2273 - val_loss: 2.2653 - val_acc: 0.2689\n",
      "Epoch 690/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4112 - acc: 0.2218 - val_loss: 2.2141 - val_acc: 0.2917\n",
      "Epoch 691/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4152 - acc: 0.2198 - val_loss: 2.2268 - val_acc: 0.2902\n",
      "Epoch 692/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4145 - acc: 0.2194 - val_loss: 2.2595 - val_acc: 0.2765\n",
      "Epoch 693/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4069 - acc: 0.2207 - val_loss: 2.2446 - val_acc: 0.2939\n",
      "Epoch 694/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4091 - acc: 0.2257 - val_loss: 2.2188 - val_acc: 0.2909\n",
      "Epoch 695/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4236 - acc: 0.2166 - val_loss: 2.2248 - val_acc: 0.2924\n",
      "Epoch 696/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4071 - acc: 0.2226 - val_loss: 2.2110 - val_acc: 0.2947\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4114 - acc: 0.2203 - val_loss: 2.2246 - val_acc: 0.2962\n",
      "Epoch 698/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3972 - acc: 0.2254 - val_loss: 2.2209 - val_acc: 0.2955\n",
      "Epoch 699/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4026 - acc: 0.2251 - val_loss: 2.2438 - val_acc: 0.2864\n",
      "Epoch 700/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4154 - acc: 0.2197 - val_loss: 2.2615 - val_acc: 0.2803\n",
      "Epoch 701/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4228 - acc: 0.2239 - val_loss: 2.2360 - val_acc: 0.2848\n",
      "Epoch 702/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4108 - acc: 0.2198 - val_loss: 2.2404 - val_acc: 0.2848\n",
      "Epoch 703/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4107 - acc: 0.2238 - val_loss: 2.2194 - val_acc: 0.2924\n",
      "Epoch 704/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4176 - acc: 0.2181 - val_loss: 2.2121 - val_acc: 0.2886\n",
      "Epoch 705/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4140 - acc: 0.2201 - val_loss: 2.2127 - val_acc: 0.2902\n",
      "Epoch 706/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4133 - acc: 0.2165 - val_loss: 2.2138 - val_acc: 0.2970\n",
      "Epoch 707/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4242 - acc: 0.2236 - val_loss: 2.2192 - val_acc: 0.2970\n",
      "Epoch 708/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4079 - acc: 0.2228 - val_loss: 2.2522 - val_acc: 0.2879\n",
      "Epoch 709/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4125 - acc: 0.2240 - val_loss: 2.2177 - val_acc: 0.2833\n",
      "Epoch 710/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4117 - acc: 0.2217 - val_loss: 2.2142 - val_acc: 0.2932\n",
      "Epoch 711/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4205 - acc: 0.2163 - val_loss: 2.2705 - val_acc: 0.2871\n",
      "Epoch 712/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4112 - acc: 0.2225 - val_loss: 2.2398 - val_acc: 0.2826\n",
      "Epoch 713/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4210 - acc: 0.2207 - val_loss: 2.2218 - val_acc: 0.2848\n",
      "Epoch 714/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4137 - acc: 0.2188 - val_loss: 2.2176 - val_acc: 0.2924\n",
      "Epoch 715/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4027 - acc: 0.2276 - val_loss: 2.2296 - val_acc: 0.2955\n",
      "Epoch 716/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4107 - acc: 0.2230 - val_loss: 2.2408 - val_acc: 0.2841\n",
      "Epoch 717/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4148 - acc: 0.2227 - val_loss: 2.2284 - val_acc: 0.2924\n",
      "Epoch 718/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4054 - acc: 0.2223 - val_loss: 2.2274 - val_acc: 0.2970\n",
      "Epoch 719/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4134 - acc: 0.2266 - val_loss: 2.2182 - val_acc: 0.2894\n",
      "Epoch 720/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3918 - acc: 0.2282 - val_loss: 2.2157 - val_acc: 0.2962\n",
      "Epoch 721/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4067 - acc: 0.2220 - val_loss: 2.2342 - val_acc: 0.2894\n",
      "Epoch 722/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4020 - acc: 0.2252 - val_loss: 2.2233 - val_acc: 0.2917\n",
      "Epoch 723/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4061 - acc: 0.2258 - val_loss: 2.2149 - val_acc: 0.2985\n",
      "Epoch 724/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4156 - acc: 0.2234 - val_loss: 2.2161 - val_acc: 0.2947\n",
      "Epoch 725/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4194 - acc: 0.2199 - val_loss: 2.2681 - val_acc: 0.2856\n",
      "Epoch 726/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4091 - acc: 0.2226 - val_loss: 2.2508 - val_acc: 0.2871\n",
      "Epoch 727/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3989 - acc: 0.2259 - val_loss: 2.2797 - val_acc: 0.2758\n",
      "Epoch 728/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4073 - acc: 0.2249 - val_loss: 2.2056 - val_acc: 0.2932\n",
      "Epoch 729/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3998 - acc: 0.2247 - val_loss: 2.2211 - val_acc: 0.2917\n",
      "Epoch 730/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4066 - acc: 0.2216 - val_loss: 2.2330 - val_acc: 0.2977\n",
      "Epoch 731/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4140 - acc: 0.2198 - val_loss: 2.2298 - val_acc: 0.2886\n",
      "Epoch 732/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4108 - acc: 0.2221 - val_loss: 2.2279 - val_acc: 0.2917\n",
      "Epoch 733/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4040 - acc: 0.2198 - val_loss: 2.2362 - val_acc: 0.2917\n",
      "Epoch 734/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4099 - acc: 0.2205 - val_loss: 2.2329 - val_acc: 0.2871\n",
      "Epoch 735/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4099 - acc: 0.2209 - val_loss: 2.2179 - val_acc: 0.2970\n",
      "Epoch 736/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4266 - acc: 0.2156 - val_loss: 2.2469 - val_acc: 0.2833\n",
      "Epoch 737/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4173 - acc: 0.2202 - val_loss: 2.2249 - val_acc: 0.2841\n",
      "Epoch 738/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4088 - acc: 0.2220 - val_loss: 2.2163 - val_acc: 0.3023\n",
      "Epoch 739/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4085 - acc: 0.2235 - val_loss: 2.2321 - val_acc: 0.2962\n",
      "Epoch 740/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4091 - acc: 0.2270 - val_loss: 2.2098 - val_acc: 0.3000\n",
      "Epoch 741/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4055 - acc: 0.2190 - val_loss: 2.2493 - val_acc: 0.2856\n",
      "Epoch 742/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4066 - acc: 0.2230 - val_loss: 2.2303 - val_acc: 0.2992\n",
      "Epoch 743/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4044 - acc: 0.2246 - val_loss: 2.2143 - val_acc: 0.2909\n",
      "Epoch 744/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4136 - acc: 0.2185 - val_loss: 2.2143 - val_acc: 0.2902\n",
      "Epoch 745/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4135 - acc: 0.2205 - val_loss: 2.2106 - val_acc: 0.2902\n",
      "Epoch 746/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4072 - acc: 0.2270 - val_loss: 2.2311 - val_acc: 0.2939\n",
      "Epoch 747/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4021 - acc: 0.2198 - val_loss: 2.2090 - val_acc: 0.2977\n",
      "Epoch 748/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4133 - acc: 0.2198 - val_loss: 2.2376 - val_acc: 0.2924\n",
      "Epoch 749/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3956 - acc: 0.2251 - val_loss: 2.2125 - val_acc: 0.2970\n",
      "Epoch 750/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3997 - acc: 0.2241 - val_loss: 2.2257 - val_acc: 0.2924\n",
      "Epoch 751/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4111 - acc: 0.2219 - val_loss: 2.2111 - val_acc: 0.2977\n",
      "Epoch 752/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4069 - acc: 0.2233 - val_loss: 2.2292 - val_acc: 0.2864\n",
      "Epoch 753/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4137 - acc: 0.2194 - val_loss: 2.2448 - val_acc: 0.2879\n",
      "Epoch 754/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4057 - acc: 0.2222 - val_loss: 2.2418 - val_acc: 0.2856\n",
      "Epoch 755/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4021 - acc: 0.2226 - val_loss: 2.2797 - val_acc: 0.2697\n",
      "Epoch 756/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4148 - acc: 0.2225 - val_loss: 2.2442 - val_acc: 0.2871\n",
      "Epoch 757/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4071 - acc: 0.2257 - val_loss: 2.2423 - val_acc: 0.2864\n",
      "Epoch 758/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4017 - acc: 0.2240 - val_loss: 2.2646 - val_acc: 0.2682\n",
      "Epoch 759/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4158 - acc: 0.2185 - val_loss: 2.2297 - val_acc: 0.2917\n",
      "Epoch 760/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4056 - acc: 0.2233 - val_loss: 2.2555 - val_acc: 0.2773\n",
      "Epoch 761/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4036 - acc: 0.2196 - val_loss: 2.2597 - val_acc: 0.2833\n",
      "Epoch 762/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4015 - acc: 0.2193 - val_loss: 2.2142 - val_acc: 0.2970\n",
      "Epoch 763/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4096 - acc: 0.2222 - val_loss: 2.2101 - val_acc: 0.2909\n",
      "Epoch 764/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4003 - acc: 0.2250 - val_loss: 2.2194 - val_acc: 0.2947\n",
      "Epoch 765/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4144 - acc: 0.2158 - val_loss: 2.2207 - val_acc: 0.2909\n",
      "Epoch 766/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4179 - acc: 0.2214 - val_loss: 2.2087 - val_acc: 0.2955\n",
      "Epoch 767/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3979 - acc: 0.2195 - val_loss: 2.2292 - val_acc: 0.2962\n",
      "Epoch 768/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4275 - acc: 0.2173 - val_loss: 2.2078 - val_acc: 0.2962\n",
      "Epoch 769/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4150 - acc: 0.2226 - val_loss: 2.2361 - val_acc: 0.2856\n",
      "Epoch 770/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4176 - acc: 0.2193 - val_loss: 2.2202 - val_acc: 0.3038\n",
      "Epoch 771/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4048 - acc: 0.2246 - val_loss: 2.2162 - val_acc: 0.3038\n",
      "Epoch 772/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3895 - acc: 0.2232 - val_loss: 2.2200 - val_acc: 0.2977\n",
      "Epoch 773/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4016 - acc: 0.2169 - val_loss: 2.2338 - val_acc: 0.2848\n",
      "Epoch 774/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4019 - acc: 0.2261 - val_loss: 2.2428 - val_acc: 0.2909\n",
      "Epoch 775/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3985 - acc: 0.2228 - val_loss: 2.2122 - val_acc: 0.2962\n",
      "Epoch 776/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4089 - acc: 0.2213 - val_loss: 2.2313 - val_acc: 0.2962\n",
      "Epoch 777/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4059 - acc: 0.2213 - val_loss: 2.2381 - val_acc: 0.2826\n",
      "Epoch 778/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4017 - acc: 0.2200 - val_loss: 2.2336 - val_acc: 0.2909\n",
      "Epoch 779/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4102 - acc: 0.2208 - val_loss: 2.2929 - val_acc: 0.2598\n",
      "Epoch 780/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4097 - acc: 0.2245 - val_loss: 2.2899 - val_acc: 0.2598\n",
      "Epoch 781/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4106 - acc: 0.2223 - val_loss: 2.2380 - val_acc: 0.2841\n",
      "Epoch 782/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3949 - acc: 0.2272 - val_loss: 2.2398 - val_acc: 0.2856\n",
      "Epoch 783/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4039 - acc: 0.2269 - val_loss: 2.2392 - val_acc: 0.2917\n",
      "Epoch 784/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4150 - acc: 0.2272 - val_loss: 2.2063 - val_acc: 0.3015\n",
      "Epoch 785/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4074 - acc: 0.2193 - val_loss: 2.2681 - val_acc: 0.2780\n",
      "Epoch 786/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4010 - acc: 0.2286 - val_loss: 2.2336 - val_acc: 0.2924\n",
      "Epoch 787/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4026 - acc: 0.2198 - val_loss: 2.2528 - val_acc: 0.2750\n",
      "Epoch 788/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4039 - acc: 0.2216 - val_loss: 2.2207 - val_acc: 0.2856\n",
      "Epoch 789/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4032 - acc: 0.2275 - val_loss: 2.2142 - val_acc: 0.3038\n",
      "Epoch 790/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4051 - acc: 0.2242 - val_loss: 2.2191 - val_acc: 0.2955\n",
      "Epoch 791/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4069 - acc: 0.2220 - val_loss: 2.2383 - val_acc: 0.2879\n",
      "Epoch 792/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3959 - acc: 0.2248 - val_loss: 2.2690 - val_acc: 0.2621\n",
      "Epoch 793/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4022 - acc: 0.2192 - val_loss: 2.2266 - val_acc: 0.2917\n",
      "Epoch 794/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3997 - acc: 0.2214 - val_loss: 2.2677 - val_acc: 0.2629\n",
      "Epoch 795/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4098 - acc: 0.2171 - val_loss: 2.2541 - val_acc: 0.2879\n",
      "Epoch 796/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4077 - acc: 0.2232 - val_loss: 2.2629 - val_acc: 0.2818\n",
      "Epoch 797/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4158 - acc: 0.2208 - val_loss: 2.3100 - val_acc: 0.2644\n",
      "Epoch 798/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3992 - acc: 0.2267 - val_loss: 2.2126 - val_acc: 0.2977\n",
      "Epoch 799/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3957 - acc: 0.2225 - val_loss: 2.2062 - val_acc: 0.2962\n",
      "Epoch 800/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4009 - acc: 0.2247 - val_loss: 2.2264 - val_acc: 0.2795\n",
      "Epoch 801/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4006 - acc: 0.2248 - val_loss: 2.2027 - val_acc: 0.2992\n",
      "Epoch 802/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4015 - acc: 0.2256 - val_loss: 2.2715 - val_acc: 0.2636\n",
      "Epoch 803/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4092 - acc: 0.2202 - val_loss: 2.2296 - val_acc: 0.2902\n",
      "Epoch 804/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4060 - acc: 0.2253 - val_loss: 2.2183 - val_acc: 0.2939\n",
      "Epoch 805/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4095 - acc: 0.2215 - val_loss: 2.2245 - val_acc: 0.2917\n",
      "Epoch 806/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3882 - acc: 0.2308 - val_loss: 2.2092 - val_acc: 0.2947\n",
      "Epoch 807/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4026 - acc: 0.2257 - val_loss: 2.2059 - val_acc: 0.2977\n",
      "Epoch 808/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4118 - acc: 0.2223 - val_loss: 2.2138 - val_acc: 0.2985\n",
      "Epoch 809/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4107 - acc: 0.2177 - val_loss: 2.2024 - val_acc: 0.2932\n",
      "Epoch 810/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4020 - acc: 0.2210 - val_loss: 2.2373 - val_acc: 0.2932\n",
      "Epoch 811/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4070 - acc: 0.2224 - val_loss: 2.2318 - val_acc: 0.2879\n",
      "Epoch 812/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3995 - acc: 0.2236 - val_loss: 2.2102 - val_acc: 0.2992\n",
      "Epoch 813/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4052 - acc: 0.2203 - val_loss: 2.2298 - val_acc: 0.2909\n",
      "Epoch 814/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4159 - acc: 0.2200 - val_loss: 2.2145 - val_acc: 0.2917\n",
      "Epoch 815/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4157 - acc: 0.2218 - val_loss: 2.2481 - val_acc: 0.2742\n",
      "Epoch 816/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3976 - acc: 0.2253 - val_loss: 2.2208 - val_acc: 0.3000\n",
      "Epoch 817/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4018 - acc: 0.2251 - val_loss: 2.2014 - val_acc: 0.2947\n",
      "Epoch 818/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4030 - acc: 0.2209 - val_loss: 2.2745 - val_acc: 0.2727\n",
      "Epoch 819/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4054 - acc: 0.2231 - val_loss: 2.2064 - val_acc: 0.2962\n",
      "Epoch 820/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3962 - acc: 0.2289 - val_loss: 2.2084 - val_acc: 0.2939\n",
      "Epoch 821/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3976 - acc: 0.2254 - val_loss: 2.2742 - val_acc: 0.2523\n",
      "Epoch 822/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4038 - acc: 0.2198 - val_loss: 2.2395 - val_acc: 0.2811\n",
      "Epoch 823/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3932 - acc: 0.2273 - val_loss: 2.2201 - val_acc: 0.3000\n",
      "Epoch 824/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4061 - acc: 0.2163 - val_loss: 2.2390 - val_acc: 0.2864\n",
      "Epoch 825/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.3952 - acc: 0.2244 - val_loss: 2.2788 - val_acc: 0.2712\n",
      "Epoch 826/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4118 - acc: 0.2218 - val_loss: 2.2026 - val_acc: 0.3000\n",
      "Epoch 827/1000\n",
      "11872/11872 [==============================] - 1s 46us/step - loss: 2.3973 - acc: 0.2251 - val_loss: 2.2369 - val_acc: 0.2826\n",
      "Epoch 828/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4000 - acc: 0.2254 - val_loss: 2.2135 - val_acc: 0.2992\n",
      "Epoch 829/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4004 - acc: 0.2268 - val_loss: 2.2532 - val_acc: 0.2765\n",
      "Epoch 830/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3872 - acc: 0.2268 - val_loss: 2.2281 - val_acc: 0.2886\n",
      "Epoch 831/1000\n",
      "11872/11872 [==============================] - 1s 46us/step - loss: 2.4105 - acc: 0.2214 - val_loss: 2.2227 - val_acc: 0.2848\n",
      "Epoch 832/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4099 - acc: 0.2189 - val_loss: 2.2207 - val_acc: 0.2970\n",
      "Epoch 833/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3995 - acc: 0.2246 - val_loss: 2.2388 - val_acc: 0.2788\n",
      "Epoch 834/1000\n",
      "11872/11872 [==============================] - 1s 46us/step - loss: 2.4147 - acc: 0.2202 - val_loss: 2.2135 - val_acc: 0.3030\n",
      "Epoch 835/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4053 - acc: 0.2207 - val_loss: 2.2119 - val_acc: 0.2939\n",
      "Epoch 836/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4009 - acc: 0.2262 - val_loss: 2.2069 - val_acc: 0.2939\n",
      "Epoch 837/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3951 - acc: 0.2240 - val_loss: 2.2089 - val_acc: 0.3008\n",
      "Epoch 838/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.3952 - acc: 0.2283 - val_loss: 2.2191 - val_acc: 0.3000\n",
      "Epoch 839/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4054 - acc: 0.2273 - val_loss: 2.3136 - val_acc: 0.2379\n",
      "Epoch 840/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4126 - acc: 0.2221 - val_loss: 2.2243 - val_acc: 0.2856\n",
      "Epoch 841/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4015 - acc: 0.2236 - val_loss: 2.2035 - val_acc: 0.3038\n",
      "Epoch 842/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4019 - acc: 0.2273 - val_loss: 2.2130 - val_acc: 0.2924\n",
      "Epoch 843/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3981 - acc: 0.2240 - val_loss: 2.2212 - val_acc: 0.2917\n",
      "Epoch 844/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4117 - acc: 0.2204 - val_loss: 2.1974 - val_acc: 0.2955\n",
      "Epoch 845/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3903 - acc: 0.2294 - val_loss: 2.2386 - val_acc: 0.2856\n",
      "Epoch 846/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4049 - acc: 0.2222 - val_loss: 2.2258 - val_acc: 0.2788\n",
      "Epoch 847/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3982 - acc: 0.2213 - val_loss: 2.2302 - val_acc: 0.2795\n",
      "Epoch 848/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4003 - acc: 0.2225 - val_loss: 2.2057 - val_acc: 0.2992\n",
      "Epoch 849/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4017 - acc: 0.2209 - val_loss: 2.2245 - val_acc: 0.2917\n",
      "Epoch 850/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4043 - acc: 0.2285 - val_loss: 2.2427 - val_acc: 0.2803\n",
      "Epoch 851/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3958 - acc: 0.2270 - val_loss: 2.2146 - val_acc: 0.2902\n",
      "Epoch 852/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4059 - acc: 0.2278 - val_loss: 2.1969 - val_acc: 0.2985\n",
      "Epoch 853/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4109 - acc: 0.2219 - val_loss: 2.2465 - val_acc: 0.2818\n",
      "Epoch 854/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3977 - acc: 0.2253 - val_loss: 2.2290 - val_acc: 0.2894\n",
      "Epoch 855/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3936 - acc: 0.2252 - val_loss: 2.2400 - val_acc: 0.2818\n",
      "Epoch 856/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4087 - acc: 0.2231 - val_loss: 2.2351 - val_acc: 0.2826\n",
      "Epoch 857/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4058 - acc: 0.2247 - val_loss: 2.2123 - val_acc: 0.2985\n",
      "Epoch 858/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4053 - acc: 0.2172 - val_loss: 2.2041 - val_acc: 0.3000\n",
      "Epoch 859/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4108 - acc: 0.2198 - val_loss: 2.2108 - val_acc: 0.2947\n",
      "Epoch 860/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.3979 - acc: 0.2236 - val_loss: 2.2214 - val_acc: 0.2970\n",
      "Epoch 861/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3997 - acc: 0.2283 - val_loss: 2.2425 - val_acc: 0.2848\n",
      "Epoch 862/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4067 - acc: 0.2217 - val_loss: 2.2075 - val_acc: 0.3008\n",
      "Epoch 863/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3976 - acc: 0.2268 - val_loss: 2.2143 - val_acc: 0.2932\n",
      "Epoch 864/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4094 - acc: 0.2225 - val_loss: 2.1969 - val_acc: 0.3008\n",
      "Epoch 865/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4096 - acc: 0.2229 - val_loss: 2.2060 - val_acc: 0.3038\n",
      "Epoch 866/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3944 - acc: 0.2226 - val_loss: 2.2109 - val_acc: 0.3023\n",
      "Epoch 867/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.4147 - acc: 0.2260 - val_loss: 2.2151 - val_acc: 0.2939\n",
      "Epoch 868/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4043 - acc: 0.2236 - val_loss: 2.2365 - val_acc: 0.2871\n",
      "Epoch 869/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4069 - acc: 0.2207 - val_loss: 2.2366 - val_acc: 0.2826\n",
      "Epoch 870/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3984 - acc: 0.2301 - val_loss: 2.2215 - val_acc: 0.3008\n",
      "Epoch 871/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4000 - acc: 0.2270 - val_loss: 2.1999 - val_acc: 0.2939\n",
      "Epoch 872/1000\n",
      "11872/11872 [==============================] - 1s 46us/step - loss: 2.4003 - acc: 0.2272 - val_loss: 2.2273 - val_acc: 0.2909\n",
      "Epoch 873/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4028 - acc: 0.2231 - val_loss: 2.2292 - val_acc: 0.2826\n",
      "Epoch 874/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3968 - acc: 0.2273 - val_loss: 2.2286 - val_acc: 0.2894\n",
      "Epoch 875/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3954 - acc: 0.2238 - val_loss: 2.2061 - val_acc: 0.3008\n",
      "Epoch 876/1000\n",
      "11872/11872 [==============================] - 1s 47us/step - loss: 2.3824 - acc: 0.2270 - val_loss: 2.2417 - val_acc: 0.2848\n",
      "Epoch 877/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4014 - acc: 0.2233 - val_loss: 2.2097 - val_acc: 0.2962\n",
      "Epoch 878/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4060 - acc: 0.2232 - val_loss: 2.2545 - val_acc: 0.2758\n",
      "Epoch 879/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4119 - acc: 0.2253 - val_loss: 2.1956 - val_acc: 0.3008\n",
      "Epoch 880/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3954 - acc: 0.2241 - val_loss: 2.2371 - val_acc: 0.2848\n",
      "Epoch 881/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4019 - acc: 0.2292 - val_loss: 2.2132 - val_acc: 0.2947\n",
      "Epoch 882/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3927 - acc: 0.2304 - val_loss: 2.2305 - val_acc: 0.2886\n",
      "Epoch 883/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4064 - acc: 0.2259 - val_loss: 2.2015 - val_acc: 0.2977\n",
      "Epoch 884/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3997 - acc: 0.2246 - val_loss: 2.2315 - val_acc: 0.2879\n",
      "Epoch 885/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3943 - acc: 0.2309 - val_loss: 2.2395 - val_acc: 0.2856\n",
      "Epoch 886/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4068 - acc: 0.2241 - val_loss: 2.2282 - val_acc: 0.2924\n",
      "Epoch 887/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4037 - acc: 0.2251 - val_loss: 2.2197 - val_acc: 0.3000\n",
      "Epoch 888/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3981 - acc: 0.2213 - val_loss: 2.2111 - val_acc: 0.2955\n",
      "Epoch 889/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4049 - acc: 0.2276 - val_loss: 2.2240 - val_acc: 0.2939\n",
      "Epoch 890/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3997 - acc: 0.2252 - val_loss: 2.2095 - val_acc: 0.3008\n",
      "Epoch 891/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.4086 - acc: 0.2222 - val_loss: 2.2516 - val_acc: 0.2864\n",
      "Epoch 892/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.4023 - acc: 0.2257 - val_loss: 2.2765 - val_acc: 0.2674\n",
      "Epoch 893/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.3882 - acc: 0.2262 - val_loss: 2.2384 - val_acc: 0.2841\n",
      "Epoch 894/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4010 - acc: 0.2235 - val_loss: 2.2851 - val_acc: 0.2598\n",
      "Epoch 895/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3964 - acc: 0.2312 - val_loss: 2.2489 - val_acc: 0.2871\n",
      "Epoch 896/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3976 - acc: 0.2263 - val_loss: 2.1994 - val_acc: 0.3008\n",
      "Epoch 897/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3957 - acc: 0.2253 - val_loss: 2.2010 - val_acc: 0.3008\n",
      "Epoch 898/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3990 - acc: 0.2296 - val_loss: 2.2225 - val_acc: 0.2962\n",
      "Epoch 899/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4121 - acc: 0.2205 - val_loss: 2.2070 - val_acc: 0.2985\n",
      "Epoch 900/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.3959 - acc: 0.2237 - val_loss: 2.2374 - val_acc: 0.2894\n",
      "Epoch 901/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.3934 - acc: 0.2293 - val_loss: 2.2287 - val_acc: 0.2902\n",
      "Epoch 902/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3956 - acc: 0.2300 - val_loss: 2.1975 - val_acc: 0.3023\n",
      "Epoch 903/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3946 - acc: 0.2233 - val_loss: 2.2019 - val_acc: 0.3015\n",
      "Epoch 904/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3963 - acc: 0.2286 - val_loss: 2.2182 - val_acc: 0.2962\n",
      "Epoch 905/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.3943 - acc: 0.2244 - val_loss: 2.2049 - val_acc: 0.2977\n",
      "Epoch 906/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3971 - acc: 0.2257 - val_loss: 2.2005 - val_acc: 0.3061\n",
      "Epoch 907/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4039 - acc: 0.2240 - val_loss: 2.2483 - val_acc: 0.2803\n",
      "Epoch 908/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4040 - acc: 0.2277 - val_loss: 2.2320 - val_acc: 0.2962\n",
      "Epoch 909/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4033 - acc: 0.2254 - val_loss: 2.1897 - val_acc: 0.3038\n",
      "Epoch 910/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.3926 - acc: 0.2310 - val_loss: 2.2202 - val_acc: 0.2955\n",
      "Epoch 911/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.4095 - acc: 0.2236 - val_loss: 2.2055 - val_acc: 0.2992\n",
      "Epoch 912/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4027 - acc: 0.2233 - val_loss: 2.2293 - val_acc: 0.2750\n",
      "Epoch 913/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3860 - acc: 0.2252 - val_loss: 2.2257 - val_acc: 0.2894\n",
      "Epoch 914/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3972 - acc: 0.2256 - val_loss: 2.2133 - val_acc: 0.2947\n",
      "Epoch 915/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3940 - acc: 0.2244 - val_loss: 2.2093 - val_acc: 0.2924\n",
      "Epoch 916/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3929 - acc: 0.2236 - val_loss: 2.2025 - val_acc: 0.2985\n",
      "Epoch 917/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3949 - acc: 0.2262 - val_loss: 2.2047 - val_acc: 0.2962\n",
      "Epoch 918/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3944 - acc: 0.2209 - val_loss: 2.2009 - val_acc: 0.3008\n",
      "Epoch 919/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3933 - acc: 0.2247 - val_loss: 2.1994 - val_acc: 0.3091\n",
      "Epoch 920/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3920 - acc: 0.2299 - val_loss: 2.1993 - val_acc: 0.3061\n",
      "Epoch 921/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.3969 - acc: 0.2254 - val_loss: 2.2160 - val_acc: 0.2902\n",
      "Epoch 922/1000\n",
      "11872/11872 [==============================] - 1s 50us/step - loss: 2.3966 - acc: 0.2240 - val_loss: 2.2343 - val_acc: 0.2864\n",
      "Epoch 923/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.4069 - acc: 0.2217 - val_loss: 2.2387 - val_acc: 0.2833\n",
      "Epoch 924/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3977 - acc: 0.2259 - val_loss: 2.2159 - val_acc: 0.2932\n",
      "Epoch 925/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.4055 - acc: 0.2243 - val_loss: 2.1981 - val_acc: 0.3000\n",
      "Epoch 926/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4021 - acc: 0.2262 - val_loss: 2.2152 - val_acc: 0.2977\n",
      "Epoch 927/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.3991 - acc: 0.2259 - val_loss: 2.2086 - val_acc: 0.2947\n",
      "Epoch 928/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3920 - acc: 0.2280 - val_loss: 2.2169 - val_acc: 0.2955\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.3896 - acc: 0.2262 - val_loss: 2.1889 - val_acc: 0.3045\n",
      "Epoch 930/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3940 - acc: 0.2262 - val_loss: 2.2107 - val_acc: 0.3000\n",
      "Epoch 931/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3968 - acc: 0.2273 - val_loss: 2.1913 - val_acc: 0.3038\n",
      "Epoch 932/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4008 - acc: 0.2287 - val_loss: 2.2047 - val_acc: 0.2917\n",
      "Epoch 933/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3949 - acc: 0.2257 - val_loss: 2.2398 - val_acc: 0.2856\n",
      "Epoch 934/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.3942 - acc: 0.2155 - val_loss: 2.2270 - val_acc: 0.2894\n",
      "Epoch 935/1000\n",
      "11872/11872 [==============================] - 0s 37us/step - loss: 2.4007 - acc: 0.2255 - val_loss: 2.2381 - val_acc: 0.2848\n",
      "Epoch 936/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3846 - acc: 0.2288 - val_loss: 2.2117 - val_acc: 0.2917\n",
      "Epoch 937/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.3858 - acc: 0.2277 - val_loss: 2.2149 - val_acc: 0.2962\n",
      "Epoch 938/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.3988 - acc: 0.2208 - val_loss: 2.1940 - val_acc: 0.3000\n",
      "Epoch 939/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3944 - acc: 0.2261 - val_loss: 2.2040 - val_acc: 0.2970\n",
      "Epoch 940/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3906 - acc: 0.2260 - val_loss: 2.2575 - val_acc: 0.2773\n",
      "Epoch 941/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3892 - acc: 0.2280 - val_loss: 2.2162 - val_acc: 0.2977\n",
      "Epoch 942/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.3881 - acc: 0.2255 - val_loss: 2.2074 - val_acc: 0.2962\n",
      "Epoch 943/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3950 - acc: 0.2265 - val_loss: 2.2033 - val_acc: 0.2985\n",
      "Epoch 944/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4027 - acc: 0.2269 - val_loss: 2.1918 - val_acc: 0.3083\n",
      "Epoch 945/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3876 - acc: 0.2305 - val_loss: 2.2390 - val_acc: 0.2848\n",
      "Epoch 946/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3923 - acc: 0.2291 - val_loss: 2.2298 - val_acc: 0.2902\n",
      "Epoch 947/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3970 - acc: 0.2250 - val_loss: 2.2314 - val_acc: 0.2886\n",
      "Epoch 948/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3813 - acc: 0.2277 - val_loss: 2.1980 - val_acc: 0.3083\n",
      "Epoch 949/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3995 - acc: 0.2224 - val_loss: 2.2356 - val_acc: 0.2879\n",
      "Epoch 950/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3929 - acc: 0.2294 - val_loss: 2.1973 - val_acc: 0.3030\n",
      "Epoch 951/1000\n",
      "11872/11872 [==============================] - 0s 38us/step - loss: 2.4010 - acc: 0.2254 - val_loss: 2.2060 - val_acc: 0.2939\n",
      "Epoch 952/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3934 - acc: 0.2288 - val_loss: 2.2485 - val_acc: 0.2788\n",
      "Epoch 953/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3961 - acc: 0.2244 - val_loss: 2.2184 - val_acc: 0.2902\n",
      "Epoch 954/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3896 - acc: 0.2263 - val_loss: 2.2235 - val_acc: 0.2886\n",
      "Epoch 955/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3892 - acc: 0.2246 - val_loss: 2.2274 - val_acc: 0.2826\n",
      "Epoch 956/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4017 - acc: 0.2258 - val_loss: 2.2040 - val_acc: 0.2985\n",
      "Epoch 957/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3876 - acc: 0.2326 - val_loss: 2.2305 - val_acc: 0.2818\n",
      "Epoch 958/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4040 - acc: 0.2232 - val_loss: 2.2244 - val_acc: 0.2864\n",
      "Epoch 959/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4000 - acc: 0.2217 - val_loss: 2.2052 - val_acc: 0.3023\n",
      "Epoch 960/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3937 - acc: 0.2257 - val_loss: 2.2375 - val_acc: 0.2811\n",
      "Epoch 961/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3988 - acc: 0.2226 - val_loss: 2.2005 - val_acc: 0.3030\n",
      "Epoch 962/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3906 - acc: 0.2273 - val_loss: 2.2239 - val_acc: 0.2917\n",
      "Epoch 963/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4168 - acc: 0.2184 - val_loss: 2.2027 - val_acc: 0.2970\n",
      "Epoch 964/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3930 - acc: 0.2261 - val_loss: 2.1976 - val_acc: 0.3038\n",
      "Epoch 965/1000\n",
      "11872/11872 [==============================] - 0s 34us/step - loss: 2.3885 - acc: 0.2243 - val_loss: 2.2009 - val_acc: 0.3015\n",
      "Epoch 966/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3939 - acc: 0.2237 - val_loss: 2.2293 - val_acc: 0.2909\n",
      "Epoch 967/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3888 - acc: 0.2278 - val_loss: 2.1923 - val_acc: 0.3053\n",
      "Epoch 968/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3897 - acc: 0.2266 - val_loss: 2.2154 - val_acc: 0.2909\n",
      "Epoch 969/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.4155 - acc: 0.2220 - val_loss: 2.2278 - val_acc: 0.2909\n",
      "Epoch 970/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.4067 - acc: 0.2267 - val_loss: 2.2162 - val_acc: 0.2856\n",
      "Epoch 971/1000\n",
      "11872/11872 [==============================] - 0s 35us/step - loss: 2.3933 - acc: 0.2294 - val_loss: 2.2272 - val_acc: 0.2924\n",
      "Epoch 972/1000\n",
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.4021 - acc: 0.2268 - val_loss: 2.2359 - val_acc: 0.2894\n",
      "Epoch 973/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3899 - acc: 0.2235 - val_loss: 2.2194 - val_acc: 0.2932\n",
      "Epoch 974/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3965 - acc: 0.2268 - val_loss: 2.2661 - val_acc: 0.2689\n",
      "Epoch 975/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3958 - acc: 0.2225 - val_loss: 2.2113 - val_acc: 0.2977\n",
      "Epoch 976/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3942 - acc: 0.2197 - val_loss: 2.2214 - val_acc: 0.2909\n",
      "Epoch 977/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4024 - acc: 0.2203 - val_loss: 2.1993 - val_acc: 0.2932\n",
      "Epoch 978/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3911 - acc: 0.2235 - val_loss: 2.2069 - val_acc: 0.3000\n",
      "Epoch 979/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.3964 - acc: 0.2221 - val_loss: 2.2041 - val_acc: 0.2985\n",
      "Epoch 980/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3993 - acc: 0.2241 - val_loss: 2.2103 - val_acc: 0.2864\n",
      "Epoch 981/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3913 - acc: 0.2239 - val_loss: 2.2161 - val_acc: 0.2962\n",
      "Epoch 982/1000\n",
      "11872/11872 [==============================] - 0s 39us/step - loss: 2.3972 - acc: 0.2236 - val_loss: 2.2293 - val_acc: 0.2917\n",
      "Epoch 983/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3974 - acc: 0.2271 - val_loss: 2.2121 - val_acc: 0.3030\n",
      "Epoch 984/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.3845 - acc: 0.2289 - val_loss: 2.2142 - val_acc: 0.2962\n",
      "Epoch 985/1000\n",
      "11872/11872 [==============================] - 1s 42us/step - loss: 2.3974 - acc: 0.2244 - val_loss: 2.2123 - val_acc: 0.3023\n",
      "Epoch 986/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.3951 - acc: 0.2204 - val_loss: 2.2139 - val_acc: 0.2970\n",
      "Epoch 987/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11872/11872 [==============================] - 0s 36us/step - loss: 2.3989 - acc: 0.2234 - val_loss: 2.2023 - val_acc: 0.3000\n",
      "Epoch 988/1000\n",
      "11872/11872 [==============================] - 0s 34us/step - loss: 2.3937 - acc: 0.2242 - val_loss: 2.2283 - val_acc: 0.2902\n",
      "Epoch 989/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.3945 - acc: 0.2266 - val_loss: 2.1973 - val_acc: 0.3038\n",
      "Epoch 990/1000\n",
      "11872/11872 [==============================] - 0s 40us/step - loss: 2.4006 - acc: 0.2271 - val_loss: 2.2783 - val_acc: 0.2674\n",
      "Epoch 991/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.4039 - acc: 0.2224 - val_loss: 2.1990 - val_acc: 0.2992\n",
      "Epoch 992/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3817 - acc: 0.2268 - val_loss: 2.2345 - val_acc: 0.2818\n",
      "Epoch 993/1000\n",
      "11872/11872 [==============================] - 1s 51us/step - loss: 2.4011 - acc: 0.2238 - val_loss: 2.2014 - val_acc: 0.3030\n",
      "Epoch 994/1000\n",
      "11872/11872 [==============================] - 1s 43us/step - loss: 2.3891 - acc: 0.2303 - val_loss: 2.1930 - val_acc: 0.3045\n",
      "Epoch 995/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.4047 - acc: 0.2236 - val_loss: 2.2006 - val_acc: 0.3023\n",
      "Epoch 996/1000\n",
      "11872/11872 [==============================] - 0s 41us/step - loss: 2.3961 - acc: 0.2262 - val_loss: 2.2487 - val_acc: 0.2871\n",
      "Epoch 997/1000\n",
      "11872/11872 [==============================] - 0s 42us/step - loss: 2.3930 - acc: 0.2302 - val_loss: 2.2243 - val_acc: 0.2932\n",
      "Epoch 998/1000\n",
      "11872/11872 [==============================] - 1s 48us/step - loss: 2.4036 - acc: 0.2262 - val_loss: 2.1929 - val_acc: 0.2992\n",
      "Epoch 999/1000\n",
      "11872/11872 [==============================] - 1s 44us/step - loss: 2.4019 - acc: 0.2204 - val_loss: 2.1999 - val_acc: 0.2992\n",
      "Epoch 1000/1000\n",
      "11872/11872 [==============================] - 1s 45us/step - loss: 2.3864 - acc: 0.2224 - val_loss: 2.1866 - val_acc: 0.3061\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.051\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0 256   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 291   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 277   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 283   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 288   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 302   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 287   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 284   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 290   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 307   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 304   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 294   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 301   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 303   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 289   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 295   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 296   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 274   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 242   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 191   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(linewidth=120)\n",
    "Ytest_ = model.predict(Xtest)\n",
    "ytest_ = np.argmax(Ytest_, axis=1)\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "print(\"accuracy score: {:.3f}\".format(accuracy_score(ytest, ytest_)))\n",
    "print(\"\\nconfusion matrix\\n\")\n",
    "print(confusion_matrix(ytest, ytest_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
